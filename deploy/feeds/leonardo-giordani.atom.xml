<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>The Digital Cat - Leonardo Giordani</title><link href="https://www.thedigitalcatonline.com/" rel="alternate"></link><link href="https://www.thedigitalcatonline.com/feeds/leonardo-giordani.atom.xml" rel="self"></link><id>https://www.thedigitalcatonline.com/</id><updated>2022-08-23T12:00:00+00:00</updated><subtitle>Adventures of a curious cat in the land of programming</subtitle><entry><title>Data Partitioning and Consistent Hashing</title><link href="https://www.thedigitalcatonline.com/blog/2022/08/23/data-partitioning-and-consistent-hashing/" rel="alternate"></link><published>2022-08-23T12:00:00+00:00</published><updated>2022-08-23T12:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2022-08-23:/blog/2022/08/23/data-partitioning-and-consistent-hashing/</id><summary type="html"></summary><content type="html">&lt;p&gt;This post is an introduction to partitioning, a technique for distributed storage systems, and to consistent hashing, a specific partitioning algorithm that promotes even distribution of data, while allowing to dynamically change the number of servers and minimising the cost of the transition.&lt;/p&gt;&lt;p&gt;My interest in partitioning dates back to 2015 when I was following courses at the MongoDB university and learned about &lt;em&gt;sharding&lt;/em&gt;, the name MongoDB uses for partitioning. I was fascinated by the topic and discovered the technique known as &lt;em&gt;consistent hashing&lt;/em&gt;; I enjoyed it a lot, so much that I wrote a little demo in Python to understand it better. Later, I focused on other things and forgot the project completely, until recently, when &lt;a href="https://github.com/drocpdp"&gt;David Eynon&lt;/a&gt; sent me a PR on GitHub to replace a deprecated testing library. So, I decided to brush up on my knowledge of consistent hashing and, as I often do on this blog, dump my thoughts in a post.&lt;/p&gt;&lt;p&gt;The topic of distributed storage and data processing is arguably rich and complicated, so while I will try to give a broader context to the concepts that I will introduce, I by no means intend to write a comprehensive guide to the subject matter. The audience of this post is developers who do not know what partitioning and consistent hashing are and want to take their first step into those topics.&lt;/p&gt;&lt;div class="infobox"&gt;&lt;i class="fa fa-"&gt;&lt;/i&gt;&lt;div class="title"&gt;Code syntax&lt;/div&gt;&lt;div&gt;&lt;p&gt;You will find some code examples mentioned in the post, which are written using the Python notation. If you are not familiar with the language, these are the main rules&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;x**y&lt;/code&gt; means x&lt;sup&gt;y&lt;/sup&gt;, e.g. &lt;code&gt;2**3 =&amp;gt; 8&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;code&gt;x//y&lt;/code&gt; means the integer division between &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, e.g. &lt;code&gt;11//4 =&amp;gt; 2&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;code&gt;x%y&lt;/code&gt; means the modulo operation (remainder of integer division), e.g. &lt;code&gt;11%4 =&amp;gt; 3&lt;/code&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2 id="rationale"&gt;Rationale&lt;a class="headerlink" href="#rationale" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When we design a system, we might want to scatter data among multiple sources to allow real concurrency of access and a more targeted optimisation.&lt;/p&gt;&lt;p&gt;For example, we might observe that in a given social media application there are two types of queries: some are very infrequent and involve tables related to personal data and the user profile, others are extremely frequent and pretty intensive, and are related to the content shared by the user. In this case, we might decide to store the tables related to the profile and the tables that are related to content in two different systems, A and B (here, the word &lt;em&gt;system&lt;/em&gt; might be freely replaced by &lt;em&gt;computer&lt;/em&gt;, &lt;em&gt;database&lt;/em&gt;, &lt;em&gt;storage system&lt;/em&gt;, or other similar components).&lt;/p&gt;&lt;p&gt;This means that the infrequent queries that fetch personal data will be served by system A, while the more frequent and intensive queries related to content will be served by system B.&lt;/p&gt;&lt;p&gt;Suddenly, we have the chance to deploy system B using more powerful and expensive hardware, or an architecture with better performances, without increasing the cost for tables that won't benefit from such an improvement as the ones stored in system A.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/partitioning_rationale.jpg"&gt;&lt;/div&gt;&lt;p&gt;This is a standard approach in system design, and it requires the introduction of an additional layer of control that will route requests to the right source. This layer might be implemented in several places, for example:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;in the code of our application, with conditional structures that query different data sources&lt;/li&gt;&lt;li&gt;in the framework that we are using for the application, for example in a middleware that automatically routes requests according to nature or the query&lt;/li&gt;&lt;li&gt;in a wrapper around the storage that hides the fact that data exists in two different systems&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In the last case, this technique is usually called &lt;em&gt;partitioning&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;In this post, I will try to show the challenges we face when we partition data and focus on some of the algorithms that can be used to implement it, in particular on consistent hashing. Please note that, while some of these techniques are used by databases to provide internal partitioning, they have a wider range of applications and might come in handy in different contexts.&lt;/p&gt;&lt;h2 id="design-choices"&gt;Design choices&lt;a class="headerlink" href="#design-choices" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Every design choice in a system depends on the requirements, and when it comes to data storage the most important factors are the &lt;em&gt;nature of the data&lt;/em&gt;, its &lt;em&gt;distribution&lt;/em&gt;, and the &lt;em&gt;access patterns&lt;/em&gt;. Consider for example databases and Content Delivery Networks (CDNs): both are meant to store data, and the storage size of both can vary substantially. However, there are important differences between the two that greatly affect the design choices. Let's see some simple examples:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;databases are meant to store data in a long-term fashion, while caches are by definition short-lived. This means that an important requirement for databases is data preservation, and we should do everything in our power to avoid losing parts of the database. A cache, conversely, holds data for a short time, either predetermined by the system or forced by a change in the data source. As you can see in this case we not only take data loss as part of the equation, but we get to the point where we trigger it on purpose.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;applications often make use of range queries, which means that they retrieve sets of results spanning a range of values of one of the keys; for example, you might want to see all employers within a certain range of salaries, or all users that have more than a certain amount of followers. In such cases, it makes little sense to scatter data among different physical sources, thus making the retrieval more complicated and ultimately affecting performances. Databases see very often an access pattern of this type, while caches, being usually implemented as key/value stores, do not need to take this into account.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="a-practical-example-of-partitioning"&gt;A practical example of partitioning&lt;a class="headerlink" href="#a-practical-example-of-partitioning" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let us consider a simple key/value store, for example a common address book where the key is the name of the contact and the value a rich document with their personal details. If multiple users access the store, chances are that the system will at a certain point struggle to serve all the requests, so we might want to partition the data to allow concurrent access. We can for example sort them alphabetically and split them in two, storing all values with a key that begins with the letters A-M in one server and the rest (keys N-Z) in the second one.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/simple_partitioning_1.jpg"&gt;&lt;/div&gt;&lt;p&gt;This might seem a good idea, but we will soon discover that performances are not great. Unfortunately, our address book doesn't contain the same number of people for each letter, as (for example) we know more people whose name starts with A or C than with X or Z.&lt;/p&gt;&lt;p&gt;That poses a problem, as our partitioning doesn't achieve the desired outcome, that of splitting requests evenly between the two servers. If we increase the number of partitions, serving smaller groups of letters, we will just worsen the problem, to the point where a partition might be completely empty and thus receive no traffic: since the problem comes from the data distribution, we need to find a way to change that property.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/simple_partitioning_2.jpg"&gt;&lt;/div&gt;&lt;p&gt;One way to deal with the problem is to change the boundaries of the partitions so that we get an almost even distribution of values among them. For example, we might store keys starting with A-B in the first partition, keys starting with C-D in the second, and all the rest in the third one.&lt;/p&gt;&lt;p&gt;The problem with such a strategy is that it is highly dependent on the actual data that we are storing. Not only does this mean the solution has to be customised for each use case (the partitions in the example might be good for one address book and completely wrong for another), but adding data to the storage might change the distribution and invalidate the solution.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/simple_partitioning_3.jpg"&gt;&lt;/div&gt;&lt;h2 id="hash-functions-to-the-rescue"&gt;Hash functions to the rescue&lt;a class="headerlink" href="#hash-functions-to-the-rescue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;An interesting solution to the problem of distributing data evenly is represented by hash functions. As I explained in my post &lt;a href="https://www.thedigitalcatonline.com/blog/2018/04/06/introduction-to-hashing/"&gt;Introduction to hashing&lt;/a&gt;, good hash functions produce a highly uniform distribution, which makes them ideal in this case. Please note that hash functions can help with &lt;em&gt;routing queries&lt;/em&gt; and not with &lt;em&gt;storing data&lt;/em&gt;. Hashed values cannot replace the content, as they are not bijective, i.e. given two different inputs the output might be the same (collision), so they can only be used to decide &lt;em&gt;where&lt;/em&gt; to store a piece of information.&lt;/p&gt;&lt;p&gt;We can at this point devise a storage strategy based on hash functions. We can divide the output space of the hash function (codomain) into a certain amount of partitions and be sure that each one of them will contain a similar amount of elements. For example, the hash function might output a 32-bit number, so we know that each hashed value will be between 0 and 2&lt;sup&gt;32&lt;/sup&gt; (4,294,967,295), and from here it's pretty straightforward to find partition boundaries. For example, we can create 16 partitions numbered 0 to 15, each one containing 2&lt;sup&gt;28&lt;/sup&gt; hash values (268,435,456).&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/hash_functions.jpg"&gt;&lt;/div&gt;&lt;p&gt;Routing is at this point very simple, as we can mathematically find the partition number given the hash. There are many ways to do this but two simple approaches are&lt;/p&gt;&lt;ul&gt;&lt;li&gt;using the integer division &lt;code&gt;hash(k) // partition_size&lt;/code&gt;, e.g. &lt;code&gt;hash(k) // 2**28&lt;/code&gt;. All keys from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;268435455&lt;/code&gt; end up in partition 0 (&lt;code&gt;268435455 // 2**28&lt;/code&gt;), keys from &lt;code&gt;268435456&lt;/code&gt; to &lt;code&gt;536870911&lt;/code&gt; end up in partition 1, and so on.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;using the modulo operator &lt;code&gt;hash(k) % number_of_partitions&lt;/code&gt;, e.g. &lt;code&gt;hash(k) % 16&lt;/code&gt;. This assigns values to partitions in a round robin fashion, where key &lt;code&gt;0&lt;/code&gt; goes to partition 0 (&lt;code&gt;0%16&lt;/code&gt;), key &lt;code&gt;1&lt;/code&gt; to partition 1 (&lt;code&gt;1%16&lt;/code&gt;), key &lt;code&gt;15&lt;/code&gt; to partition 15 (&lt;code&gt;15%16&lt;/code&gt;), and then starts again with key &lt;code&gt;16&lt;/code&gt; which goes to partition 0 (&lt;code&gt;16%16&lt;/code&gt;), and so on.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This architecture has the clear advantage that thanks to the properties of hash functions, data is scattered evenly among the partitions. This means that when we query the system, requests will also be divided evenly, thus giving us a good distribution of the load.&lt;/p&gt;&lt;p&gt;As we will see later, however, this is not a good approach for dynamic systems.&lt;/p&gt;&lt;h2 id="partitioning-use-cases"&gt;Partitioning use cases&lt;a class="headerlink" href="#partitioning-use-cases" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Hash functions are definitely interesting but they are not the perfect solution in every case. Let's have a brief look at three different types of systems that might benefit from partitioning and discuss their specific requirements.&lt;/p&gt;&lt;h3 id="load-balancers"&gt;Load balancers&lt;/h3&gt;&lt;p&gt;Pure load balancers solve a simple problem: to spread requests evenly across multiple &lt;em&gt;identical&lt;/em&gt; servers. The key word here is "identical", as you cannot pick the wrong server, thus no routing can result in an error. However, spreading the load unevenly can result in performance loss, and possibly also service failure. For example, if a server gets overloaded queries might hit a timeout while waiting to be served.&lt;/p&gt;&lt;p&gt;For this reason, when load balancing is not content-aware, for example in a simple HTTP server scenario, round-robin partitioning is a good choice. The system just assigns new requests to servers on a rotation basis, which ensures perfectly even distribution. For example, this algorithm is the default choice for AWS Application Load Balancers.&lt;/p&gt;&lt;p&gt;Clearly, load balancers can be more complicated and feature-rich even without becoming content aware. The aforementioned AWS ALBs, for example, support also the "least outstanding requests" algorithm, which in simple words means choosing the server with the smallest workload.&lt;/p&gt;&lt;h3 id="caches"&gt;Caches&lt;/h3&gt;&lt;p&gt;Caches are systems that temporarily store data whose retrieval is expensive, either for the user or for the provider. For example, if a system runs a long query on a database caching the result will be beneficial both for the system and the database. For the former, because a repeated run will get the result much faster and for the latter because the load of the new query is zero.&lt;/p&gt;&lt;p&gt;Caches can be found everywhere and vary dramatically in size, but they are one of the best examples of systems that benefit from partitioning. As I mentioned before, their standard usage patterns don't include range queries and data loss (flushing) is part of their normal workflow.&lt;/p&gt;&lt;p&gt;A Content Delivery Network (CDN) is a specific type of cache that is distributed geographically. The purpose of the CDN nodes is to store content in a location that is physically near the users, thus increasing the performance of the system. This means that two geographically distinct nodes of a CDN contain the same values (replication), and the routing policy is solely based on the physical position of the user with respect to the node. Internally, each CDN node can be implemented using partitioning, though, which might speed up the performances of that specific node.&lt;/p&gt;&lt;h3 id="databases"&gt;Databases&lt;/h3&gt;&lt;p&gt;As for databases, I already mentioned that the most important problem is range queries or if you prefer, content-aware partitioning. In general, you can't partition a database without taking into account the content, or you will incur severe performance losses. So, when it comes to databases, partitioning has to be the result of a specific design and can't be applied regardless of the database schema. &lt;/p&gt;&lt;p&gt;To better understand the challenge, let's consider a simple database whose elements are employees with a name and a salary. Now, if we want to partition this database we have to choose a key for the partitioning itself. It might be the primary key, the name, or the salary, as these are the only values available in each record.&lt;/p&gt;&lt;p&gt;Say we use hash functions to partition the database and use the employee salary as a key. Because of the properties of hash functions, employees with the exact same salary will end up being stored in the same partition, but employees with similar salaries might end up in different ones. This depends on the number of partitions, clearly, but the main point is that records that are "near" (according to the selected key) now are potentially very far.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/hash_functions_and_range_queries.jpg"&gt;&lt;/div&gt;&lt;p&gt;In the example above I used MD5 as the routing hash function, and you can reproduce the calculations using the following Python code&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hashlib&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hash_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hashlib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;md5&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hexdigest&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 57500283691658467528082923406379043196&lt;/span&gt;
&lt;span class="n"&gt;hash_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 209589555716047624083879134729984902154&lt;/span&gt;
&lt;span class="n"&gt;hash_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 12&lt;/span&gt;
&lt;span class="n"&gt;hash_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;

&lt;span class="c1"&gt;# 10&lt;/span&gt;
&lt;span class="n"&gt;hash_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Things do not go much better if we use the integer division. If we have 16 partitions, each one of them contains 2&lt;sup&gt;124&lt;/sup&gt; values&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 2&lt;/span&gt;
&lt;span class="n"&gt;hash_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;124&lt;/span&gt;

&lt;span class="c1"&gt;# 9&lt;/span&gt;
&lt;span class="n"&gt;hash_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;124&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Now, let's consider a query that selects all employees within a certain range of salaries. If the database is not partitioned, all records are kept on the same server, and if we optimised the system for such a query, the records will also be physically adjacent (e.g. stored in nearby memory addresses). This makes the query blazing fast, but if the database is partitioned the query has to collect values from multiple partitions which greatly penalises performance.&lt;/p&gt;&lt;p&gt;We can see a real example of this design challenge in the documentation of MongoDB, a non-relational database that supports partitioning (called &lt;em&gt;sharding&lt;/em&gt;). MongoDB supports &lt;a href="https://www.mongodb.com/docs/manual/core/hashed-sharding/"&gt;hashed sharding&lt;/a&gt; and &lt;a href="https://www.mongodb.com/docs/manual/core/ranged-sharding/"&gt;ranged sharding&lt;/a&gt;. In their words&lt;/p&gt;&lt;p&gt;&lt;em&gt;Hashed sharding uses either a single field hashed index or a compound hashed index as the shard key to partition data across your sharded cluster.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Range-based sharding involves dividing data into contiguous ranges determined by the shard key values. In this model, documents with "close" shard key values are likely to be in the same chunk or shard. This allows for efficient queries where reads target documents within a contiguous range. However, both read and write performance may decrease with poor shard key selection.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;I highly recommend reading the two pages I linked above as they will give you a good idea of how a real system uses the concepts I introduced and what design challenges are involved when using partitioning.&lt;/p&gt;&lt;h2 id="caching-and-scaling-strategies"&gt;Caching and scaling strategies&lt;a class="headerlink" href="#caching-and-scaling-strategies" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When we design distributed caches, an interesting problem we might face is that of scaling the system in and out to match the current load without wasting resources.&lt;/p&gt;&lt;p&gt;When the cache is under a light load we might want to run a small number of servers, but as soon as the number of requests increases we need to proportionally increase the number of cache nodes if we want to avoid a performance drop. This is usually not a big problem for partitioned databases, since in that case we change the number of partitions only occasionally to adjust performances or to increase the storage size, but caches like CDNs might need continuous adjustments during a single day.&lt;/p&gt;&lt;p&gt;Increasing or decreasing the number of nodes in a distributed cache might however be a pretty destructive action. Depending on the routing algorithm, if we add nodes (scale out) we might need to move data from existing ones to the newly added ones, and if we remove nodes (scale in) we will certainly lose the data contained in them. Both scenarios result in a (potentially massive) cache invalidation which can't be taken lightly.&lt;/p&gt;&lt;p&gt;The hash-based routing method presented in the previous section has terrible performances when it comes to scaling because any change in the number of servers impacts the key boundaries of the existing ones. Let's see a practical example of that and calculate the actual figures.&lt;/p&gt;&lt;h3 id="scaling-out-with-hash-partitioning"&gt;Scaling out with hash partitioning&lt;/h3&gt;&lt;p&gt;Every time you consider a process or an algorithm you should have a look at how it behaves in the worst possible condition, to have a glimpse of what you might run into when you use it. For this reason, the following example considers a scale-out scenario in which all cache nodes are full. The best case is obviously when all nodes are empty, but in that case we don't need to scale out at all.&lt;/p&gt;&lt;p&gt;Let's consider a 32-bit hash function and 16 partitions numbered 0 to 15. Since the hash function space is 2&lt;sup&gt;32&lt;/sup&gt; (4,294,967,296), each partition will contain 2&lt;sup&gt;28&lt;/sup&gt; hash values (268,435,456). Each node is full, which means that all the possible 2&lt;sup&gt;28&lt;/sup&gt; slots are assigned to a cached item, that is some data stored in the server that corresponds to that partition. The system is using the integer division routing system.&lt;/p&gt;&lt;p&gt;If we scale out to 17 partitions, increasing the pool by just by 1 node, each node will now contain a smaller part of the global data space, as now we split it among more nodes. In particular, each node used to contain 1/16 of the global data (268,435,456), and will now contain 1/17 of it (approx. 252,645,135). Our biggest problem is now managing the transition between the initial setup and the new one.&lt;/p&gt;&lt;p&gt;The first node hosted 1/16 of the data space, the keys from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;268435455&lt;/code&gt;. It will now contain 1/17 of the data space, the keys from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;252645134&lt;/code&gt;. To simplify the example it is useful to convert everything into a common unit of measure: the node used to contain 17/272 of the space (1/16) and contains now 16/272 (1/17) of it.&lt;/p&gt;&lt;p&gt;This means that 1/272 of the whole data space has to be moved to the second node, corresponding to the keys from &lt;code&gt;252645135&lt;/code&gt; to &lt;code&gt;268435455&lt;/code&gt;. It is important to note that these keys cannot be moved to the newly added node, but have to be moved to the second node because the algorithm we use maps keys to nodes in order.&lt;/p&gt;&lt;p&gt;This means that the second node will receive 1/272 of the whole data space. Since it originally already contained 17/272 of the whole space it should now theoretically contain 18/272 of it. However, as it happened for the first node, we want to balance the content and reduce it to 16/272, so now we have 2/272 of the whole space that we want to move to the third node.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/ripple_effect.jpg"&gt;&lt;/div&gt;&lt;p&gt;So, we move 1/272 from node 1 to node 2, 2/272 from node 2 to node 3, 3/272 from node 3 to node 4, and going on with the example we end up moving 16/272 (1/17) from the 16th node to the 17th, which fills it with the correct amount of keys. However, in doing so we moved 136/272 (1/272 + 2/272 + 3/272 + ... + 16/272) of the data space between nodes, which is exactly 50% of it.&lt;/p&gt;&lt;p&gt;So, for any initial size and a scale out of 1 single node, we have to move 50% of the data stored in our cache, and it might only get worse by increasing the number of final nodes until we end up having to move almost 100% of it (in an extreme case). A similar effect plagues the scale-in action, where one or more nodes are removed from the pool, and the keys they contain have to be migrated to the remaining nodes, creating a ripple effect to redistribute the keys according to the algorithm.&lt;/p&gt;&lt;p&gt;Using a modulo routing strategy doesn't change things: as I mentioned before, the core issue is that the addition of new nodes changes the routing of the whole data space, requiring a massive migration of keys in the entire system.&lt;/p&gt;&lt;h2 id="a-different-approach"&gt;A different approach&lt;a class="headerlink" href="#a-different-approach" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;While the idea of using hash functions looked very promising, we quickly found that the trivial implementation has very poor performances in a dynamic setting. As we clearly saw in the previous section, the problem is that upon scaling more than half of the keys have to be moved across nodes, so if we could find a way to avoid this we could still use hash functions to scatter data uniformly across the nodes.&lt;/p&gt;&lt;p&gt;As you might have already figured out, the issue comes from the attempt to keep all nodes perfectly balanced. The modulo and integer division algorithms distribute keys evenly (as long as the hash function has a good diffusion), but this is a double-edged sword. The balance is extremely beneficial in a static environment, but it is also the Achilles heel of this architecture when we change the number of nodes.&lt;/p&gt;&lt;p&gt;When we design a system, requirements are paramount. Everything we add to the final product should be there to satisfy one or more requirements. However, often requirements clash with each other, and trying to implement all of them at once might lead to situations where there is no apparent solution. In such cases, it is useful to temporarily drop one or more requirements and investigate the options we have, and this is exactly what we can do in this case: maintaining balance is an important feature, but let's see what would happen if we didn't have that requirement.&lt;/p&gt;&lt;p&gt;If we don't care about balancing nodes we can solve the problem with a different approach. Instead of using the integer division to find the slot, we can keep a table of the minimum hash served by each slot and route requests according to that. Each row of the table will have a minimum hash and the node that serves them.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/hash_table.jpg"&gt;&lt;/div&gt;&lt;p&gt;This means that when we increase the number of slots we can just drop a new slot anywhere and assign to it all the keys that fall under its domain. This means that the new node will become the owner of keys that belonged to another node as it happened before, but with an important difference. Now all keys come from another single node, and the amount of keys moved is a fraction of those contained in it (which is much less than half of the keys). In the worst case, we need to move all keys contained in a node, which once again is much less than half of the keys.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/hash_table_add_node.jpg"&gt;&lt;/div&gt;&lt;p&gt;As you can see, this relieves the load of one single node. According to what we said before, we are not trying to balance the load of the whole cluster. If we could use this technique to cover multiple spaces with a single added node, though, we could relieve the load of more than one other node. In principle this is simple: we just need to add multiple rows with the same node to the table.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/data-partitioning-and-consistent-hashing/hash_table_add_node_multiple.jpg"&gt;&lt;/div&gt;&lt;p&gt;Pay attention to the fact that we added multiple rows, that is multiple partitions, but they are all served by the same physical node. This has several advantages:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It fills the new node with keys coming from several different nodes without rippling effects.&lt;/li&gt;&lt;li&gt;The key transfer load is spread among different nodes, noticeably hitting only the new node.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;There is also an interesting turn of events: since keys for the new node are fetched from several different existing nodes, the process will keep the cluster balanced! This is a remarkable outcome: we temporarily dropped a requirement and found a solution that provides that exact requirement in a different way.&lt;/p&gt;&lt;p&gt;The key part of this new process is the idea that multiple partitions can be served by the same node. The only missing part at this point is a way to identify the new partitions (the sets of hashes) served by the new node in a deterministic way.&lt;/p&gt;&lt;h2 id="consistent-hashing"&gt;Consistent hashing&lt;a class="headerlink" href="#consistent-hashing" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Finally, let me introduce consistent hashing as a technique to implement the process described above.&lt;/p&gt;&lt;p&gt;As we discussed in the previous section, the only missing part is an algorithm that produces a deterministic set of hash ranges for a single new node. These hash ranges represent the partitions served by that node and should be scattered across the whole hash space. It is important for them to be spread because this way they will each receive some keys from existing nodes, instead of migrating a bulk of keys from a single one. The more evenly spread, the better the distribution of the load and the more balanced the resulting cluster.&lt;/p&gt;&lt;p&gt;As we saw previously, any time we need to scatter data across a given space in a deterministic way, hash functions are a good choice, and they can be used in this case as well. The idea is simple: &lt;em&gt;each partition of a node is assigned a name and this name is hashed with the same function used to hash the keys stored in the system&lt;/em&gt;. This will produce a deterministic value in the hash space, and &lt;em&gt;that value will be the minimum value served by that partition&lt;/em&gt;. Thanks to diffusion the names of all partitions will generate different hash values that won't easily clash, and this is the way we generate the routing table.&lt;/p&gt;&lt;p&gt;Let's see an example, bearing in mind that the specific function can change among implementations.&lt;/p&gt;&lt;p&gt;For simplicity's sake, I used a custom hash function that outputs 28-bit hashes (7 hexadecimal digits). This makes it possible to compare hashes visually and simplifies the example. To do this I took the first 7 digits of the SHA1 hash with the following Python code&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hash_name&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hashlib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sha1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hexdigest&lt;/span&gt;&lt;span class="p"&gt;()[:&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;thus creating a hash function whose values go from &lt;code&gt;0x0000000&lt;/code&gt; to &lt;code&gt;0xfffffff&lt;/code&gt;. At the end of the post you will find the Python code that I used to generate the following routing tables, and you are free to experiment using different settings.&lt;/p&gt;&lt;p&gt;WARNING: this is not a good hash function! SHA1 produces 160 bits hashes, so taking the first 28 bits reduces the hash space to a microscopic fraction of the total, as we go from 2&lt;sup&gt;160&lt;/sup&gt; total hashes to 2&lt;sup&gt;28&lt;/sup&gt;. Please keep in mind that this is done only to simplify the visualisation of the example.&lt;/p&gt;&lt;p&gt;All our nodes are called &lt;code&gt;server-X&lt;/code&gt; with &lt;code&gt;X&lt;/code&gt; being a letter of the English alphabet, thus giving us &lt;code&gt;server-a&lt;/code&gt;, &lt;code&gt;server-b&lt;/code&gt;, and so on. I decided to create 5 partitions per server, numbered from 0 to 4, which are generated appending &lt;code&gt;-Y&lt;/code&gt; to the name, where &lt;code&gt;Y&lt;/code&gt; is the number of the partition. For example:&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;server-a-0 -- hash --&amp;gt; 148456820
server-a-1 -- hash --&amp;gt; 57674441
server-a-2 -- hash --&amp;gt; 216250418
server-a-3 -- hash --&amp;gt; 30595746
server-a-4 -- hash --&amp;gt; 23746828
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;If we do this for two nodes (&lt;code&gt;server-a&lt;/code&gt; and &lt;code&gt;server-b&lt;/code&gt;) and then sort the results we will get a full routing table&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 23746828 --&amp;gt; server-a-4 ( 6848918 hashes)
 30595746 --&amp;gt; server-a-3 (27078695 hashes)
 57674441 --&amp;gt; server-a-1 ( 3228787 hashes)
 60903228 --&amp;gt; server-b-2 (17957108 hashes)
 78860336 --&amp;gt; server-b-0 ( 7773725 hashes)
 86634061 --&amp;gt; server-b-4 (61822759 hashes)
148456820 --&amp;gt; server-a-0 (67793598 hashes)
216250418 --&amp;gt; server-a-2 (17304439 hashes)
233554857 --&amp;gt; server-b-3 (29289666 hashes)
262844523 --&amp;gt; server-b-1 ( 5590932 hashes)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Remember that the hashes in the routing table are the minimum hash served by that partition. For example, the first line tells us that all hashes from &lt;code&gt;23746828&lt;/code&gt; are served by the partition &lt;code&gt;server-a-4&lt;/code&gt;, while hashes from &lt;code&gt;30595746&lt;/code&gt; are served by the partition &lt;code&gt;server-a-3&lt;/code&gt;. This means that the partition &lt;code&gt;server-a-4&lt;/code&gt; serves 6848918 hashes (as you can read in the table). A key whose hash is &lt;code&gt;79249022&lt;/code&gt; will be served by &lt;code&gt;server-b-0&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 60903228 --&amp;gt; server-b-2 (17957108 hashes)
 78860336 --&amp;gt; server-b-0 ( 7773725 hashes)
                     ^
                     |
 79249022 -----------+

 86634061 --&amp;gt; server-b-4 (61822759 hashes)
148456820 --&amp;gt; server-a-0 (67793598 hashes)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Since partitions are not physically separated, but are just virtual entities belonging to a node, the route table can be simplified to&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 23746828 -- &amp;gt; server-a (37156400 hashes)
 60903228 -- &amp;gt; server-b (87553592 hashes)
148456820 -- &amp;gt; server-a (85098037 hashes)
233554857 -- &amp;gt; server-b (34880598 hashes)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;hr&gt;&lt;p&gt;What we achieved is remarkable, but there are still two problems. Let's have a look at a simple routing table for three nodes with 5 partitions each&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;3 nodes with 5 partitions each&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 23746828 --&amp;gt; server-a (23267855 hashes)
 47014683 --&amp;gt; server-c (10659758 hashes)
 57674441 --&amp;gt; server-a ( 3228787 hashes)
 60903228 --&amp;gt; server-b (63557309 hashes)
124460537 --&amp;gt; server-c (23996283 hashes)
148456820 --&amp;gt; server-a (31382512 hashes)
179839332 --&amp;gt; server-c (36411086 hashes)
216250418 --&amp;gt; server-a (17304439 hashes)
233554857 --&amp;gt; server-b (15386579 hashes)
248941436 --&amp;gt; server-c (13903087 hashes)
262844523 --&amp;gt; server-b ( 5590932 hashes)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;First, the lowest value is not 0, which means that there are some hashes (23,746,828 in this case) which are not served by any slot. Second, in general the distribution doesn't cover the space evenly, as some nodes receive too many keys compared to others. This second problem isn't actually visible in the setups I showed so far, but it becomes noticeable increasing the number of servers. For example, with two nodes we have this situation&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;2 nodes with 5 partitions each&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;server-a: 122254437 hashes
server-b: 146181018 hashes
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;while with 5 nodes it becomes&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;5 nodes with 5 partitions each&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;server-a: 64211359 hashes
server-b: 66179053 hashes
server-c: 57545779 hashes
server-d: 43217324 hashes
server-e: 37281940 hashes
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see, in the second case the load of &lt;code&gt;server-e&lt;/code&gt; is 56% that of &lt;code&gt;server-b&lt;/code&gt;.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;The first problem is easily solved assigning the initial hashes to the last node, that is considering the hash space mapped on a circle. This means that for 2 nodes with 5 partitions each we have&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;Routing table of 2 nodes with 5 partitions each&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Full routing table
&lt;span class="hll"&gt;        0 --&amp;gt; server-b-1 (23746828 hashes)
&lt;/span&gt; 23746828 --&amp;gt; server-a-4 (6848918 hashes)
 30595746 --&amp;gt; server-a-3 (27078695 hashes)
 57674441 --&amp;gt; server-a-1 (3228787 hashes)
 60903228 --&amp;gt; server-b-2 (17957108 hashes)
 78860336 --&amp;gt; server-b-0 (7773725 hashes)
 86634061 --&amp;gt; server-b-4 (61822759 hashes)
148456820 --&amp;gt; server-a-0 (67793598 hashes)
216250418 --&amp;gt; server-a-2 (17304439 hashes)
233554857 --&amp;gt; server-b-3 (29289666 hashes)
262844523 --&amp;gt; server-b-1 (5590932 hashes)

Simplified routing table
&lt;span class="hll"&gt;        0 -- &amp;gt; server-b (23746828 hashes)
&lt;/span&gt; 23746828 -- &amp;gt; server-a (37156400 hashes)
 60903228 -- &amp;gt; server-b (87553592 hashes)
148456820 -- &amp;gt; server-a (85098037 hashes)
233554857 -- &amp;gt; server-b (34880598 hashes)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;where the partition &lt;code&gt;server-b-1&lt;/code&gt; contains the orphaned initial hashes.&lt;/p&gt;&lt;p&gt;The second problem is a matter of statistical approach. The hash function that we use to map the partition name to the key space cannot be controlled, as its diffusion property has been designed to avoid a regular spacing of values. However, if we increase the number of partitions we expect the hash function to spread values across the whole space. At that point, each partition will be assigned just a tiny key space, and the differences between partitions will be less noticeable. In other words, by increasing the number of partitions dramatically we should achieve a better distribution. Let's compare the results of 5 nodes with 2 partitions each&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;5 nodes with 2 partitions each&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;server-a 36500586
server-b 76678431
server-c 31738329
server-d 56183426
server-e 67334683
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;with the results of 5 nodes with 3000 partitions each&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;5 nodes with 3000 partitions each&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;server-a 53385222
server-b 53855877
server-c 53755762
server-d 53597662
server-e 53840932
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;There is clearly an upper limit to the number of partitions that we can create. If we create more partitions than the possible number of hashes we will end up having empty ones and incurring routing errors as some of them will clash, but this is a purely theoretical case: using standard real hash functions we generate hashes of at least 160 bits, which means a codomain of 2&lt;sup&gt;160&lt;/sup&gt; possible values (more than 10&lt;sup&gt;48&lt;/sup&gt;). With 10,000 nodes (which is a considerable amount of servers in 2022) the threshold would be greater than 10&lt;sup&gt;44&lt;/sup&gt; partitions per server.&lt;/p&gt;&lt;p&gt;So far, we achieved great results, but we already managed to properly partition the space with simple techniques. The real power of consistent hashing is in the way it behaves in a dynamic setting.&lt;/p&gt;&lt;h2 id="consistent-hashing-and-scaling"&gt;Consistent hashing and scaling&lt;a class="headerlink" href="#consistent-hashing-and-scaling" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The interesting thing about consistent hashing is its amazing behaviour in a dynamic environment. As you might remember, the problem with hash partitioning was that a change in the number of nodes had ripple effects that resulted in a massive migration of at least half the keys.&lt;/p&gt;&lt;p&gt;With consistent hashing, when we add a new node we need to generate the hash values for that and put them in the routing table, and at that point we need to migrate the keys that fall under the domain of the newly created slots. Let's see an example before we discuss the performances.&lt;/p&gt;&lt;p&gt;The initial setup is 2 nodes with 5 partitions each&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;2 nodes with 5 partitions&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Full routing table
        0 --&amp;gt; server-b-1 (23746828 hashes)
 23746828 --&amp;gt; server-a-4 (6848918 hashes)
 30595746 --&amp;gt; server-a-3 (27078695 hashes)
 57674441 --&amp;gt; server-a-1 (3228787 hashes)
 60903228 --&amp;gt; server-b-2 (17957108 hashes)
 78860336 --&amp;gt; server-b-0 (7773725 hashes)
 86634061 --&amp;gt; server-b-4 (61822759 hashes)
148456820 --&amp;gt; server-a-0 (67793598 hashes)
216250418 --&amp;gt; server-a-2 (17304439 hashes)
233554857 --&amp;gt; server-b-3 (29289666 hashes)
262844523 --&amp;gt; server-b-1 (5590932 hashes)

Simplified routing table
        0 -- &amp;gt; server-b (23746828 hashes)
 23746828 -- &amp;gt; server-a (37156400 hashes)
 60903228 -- &amp;gt; server-b (87553592 hashes)
148456820 -- &amp;gt; server-a (85098037 hashes)
233554857 -- &amp;gt; server-b (34880598 hashes)

Stats
server-a 122254437
server-b 146181018

TOTAL HASHES: 268435455/268435455
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;if we add one node we migrate to this new setup&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;3 nodes with 5 partitions&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Full routing table
        0 --&amp;gt; server-b-1 (23746828 hashes)
 23746828 --&amp;gt; server-a-4 (6848918 hashes)
 30595746 --&amp;gt; server-a-3 (16418937 hashes)
 47014683 --&amp;gt; server-c-3 (10659758 hashes)
 57674441 --&amp;gt; server-a-1 (3228787 hashes)
 60903228 --&amp;gt; server-b-2 (17957108 hashes)
 78860336 --&amp;gt; server-b-0 (7773725 hashes)
 86634061 --&amp;gt; server-b-4 (37826476 hashes)
124460537 --&amp;gt; server-c-2 (23996283 hashes)
148456820 --&amp;gt; server-a-0 (31382512 hashes)
179839332 --&amp;gt; server-c-1 (25303093 hashes)
205142425 --&amp;gt; server-c-4 (11107993 hashes)
216250418 --&amp;gt; server-a-2 (17304439 hashes)
233554857 --&amp;gt; server-b-3 (15386579 hashes)
248941436 --&amp;gt; server-c-0 (13903087 hashes)
262844523 --&amp;gt; server-b-1 (5590932 hashes)

Simplified routing table
        0 -- &amp;gt; server-b (23746828 hashes)
 23746828 -- &amp;gt; server-a (23267855 hashes)
 47014683 -- &amp;gt; server-c (10659758 hashes)
 57674441 -- &amp;gt; server-a ( 3228787 hashes)
 60903228 -- &amp;gt; server-b (63557309 hashes)
124460537 -- &amp;gt; server-c (23996283 hashes)
148456820 -- &amp;gt; server-a (31382512 hashes)
179839332 -- &amp;gt; server-c (36411086 hashes)
216250418 -- &amp;gt; server-a (17304439 hashes)
233554857 -- &amp;gt; server-b (15386579 hashes)
248941436 -- &amp;gt; server-c (13903087 hashes)
262844523 -- &amp;gt; server-b ( 5590932 hashes)

Stats
server-a 75183593
server-b 108281648
server-c 84970214

TOTAL HASHES: 268435455/268435455
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Let's have a closer look to what happens with &lt;code&gt;server-c&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Simplified routing table
        0 -- &amp;gt; server-b (23746828 hashes)
 23746828 -- &amp;gt; server-a (23267855 hashes) ----+ 10659758 hashes
                                              | from server-a
 47014683 -- &amp;gt; server-c (10659758 hashes) &amp;lt;---+
 57674441 -- &amp;gt; server-a ( 3228787 hashes)
 60903228 -- &amp;gt; server-b (63557309 hashes) ----+ 23996283 hashes
                                              | from server-b
124460537 -- &amp;gt; server-c (23996283 hashes) &amp;lt;---+
148456820 -- &amp;gt; server-a (31382512 hashes) ----+ 36411086 hashes
                                              | from server-a
179839332 -- &amp;gt; server-c (36411086 hashes) &amp;lt;---+
216250418 -- &amp;gt; server-a (17304439 hashes)
233554857 -- &amp;gt; server-b (15386579 hashes) ----+ 13903087 hashes
                                              | from server-b
248941436 -- &amp;gt; server-c (13903087 hashes) &amp;lt;---+
262844523 -- &amp;gt; server-b ( 5590932 hashes)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Globally, &lt;code&gt;server-c&lt;/code&gt; receives 47,070,844 hashes from &lt;code&gt;server-a&lt;/code&gt; and 37,899,370 hashes from &lt;code&gt;server-b&lt;/code&gt;, which results in a migration of approximately 30% of the total hashes. As you can see there is no ripple effect here, as the boundaries of the existing partitions do not change.&lt;/p&gt;&lt;p&gt;Let's consider the performances in the worst case when we add one single node. If we are terribly unlucky (and we use a hash function with clear issues) each partition of the new node will cover completely a partition of an existing node. Assuming that the initial setup with N nodes created a balanced cluster, each node contains 1/Nth of the total keys, and in the worst case we need to move all of them from an existing node to the newly added one.&lt;/p&gt;&lt;p&gt;So, adding one node to a cluster of N nodes using consistent hashing results, in the worst case, in the migration of 1/Nth of the keys. In the previous example, then, we expected to migrate &lt;em&gt;at most&lt;/em&gt; 50% of the keys (1/2), and we ended up migrating 30$ of them.&lt;/p&gt;&lt;p&gt;This is a terrific result. Not only it's much better than the previous one (&lt;em&gt;at least&lt;/em&gt; 50% of the keys), but it gets better increasing the size of the cluster. In a cluster with 100 nodes, adding a node will result (in the worst case!) in the migration of 1/100 of the keys.&lt;/p&gt;&lt;h2 id="source-code"&gt;Source code&lt;a class="headerlink" href="#source-code" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;All routing tables shown in the post have been created with the following Python script. Please bear in mind that this is just demo code, so things haven't been optimised or designed particularly well. Feel free to change the hash function and the parameters of the script to experiment and see what consistent hashing can do.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;consistent&lt;em&gt;hashing&lt;/em&gt;demo.py&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hashlib&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;itemgetter&lt;/span&gt;

&lt;span class="n"&gt;NUM_NODES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;NUM_PARTITIONS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hash_name&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;encoded_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;hash_encoded_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hashlib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sha1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encoded_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hexdigest&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hash_encoded_name&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_partitions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;partitions&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;partition_hashes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;partition_number&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partitions&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;partition_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;node_name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;-&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;partition_number&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;partition_hash&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hash_name&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partition_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;partition_hashes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;partition_hash&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="s2"&gt;&amp;quot;partition_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;partition_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;node_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;partition_hashes&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_routing_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;partitions&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;node_name&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;node_names&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;create_partitions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;partitions&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;itemgetter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;NUM_NODES&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ascii_lowercase&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Too many servers&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;nodes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;server-&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ascii_lowercase&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;NUM_NODES&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;

&lt;span class="n"&gt;routing_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_routing_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nodes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NUM_PARTITIONS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;routing_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;partition_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;routing_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;partition_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;routing_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;routing_table&lt;/span&gt;

&lt;span class="n"&gt;routing_table_shift&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;routing_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mh"&gt;0xFFFFFFF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;partition_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;END&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;full_routing_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;routing_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;routing_table_shift&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;full_routing_table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;partition_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;partition_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Full routing table&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;full_routing_table&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;9&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt; --&amp;gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;partition_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt; (&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt; hashes)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;grouped_routing_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;itertools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;full_routing_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;itemgetter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="n"&gt;simplified_routing_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;grouped_routing_table&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;consecutive_partitions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;simplified_routing_table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;consecutive_partitions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;consecutive_partitions&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Simplified routing table&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;simplified_routing_table&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;min_hash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;9&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt; -- &amp;gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt; (&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;8&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt; hashes)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Stats&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;stats&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;nodes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;slots&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;simplified_routing_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;total_hashes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;slots&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;total_hashes&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;node_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;total_hashes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;served_hashes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;TOTAL HASHES: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;total_hashes&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="final-words"&gt;Final words&lt;a class="headerlink" href="#final-words" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I hope this long post was useful to introduce you to the topic of partitioning and in general to system design. As I mentioned, such concepts are currently in use by well-known systems, and still discussed as none of them is perfect, so it is worth understanding the fundamental issues before adopting a specific solution.&lt;/p&gt;&lt;h2 id="resources"&gt;Resources&lt;a class="headerlink" href="#resources" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;Martin Kleppmann, &lt;em&gt;Designing Data-Intensive Applications&lt;/em&gt;, Chapter 6 "Partitioning", O’Reilly 2017 &lt;a href="https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/"&gt;official site&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;The &lt;a href="https://en.wikipedia.org/wiki/Consistent_hashing"&gt;Wikipedia article&lt;/a&gt; about consistent hashing.&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.toptal.com/big-data/consistent-hashing"&gt;A Guide to Consistent Hashing&lt;/a&gt; by Juan Pablo Carzolio.&lt;/li&gt;&lt;li&gt;The &lt;a href="https://www.cs.princeton.edu/courses/archive/fall09/cos518/papers/chash.pdf"&gt;original article&lt;/a&gt; by David Karger et al.: "Consistent Hashing and Random Trees: Distributed Caching protocols for Relieving Hot Spots ont the World Wide Web".&lt;/li&gt;&lt;li&gt;An &lt;a href="https://arxiv.org/pdf/1406.2294.pdf"&gt;alternative algorithm&lt;/a&gt; by John Lamping and Eric Veach: "A Fast, Minimal Memory, Consistent Hash Algorithm".&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;&lt;p&gt;Photo by &lt;a href="https://unsplash.com/@alexlvrs?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Alex Lvrs&lt;/a&gt; on &lt;a href="https://unsplash.com/s/photos/cake?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Unsplash&lt;/a&gt;.&lt;/p&gt;</content><category term="Programming"></category><category term="algorithms"></category><category term="architectures"></category><category term="big data"></category><category term="cryptography"></category><category term="devops"></category><category term="distributed systems"></category><category term="Python"></category></entry><entry><title>From Docker CLI to Docker Compose</title><link href="https://www.thedigitalcatonline.com/blog/2022/02/19/from-docker-cli-to-docker-compose/" rel="alternate"></link><published>2022-02-19T15:00:00+01:00</published><updated>2022-03-17T10:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2022-02-19:/blog/2022/02/19/from-docker-cli-to-docker-compose/</id><summary type="html">&lt;p&gt; A hands-on post that shows how to build a system with Docker and which problems Docker Compose solves&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post I will show you how and why Docker Compose is useful, building a simple application written in Python that uses PostgreSQL. I think it is worth going through such an exercise to see how technologies that we might be already familiar with actually simplify workflows that would otherwise definitely be more complicated.&lt;/p&gt;&lt;p&gt;The name of the demo application I will develop is a very unimaginative &lt;code&gt;whale&lt;/code&gt;, that shouldn't clash with any other name introduced by the tools I will use. Every time you see something with &lt;code&gt;whale&lt;/code&gt; in it you know that I am referring to a value that you can change according to your setup.&lt;/p&gt;&lt;p&gt;Before we start, please create a directory to host all the files we will create. I will refer to this directory as the "project directory". &lt;/p&gt;&lt;h2 id="postgresql"&gt;PostgreSQL&lt;a class="headerlink" href="#postgresql" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Since the application will connect to a PostgreSQL database the first thing we can explore is how to run that in a Docker container.&lt;/p&gt;&lt;p&gt;The official Postgres image can be found &lt;a href="https://hub.docker.com/_/postgres"&gt;here&lt;/a&gt;, and I highly recommend taking the time to properly read the documentation, as it contains a myriad of details that you should be familiar with.&lt;/p&gt;&lt;p&gt;For the time being, let's focus on the environment variables that the image requires you to set.&lt;/p&gt;&lt;h3 id="password"&gt;Password&lt;/h3&gt;&lt;p&gt;The first variable is &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt;, which is the only mandatory configuration value (unless you disable authentication which is not recommended). Indeed, if you run the image without setting this value, you get this message&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run postgres
Error: Database is uninitialized and superuser password is not specified.
       You must specify POSTGRES_PASSWORD to a non-empty value for the
       superuser. For example, &amp;quot;-e POSTGRES_PASSWORD=password&amp;quot; on &amp;quot;docker run&amp;quot;.

       You may also use &amp;quot;POSTGRES_HOST_AUTH_METHOD=trust&amp;quot; to allow all
       connections without a password. This is *not* recommended.

       See PostgreSQL documentation about &amp;quot;trust&amp;quot;:
       https://www.postgresql.org/docs/current/auth-trust.html
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This value is very interesting because it's a secret. So, while I will treat it as a simple configuration value in the first stages of the setup, later we will need to discuss how to manage it properly.&lt;/p&gt;&lt;h3 id="superuser"&gt;Superuser&lt;/h3&gt;&lt;p&gt;Being a production-grade database, Postgres allows you to specify users, groups, and permissions in a fine-grained fashion. I won't go into that as it's usually more a matter of database administration and application development, but we need to define at least the superuser. The default value for this image is &lt;code&gt;postgres&lt;/code&gt;, but you can change it setting &lt;code&gt;POSTGRES_USER&lt;/code&gt;.&lt;/p&gt;&lt;h3 id="database-name"&gt;Database name&lt;/h3&gt;&lt;p&gt;If you do not specify the value of &lt;code&gt;POSTGRES_DB&lt;/code&gt;, this image will create a default database with the name of the superuser.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;A note of warning here. If you omit both the database name and the user you will end up with the superuser &lt;code&gt;postgres&lt;/code&gt; and database &lt;code&gt;postgres&lt;/code&gt;. The &lt;a href="https://www.postgresql.org/docs/current/creating-cluster.html"&gt;official documentation&lt;/a&gt; states that&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;After initialization, a database cluster will contain a database named
postgres, which is meant as a default database for use by utilities,
users and third party applications. The database server itself does not
require the postgres database to exist, but many external utility programs
assume it exists.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This mean that it is not ideal to use that as the database for our application. So, unless you are just trying out a quick piece of code, my recommendation is to always configure all three values: &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt;, &lt;code&gt;POSTGRES_USER&lt;/code&gt;, and &lt;code&gt;POSTGRES_DB&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;We can run the image with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -d \
  -e POSTGRES_PASSWORD=whale_password \
  -e POSTGRES_DB=whale_db \
  -e POSTGRES_USER=whale_user \
  postgres:13
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see I run the image in &lt;a href="https://docs.docker.com/engine/reference/run/#detached--d"&gt;detached mode&lt;/a&gt;. This image is not meant to be interactive, as Postgres is by it's very nature a daemon. To connect in an interactive way we need to use the tool &lt;code&gt;psql&lt;/code&gt;, which is provided by this image. Please note that I'm running &lt;code&gt;postgres:13&lt;/code&gt; only to keep the post consistent with what you will see if you read it in the future, you are clearly free to use any version of the engine.&lt;/p&gt;&lt;p&gt;The ID of the container is returned by &lt;code&gt;docker run&lt;/code&gt; but we can retrieve it any time running &lt;code&gt;docker ps&lt;/code&gt;. Using IDs is however pretty complicated, and looking at the command history is not immediately clear what you have been doing at a certain point in time. For this reason, it's a good idea to name the containers.&lt;/p&gt;&lt;p&gt;Stop the previous container and run it again with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -d \
  --name whale-postgres \
  -e POSTGRES_PASSWORD=whale_password \
  -e POSTGRES_DB=whale_db \
  -e POSTGRES_USER=whale_user \
  postgres:13
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div class="infobox"&gt;&lt;i class="fa fa-info-circle"&gt;&lt;/i&gt;&lt;div class="title"&gt;Stopping containers&lt;/div&gt;&lt;div&gt;&lt;p&gt;You can stop containers using &lt;code&gt;docker stop ID&lt;/code&gt;. This &lt;a href="https://docs.docker.com/engine/reference/commandline/stop/#extended-description"&gt;gives containers a grace period&lt;/a&gt; to react to the &lt;code&gt;SIGTERM&lt;/code&gt; signal, for example to properly close files and terminate connections, and then terminates it with &lt;code&gt;SIGKILL&lt;/code&gt;. You can also force it to stop unconditionally using &lt;code&gt;docker kill ID&lt;/code&gt; which sends &lt;code&gt;SIGKILL&lt;/code&gt; immediately.&lt;/p&gt;
&lt;p&gt;In either case, however, you might want to remove the container, that otherwise will be kept indefinitely by Docker. This can become a problem when containers are named, as you can't reuse a name that is currently assigned to a container.&lt;/p&gt;
&lt;p&gt;To remove a container you have to run &lt;code&gt;docker rm ID&lt;/code&gt;, but you can leverage the fact that both &lt;code&gt;docker stop&lt;/code&gt; and &lt;code&gt;docker kill&lt;/code&gt; return the ID of the container to pipe the termination and the removal&lt;/p&gt;
&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker stop ID | xargs docker rm
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Otherwise, you can use &lt;code&gt;docker rm -f ID&lt;/code&gt;, which corresponds to &lt;code&gt;docker kill&lt;/code&gt; followed by &lt;code&gt;docker rm&lt;/code&gt;. If you name a container, however, you can use its name instead of the ID.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;hr&gt;&lt;p&gt;Now we can connect to the database using the executable &lt;code&gt;psql&lt;/code&gt; provided in the image itself. To execute a command inside a container we use &lt;code&gt;docker exec&lt;/code&gt; and this time we will specify &lt;code&gt;-it&lt;/code&gt; to open an interactive session. &lt;code&gt;psql&lt;/code&gt; uses by default the user name &lt;code&gt;root&lt;/code&gt;, and the database with the same name as the user, so we need to specify both. The header informs me that the image is running PostgreSQL 13.5 on Debian.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker exec -it whale-postgres psql -U whale_user whale_db
psql (13.5 (Debian 13.5-1.pgdg110+1))
Type &amp;quot;help&amp;quot; for help.

whale_db=# 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div class="infobox"&gt;&lt;i class="fa fa-info-circle"&gt;&lt;/i&gt;&lt;div class="title"&gt;Postgres trust&lt;/div&gt;&lt;div&gt;&lt;p&gt;You might be surprised by the fact that &lt;code&gt;psql&lt;/code&gt; didn't ask for the password that we set when we run the container. This happens because the server trusts local connections, and when we run &lt;code&gt;psql&lt;/code&gt; inside the container we are on &lt;code&gt;localhost&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you are curious about trust in Postgres you can see the configuration file with&lt;/p&gt;
&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker exec -it whale-postgres \
  cat /var/lib/postgresql/data/pg_hba.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where you can spot the lines&lt;/p&gt;
&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# TYPE  DATABASE  USER  ADDRESS  METHOD

# &amp;quot;local&amp;quot; is for Unix domain socket connections only
local   all       all            trust
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You can find more information about Postgres trust in &lt;a href="https://www.postgresql.org/docs/current/auth-trust.html"&gt;the official documentation&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Here, I can list all the databases with &lt;code&gt;\l&lt;/code&gt;. You can see all &lt;code&gt;psql&lt;/code&gt; commands and the rest of the documentation at &lt;a href="https://www.postgresql.org/docs/current/app-psql.html"&gt;https://www.postgresql.org/docs/current/app-psql.html&lt;/a&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker exec -it whale-postgres psql -U whale_user whale_db
psql (13.5 (Debian 13.5-1.pgdg110+1))
Type &amp;quot;help&amp;quot; for help.

whale_db=# \l
                                    List of databases
   Name    |   Owner    | Encoding |  Collate   |   Ctype    |     Access privileges     
-----------+------------+----------+------------+------------+---------------------------
 postgres  | whale_user | UTF8     | en_US.utf8 | en_US.utf8 | 
 template0 | whale_user | UTF8     | en_US.utf8 | en_US.utf8 | =c/whale_user            +
           |            |          |            |            | whale_user=CTc/whale_user
 template1 | whale_user | UTF8     | en_US.utf8 | en_US.utf8 | =c/whale_user            +
           |            |          |            |            | whale_user=CTc/whale_user
 whale_db  | whale_user | UTF8     | en_US.utf8 | en_US.utf8 | 
(4 rows)

whale_db=# 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see, the database called &lt;code&gt;postgres&lt;/code&gt; has been created as part of the initialisation, as clarified previously. You can exit &lt;code&gt;psql&lt;/code&gt; with &lt;code&gt;Ctrl-D&lt;/code&gt; or &lt;code&gt;\q&lt;/code&gt;.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;If we want the database to be accessible from outside we need to publish a port. The image &lt;strong&gt;exposes&lt;/strong&gt; port 5432 (see the &lt;a href="https://github.com/docker-library/postgres/blob/master/13/alpine/Dockerfile#L190"&gt;source code&lt;/a&gt;), which tells us where the server is listening. To &lt;strong&gt;publish&lt;/strong&gt; the port towards the host system we can add &lt;code&gt;-p 5432:5432&lt;/code&gt;. Please remember that exposing a port in Docker basically means to add some metadata that informs the user of the image, but doesn't affect the way it runs.&lt;/p&gt;&lt;p&gt;Stop the container (you can use its name now) and run it again with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -d \
  --name whale-postgres \
  -e POSTGRES_PASSWORD=whale_password \
  -e POSTGRES_DB=whale_db \
  -e POSTGRES_USER=whale_user \
  -p 5432:5432 postgres:13
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Running &lt;code&gt;docker ps&lt;/code&gt; we can see that the container publishes the port now (&lt;code&gt;0.0.0.0:5432-&amp;gt;5432/tcp&lt;/code&gt;). We can double-check it with &lt;code&gt;ss&lt;/code&gt; ("socket statistics")&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ss -nulpt | grep 5432
tcp  LISTEN  0  4096  0.0.0.0:5432  0.0.0.0:*
tcp  LISTEN  0  4096     [::]:5432     [::]:*
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that usually &lt;code&gt;ss&lt;/code&gt; won't tell you the name of the process using that port because the process is run by &lt;code&gt;root&lt;/code&gt;. If you run &lt;code&gt;ss&lt;/code&gt; with &lt;code&gt;sudo&lt;/code&gt; you will see it&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo ss -nulpt | grep 5432
tcp  LISTEN  0  4096  0.0.0.0:5432  0.0.0.0:*  users:((&amp;quot;docker-proxy&amp;quot;,pid=1262717,fd=4))
tcp  LISTEN  0  4096     [::]:5432     [::]:*  users:((&amp;quot;docker-proxy&amp;quot;,pid=1262724,fd=4))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Unfortunately, &lt;code&gt;ss&lt;/code&gt; is not available on macOS. On that platform (and on Linux as well) you can use &lt;code&gt;lsof&lt;/code&gt; with &lt;code&gt;grep&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo lsof -i -p -n | grep 5432
docker-pr 219643            root    4u  IPv4 2945982      0t0  TCP *:5432 (LISTEN)
docker-pr 219650            root    4u  IPv6 2952986      0t0  TCP *:5432 (LISTEN)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;or directly using the option &lt;code&gt;-i&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo lsof -i :5432
COMMAND      PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME
docker-pr 219643 root    4u  IPv4 2945982      0t0  TCP *:postgresql (LISTEN)
docker-pr 219650 root    4u  IPv6 2952986      0t0  TCP *:postgresql (LISTEN)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that &lt;code&gt;docker-pr&lt;/code&gt; in the output above is just &lt;code&gt;docker-proxy&lt;/code&gt; truncated, matching what we saw with &lt;code&gt;ss&lt;/code&gt; previously.&lt;/p&gt;&lt;p&gt;If you want to publish the container's port 5432 to a different port on the host you can just use &lt;code&gt;-p ANY_NUMBER:5432&lt;/code&gt;. Remember however that port numbers under 1024 are &lt;em&gt;privileged&lt;/em&gt; or &lt;em&gt;well-known&lt;/em&gt;, which means that they are assigned by default to specific services (&lt;a href="https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers#Well-known_ports"&gt;listed here&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;This means that in theory you can use &lt;code&gt;-p 80:5432&lt;/code&gt; for your database container, exposing it on port 80 of your host. In practice this will result in a lot of headaches and a bunch of developers chasing you with spikes and shovels.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Now that we exposed a port we can connect to the database running &lt;code&gt;psql&lt;/code&gt; in an ephemeral container. "Ephemeral" means that a resource (in this case a Docker container) is run just for the time necessary to serve a specific purpose, as opposed to "permanent". This way we can simulate someone that tries to connect to the Docker container from a different computer on the network.&lt;/p&gt;&lt;p&gt;Since &lt;code&gt;psql&lt;/code&gt; is provided by the image &lt;code&gt;postgres&lt;/code&gt; we can in theory run that passing the hostname with &lt;code&gt;-h localhost&lt;/code&gt;, but if you try it you will be disappointed.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -it postgres:13 psql -h localhost -U whale_user whale_db
psql: error: connection to server at &amp;quot;localhost&amp;quot; (127.0.0.1), port 5432 failed: Connection refused
        Is the server running on that host and accepting TCP/IP connections?
connection to server at &amp;quot;localhost&amp;quot; (::1), port 5432 failed: Cannot assign requested address
        Is the server running on that host and accepting TCP/IP connections?
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This is correct, as that container runs in a bridge network where &lt;code&gt;localhost&lt;/code&gt; is the container itself. To make it work we need to run the container as part of the host network (that is the same network our computer is running on). This can be done with &lt;code&gt;--network=host&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -it \
  --network=host postgres:13 \
  psql -h localhost -U whale_user whale_db
Password for user whale_user: 
psql (13.5 (Debian 13.5-1.pgdg110+1))
Type &amp;quot;help&amp;quot; for help.

whale_db=#
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that now &lt;code&gt;psql&lt;/code&gt; asks for a password (that you know because you set it when we run the container &lt;code&gt;whale-postgres&lt;/code&gt;). This happens because the tool is not run on the same node as the database server any more, so PostgreSQL doesn't trust it.&lt;/p&gt;&lt;h2 id="volumes"&gt;Volumes&lt;a class="headerlink" href="#volumes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;If we used a structured framework in Python, we could leverage an ORM like SQLAlchemy to map classes to database tables. The model definitions (or changes) can be captured into little scripts called migrations that are applied to the database, and those can also be used to insert some initial data. For this example I will go a simpler route, that is to initialise the database using SQL directly.&lt;/p&gt;&lt;p&gt;I do not recommend this approach for a real project but it should be good enough in this case. In particular, it will allow me to demonstrate how to use volumes in Docker.&lt;/p&gt;&lt;p&gt;Make sure the container &lt;code&gt;whale-postgres&lt;/code&gt; is running (with or without publishing the port, it's not important at the moment). Connect to the container using &lt;code&gt;psql&lt;/code&gt; and run the following two SQL commands (make sure you are connected to the database &lt;code&gt;whale_db&lt;/code&gt;)&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;CREATE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;TABLE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recipes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;recipe_id&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;NOT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;recipe_name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;VARCHAR&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;NOT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;PRIMARY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;KEY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recipe_id&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;UNIQUE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recipe_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;INSERT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;INTO&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recipes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recipe_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recipe_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="k"&gt;VALUES&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Tacos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Tomato Soup&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Grilled Cheese&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This code creates a table called &lt;code&gt;recipes&lt;/code&gt; and inserts 3 rows with an &lt;code&gt;id&lt;/code&gt; and a &lt;code&gt;name&lt;/code&gt;. The output of the above commands should be&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;CREATE TABLE
INSERT 0 3
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can double check that the database contains the table with &lt;code&gt;\dt&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;whale_db=# \dt
           List of relations
 Schema |  Name   | Type  |   Owner    
--------+---------+-------+------------
 public | recipes | table | whale_user
(1 row)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;and that the table contains three rows with a &lt;code&gt;select&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;whale_db=# select * from recipes;
 recipe_id |  recipe_name   
-----------+----------------
         1 | Tacos
         2 | Tomato Soup
         3 | Grilled Cheese
(3 rows)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Now, the problem with containers is that they do not store data permanently. While the container is running there are no issues, as a matter of fact you can terminate &lt;code&gt;psql&lt;/code&gt;, connect, and run the &lt;code&gt;select&lt;/code&gt; again, and you will see the same data.&lt;/p&gt;&lt;p&gt;If we stop the container and run it again, though, we will quickly realise that the values stored in the database are gone.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker stop whale-postgres | xargs docker rm 
whale-postgres

$ docker run -d \
  --name whale-postgres \
  -e POSTGRES_PASSWORD=whale_password \
  -e POSTGRES_DB=whale_db \
  -e POSTGRES_USER=whale_user \
  -p 5432:5432 postgres:13
4a647ebef78e32bb4733484a6e435780e17a69b643e872613ca50115d60d54ce

$ docker exec -it whale-postgres \
  psql -U whale_user whale_db -c &amp;quot;select * from recipes&amp;quot;
ERROR:  relation &amp;quot;recipes&amp;quot; does not exist
LINE 1: select * from recipes
                      ^
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;hr&gt;&lt;p&gt;Containers have been created with isolation in mind, which is why by default nothing of what happens inside the container is connected with the host and is preserved when the container is destroyed.&lt;/p&gt;&lt;p&gt;As happened with ports, however, we need to establish some communication between containers and the host system, and we also want to keep data after the container has been destroyed. The solution in Docker is to use volumes.&lt;/p&gt;&lt;p&gt;There are three types of volumes in Docker: &lt;em&gt;host&lt;/em&gt;, &lt;em&gt;anonymous&lt;/em&gt;, and &lt;em&gt;named&lt;/em&gt;. Host volumes are a way to mount inside the container a path on the host's filesystem, and while they are useful to exchange data between the host and the container, they also often have permissions issues. Generally speaking, containers define users whose IDs are not mapped to the host's ones, which means that the files written by the container might end up belonging to non-existing users.&lt;/p&gt;&lt;p&gt;Anonymous and named volumes are simply virtual filesystems created and managed independently from containers. These can be connected with a running container so the latter can use the data contained in them and store data that will survive its termination. The only difference between named an anonymous volumes is the name that allows you to easily manage them. For this reason, I think it's not really useful to consider anonymous volumes, which is why I will focus on named ones.&lt;/p&gt;&lt;p&gt;You can manage volumes using &lt;code&gt;docker volume&lt;/code&gt;, that provides several subcommands such as &lt;code&gt;create&lt;/code&gt;, and &lt;code&gt;rm&lt;/code&gt;. You can then &lt;a href="https://docs.docker.com/engine/reference/run/#volume-shared-filesystems"&gt;attach a named volume to a container&lt;/a&gt; when you run it using the option &lt;code&gt;-v&lt;/code&gt; of &lt;code&gt;docker run&lt;/code&gt;. This creates the volume if it's not already existing, so this is the standard way many of us create a volume.&lt;/p&gt;&lt;p&gt;Stop and remove the running Postgres container and run it again with a named volume&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker stop whale-postgres | xargs docker rm 
$ docker run -d \
  --name whale-postgres \
  -e POSTGRES_PASSWORD=whale_password \
  -e POSTGRES_DB=whale_db \
  -e POSTGRES_USER=whale_user \
  -p 5432:5432 \
  -v whale_dbdata:/var/lib/postgresql/data \
  postgres:13
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This will create the volume named &lt;code&gt;whale_dbdata&lt;/code&gt; and connect it to the path &lt;code&gt;/var/lib/postgresql/data&lt;/code&gt; in the container that we are running. That path happens to be the one where Postgres stores the actual database, as you can see from &lt;a href="https://www.postgresql.org/docs/current/storage-file-layout.html"&gt;the official documentation&lt;/a&gt;. There is a specific reason why I used the prefix &lt;code&gt;whale_&lt;/code&gt; for the name of the volume, which will be clear later when we will introduce Docker Compose.&lt;/p&gt;&lt;p&gt;&lt;code&gt;docker ps&lt;/code&gt; doesn't give any information on volumes, so to see what is connected to your container you need to use &lt;code&gt;docker inspect&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker inspect whale-postgres 
[...]
        &amp;quot;Mounts&amp;quot;: [
            {
                &amp;quot;Type&amp;quot;: &amp;quot;volume&amp;quot;,
                &amp;quot;Name&amp;quot;: &amp;quot;whale_dbdata&amp;quot;,
                &amp;quot;Source&amp;quot;: &amp;quot;/var/lib/docker/volumes/whale_dbdata/_data&amp;quot;,
                &amp;quot;Destination&amp;quot;: &amp;quot;/var/lib/postgresql/data&amp;quot;,
                &amp;quot;Driver&amp;quot;: &amp;quot;local&amp;quot;,
                &amp;quot;Mode&amp;quot;: &amp;quot;z&amp;quot;,
                &amp;quot;RW&amp;quot;: true,
                &amp;quot;Propagation&amp;quot;: &amp;quot;&amp;quot;
            }
        ],
[...]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The value for &lt;code&gt;&amp;quot;Source&amp;quot;&lt;/code&gt; is where the volume is stored in the host, that is on your computer, but generally speaking you can ignore that detail. You can see all volumes using &lt;code&gt;docker volume ls&lt;/code&gt; (using &lt;code&gt;grep&lt;/code&gt; if the list is long as it is in my case)&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker volume ls | grep whale
local     whale_dbdata
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Now that the container is running and is connected to a volume, we can try to initialise the database again. Connect with &lt;code&gt;psql&lt;/code&gt; using the command line we developed before and run the SQL commands that create the table &lt;code&gt;recipes&lt;/code&gt; and insert three rows.&lt;/p&gt;&lt;p&gt;The whole point of using a volume is to make information permanent, so now terminate and remove the Postgres container, and run it again using the same volume. You can check that the database still contains data using the query shown previously.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker rm -f whale-postgres 
whale-postgres
$ docker run -d \
  --name whale-postgres \
  -e POSTGRES_PASSWORD=whale_password \
  -e POSTGRES_DB=whale_db \
  -e POSTGRES_USER=whale_user \
  -p 5432:5432 \
  -v whale_dbdata:/var/lib/postgresql/data \
  postgres:13
893378f044204e5c1a87473a038b615a08ad08e5da9225002a470caeac8674a8
$ docker exec -it whale-postgres \
  psql -U whale_user whale_db \
  -c &amp;quot;select * from recipes&amp;quot;
 recipe_id |  recipe_name   
-----------+----------------
         1 | Tacos
         2 | Tomato Soup
         3 | Grilled Cheese
(3 rows)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="python-application"&gt;Python application&lt;a class="headerlink" href="#python-application" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Great! Now that we have a database that can be restarted without losing data we can create a Python application that interacts with it. Again, please remember that the goal of this post is to show what container orchestration is and how Docker compose can simplify it, so the application developed in this section is absolutely minimal.&lt;/p&gt;&lt;p&gt;I will first create an application and run it in the host, leveraging the port exposed by the container to connect to the database. Later, I will move the application in its own container.&lt;/p&gt;&lt;p&gt;To create the application, first create a Python virtual environment using your preferred method. I currently use &lt;code&gt;pyenv&lt;/code&gt; (&lt;a href="https://github.com/pyenv/pyenv"&gt;https://github.com/pyenv/pyenv&lt;/a&gt;).&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pyenv virtualenv whale_docker
pyenv activate whale_docker
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Now we need to put our requirements in a file and install them. I prefer to keep things tidy from day zero, so create the directory &lt;code&gt;whaleapp&lt;/code&gt; in the project directory and inside it the file &lt;code&gt;requirements.txt&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mkdir whaleapp
touch whaleapp/requirements.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The only requirement we have for this simple application is &lt;code&gt;psycopg2&lt;/code&gt;, so I add it to the file and then install it. Since we are installing requirements is useful to update &lt;code&gt;pip&lt;/code&gt; as well.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;echo &amp;quot;psycopg2&amp;quot; &amp;gt;&amp;gt; whaleapp/requirements.txt
pip install -U pip
pip install -r whaleapp/requirements.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;hr&gt;&lt;p&gt;Now create the file &lt;code&gt;whaleapp/whaleapp.py&lt;/code&gt; and put this code in it&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;whaleapp/whaleapp.py&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;psycopg2&lt;/span&gt;

&lt;span class="n"&gt;connection_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="callout"&gt;1&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;localhost&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;database&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;whale_db&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;whale_user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;password&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;whale_password&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;

        &lt;span class="c1"&gt;# Connect to the PostgreSQL server&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Connecting to the PostgreSQL database...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;psycopg2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;connection_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="callout"&gt;2&lt;/span&gt;

        &lt;span class="c1"&gt;# Create a cursor&lt;/span&gt;
        &lt;span class="n"&gt;cur&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="c1"&gt;# Execute the query&lt;/span&gt;
        &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;select * from recipes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="callout"&gt;3&lt;/span&gt;

        &lt;span class="c1"&gt;# Fetch all results&lt;/span&gt;
        &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetchall&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="callout"&gt;4&lt;/span&gt;

        &lt;span class="c1"&gt;# Close the connection&lt;/span&gt;
        &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;psycopg2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DatabaseError&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;finally&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="callout"&gt;5&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Database connection closed.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Wait three seconds&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see the code is not complicated. The application is an endless &lt;code&gt;while&lt;/code&gt; loop that every 3 seconds establishes a connection with the DB &lt;span class="callout"&gt;2&lt;/span&gt; using the configuration in &lt;span class="callout"&gt;1&lt;/span&gt;. After this, the query &lt;code&gt;select * from recipes&lt;/code&gt; is run &lt;span class="callout"&gt;3&lt;/span&gt; , all the results are printed on the standard output &lt;span class="callout"&gt;4&lt;/span&gt;, and the connection is closed &lt;span class="callout"&gt;5&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;If the Postgres container is running and publishing port 5432, this application can be run directly on the host&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python whaleapp.py 
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;and will go on indefinitely until we press &lt;code&gt;Ctrl-C&lt;/code&gt; to stop it.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;For the same reasons of isolation and security that we discussed previously, we want to run the application in a Docker container. This can be done pretty easily, but we will run into the same issues that we had when we where trying to run &lt;code&gt;psql&lt;/code&gt; in a separate container. At the moment, the application tries to connect to the database on &lt;code&gt;localhost&lt;/code&gt;, which is fine while the application is running on the host directly, but won't work any more once that is transported into a Docker container.&lt;/p&gt;&lt;p&gt;To face one problem at a time, let's first containerise the application and run it using the &lt;code&gt;host&lt;/code&gt; network. Once this works, we can see how to solve the communication problem between containers.&lt;/p&gt;&lt;p&gt;The easiest way to containerise a Python application is to create a new image starting from the image &lt;code&gt;python:3&lt;/code&gt;. The following &lt;code&gt;Dockerfile&lt;/code&gt; goes into the application directory&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;whaleapp/Dockerfile&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;python:3&lt;/span&gt; &lt;span class="callout"&gt;1&lt;/span&gt;

&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/usr/src/app&lt;/span&gt; &lt;span class="callout"&gt;2&lt;/span&gt;

&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;requirements.txt . &lt;span class="callout"&gt;3&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pip install --no-cache-dir -r requirements.txt &lt;span class="callout"&gt;4&lt;/span&gt;

&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;. . &lt;span class="callout"&gt;5&lt;/span&gt;

&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;python&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-u&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;./whaleapp.py&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="callout"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;A Docker file contains the description of the layers that build an image. Here, we start from the official Python 3 image &lt;span class="callout"&gt;1&lt;/span&gt; (&lt;a href="https://hub.docker.com/_/python"&gt;https://hub.docker.com/_/python&lt;/a&gt;), set a working directory &lt;span class="callout"&gt;2&lt;/span&gt;, copy the requirements file &lt;span class="callout"&gt;3&lt;/span&gt; and install the requirements &lt;span class="callout"&gt;4&lt;/span&gt;, then copy the rest of the application &lt;span class="callout"&gt;5&lt;/span&gt;, and run the application &lt;span class="callout"&gt;6&lt;/span&gt;. The Python option &lt;code&gt;-u&lt;/code&gt; avoids output buffering, see &lt;a href="https://docs.python.org/3/using/cmdline.html#cmdoption-u"&gt;https://docs.python.org/3/using/cmdline.html#cmdoption-u&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;It is important to keep in mind the layered nature of Docker images, as this can lead to simple optimisation tricks. In this case, loading the requirements file and installing them creates a layer out of a file that doesn't change very often, while the layer created at &lt;span class="callout"&gt;5&lt;/span&gt; is probably changing very quickly while we develop the application. If we run something like&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;. .

&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pip install --no-cache-dir -r requirements.txt

&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;python&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-u&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;./app.py&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;we would have to install the requirements every time we change the application code, as this would rebuild the &lt;code&gt;COPY&lt;/code&gt; layer and thus invalidate the layer containing the &lt;code&gt;RUN&lt;/code&gt; command.&lt;/p&gt;&lt;p&gt;Once the &lt;code&gt;Dockerfile&lt;/code&gt; is in place we can build the image&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cd whaleapp
$ docker build -t whaleapp .
Sending build context to Docker daemon  6.144kB
Step 1/6 : FROM python:3
 ---&amp;gt; 768307cdb962
Step 2/6 : WORKDIR /usr/src/app
 ---&amp;gt; Using cache
 ---&amp;gt; b00189756ddb
Step 3/6 : COPY requirements.txt .
 ---&amp;gt; a7aef12f562c
Step 4/6 : RUN pip install --no-cache-dir -r requirements.txt
 ---&amp;gt; Running in 153a3ca6a1b2
Collecting psycopg2
  Downloading psycopg2-2.9.3.tar.gz (380 kB)
Building wheels for collected packages: psycopg2
  Building wheel for psycopg2 (setup.py): started
  Building wheel for psycopg2 (setup.py): finished with status &amp;#39;done&amp;#39;
  Created wheel for psycopg2: filename=psycopg2-2.9.3-cp39-cp39-linux_x86_64.whl size=523502 sha256=1a3aac3cf72cc86b63a3e0f42b9b788c5237c3e5d23df649ca967b29bf89ecf5
  Stored in directory: /tmp/pip-ephem-wheel-cache-ow3d1yop/wheels/b3/a1/6e/5a0e26314b15eb96a36263b80529ce0d64382540ac7b9544a9
Successfully built psycopg2
Installing collected packages: psycopg2
Successfully installed psycopg2-2.9.3
WARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.
You should consider upgrading via the &amp;#39;/usr/local/bin/python -m pip install --upgrade pip&amp;#39; command.
Removing intermediate container 153a3ca6a1b2
 ---&amp;gt; b18aead1ef15
Step 5/6 : COPY . .
 ---&amp;gt; be7c3c11e608
Step 6/6 : CMD [ &amp;quot;python&amp;quot;, &amp;quot;-u&amp;quot;, &amp;quot;./app.py&amp;quot; ]
 ---&amp;gt; Running in 9e2f4f30b59e
Removing intermediate container 9e2f4f30b59e
 ---&amp;gt; b735eece4f86
Successfully built b735eece4f86
Successfully tagged whaleapp:latest
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can see the layers being built one by one (marked as &lt;code&gt;Step x/6&lt;/code&gt; here). Once the image has been build you should be able to see it in the list of images present in your system&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker image ls | grep whale
whaleapp  latest  969b15466905  9 minutes ago  894MB
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div class="infobox"&gt;&lt;i class="fa fa-info-circle"&gt;&lt;/i&gt;&lt;div class="title"&gt;Size of containers&lt;/div&gt;&lt;div&gt;&lt;p&gt;You might want to observe 1 minute of silence meditating on the fact that we used almost 900 megabytes of space to run 40 lines of Python. As you can see benefits come with a cost, and you should not underestimate those. 900 megabytes might not seem a lot nowadays, but if you keep building images you will soon use up the space on your hard drive or end up paying a lot for the space on your remote repository.&lt;/p&gt;
&lt;p&gt;By the way, this is the reason why Docker splits image into layers and reuses them. For now we can ignore this part of the game, but remember that keeping the system clean and removing past artefacts is important.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As I mentioned before we can run this image but we need to use the &lt;code&gt;host&lt;/code&gt; network configuration.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -it --rm --network=host --name whale-app whaleapp
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that I used &lt;code&gt;--rm&lt;/code&gt; to make Docker remove the container automatically when it is terminated. This way I can run it again with the same name without having to explicitly remove the past container with &lt;code&gt;docker rm&lt;/code&gt;.&lt;/p&gt;&lt;h2 id="run-containers-in-the-same-network"&gt;Run containers in the same network&lt;a class="headerlink" href="#run-containers-in-the-same-network" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Docker containers are isolated from the host and from other containers by default. This however doesn't mean that they can't communicate with each other if we run them in a specific configuration. In particular, an important part in Docker networking is played by bridge networks.&lt;/p&gt;&lt;p&gt;Whenever containers are run in the same custom bridge network, Docker provides them DNS resolution using the container names. This means that we can make the application communicate with the database without having to run the former in the host network.&lt;/p&gt;&lt;p&gt;A custom network can be created using &lt;code&gt;docker network&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker network create whale
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As always, Docker will return the ID of the object it just created, but we can ignore it for now, as we can refer to the network by name.&lt;/p&gt;&lt;p&gt;Stop and remove the Postgres container, and run it again using the network &lt;code&gt;whale&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker rm -f whale-postgres 
whale-postgres
$ docker run -d \
  --name whale-postgres \
  -e POSTGRES_PASSWORD=whale_password \
  -e POSTGRES_DB=whale_db \
  -e POSTGRES_USER=whale_user \
  --network=whale \
  -v whale_dbdata:/var/lib/postgresql/data \
  postgres:13
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that there is no need to publish the port 5432 in this setup, as the host doesn't need to access the container. Should this be a requirement, add the option &lt;code&gt;-p 5432:5432&lt;/code&gt; again.&lt;/p&gt;&lt;p&gt;As happened with volumes, &lt;code&gt;docker ps&lt;/code&gt; doesn't give information about the network that containers are using, so you have to use &lt;code&gt;docker inspect&lt;/code&gt; again&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker inspect whale-postgres 
[...]
        &amp;quot;NetworkSettings&amp;quot;: {
            &amp;quot;Networks&amp;quot;: {
                &amp;quot;whale&amp;quot;: {
[...]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div class="infobox"&gt;&lt;i class="fa fa-info-circle"&gt;&lt;/i&gt;&lt;div class="title"&gt;Docker network management&lt;/div&gt;&lt;div&gt;&lt;p&gt;The command &lt;code&gt;docker network&lt;/code&gt; can be used to change the network configuration of &lt;em&gt;running&lt;/em&gt; containers.&lt;/p&gt;
&lt;p&gt;You can disconnect a running container from a network with&lt;/p&gt;
&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker network disconnect NETWORK_ID CONTAINER_ID
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and connect it with&lt;/p&gt;
&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker network connect NETWORK_ID CONTAINER_ID
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You can see which containers are using a given network inspecting it&lt;/p&gt;
&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker network inspect NETWORK_ID
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Remember that disconnecting a container from a network makes it unreachable, so while it is good that we can do this on running containers, maintenance shall be always carefully planned to avoid unexpected downtime.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As I mentioned before, Docker bridge networks provide DNS resolution using the container's name. We can double check this running a container and using &lt;code&gt;ping&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -it --rm --network=whale whaleapp ping whale-postgres
PING whale-postgres (172.19.0.2) 56(84) bytes of data.
64 bytes from whale-postgres.whale (172.19.0.2): icmp_seq=1 ttl=64 time=0.064 ms
64 bytes from whale-postgres.whale (172.19.0.2): icmp_seq=2 ttl=64 time=0.100 ms
64 bytes from whale-postgres.whale (172.19.0.2): icmp_seq=3 ttl=64 time=0.115 ms
64 bytes from whale-postgres.whale (172.19.0.2): icmp_seq=4 ttl=64 time=0.101 ms
^C
--- whale-postgres ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 80ms
rtt min/avg/max/mdev = 0.064/0.095/0.115/0.018 ms
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;What I did here was to run the image &lt;code&gt;whaleapp&lt;/code&gt; that we built previously, but overriding the default command and running &lt;code&gt;ping whale-postgres&lt;/code&gt; instead. This is a good way to check if a host can resolve a name on the network (&lt;code&gt;dig&lt;/code&gt; is another useful tool but is not installed by default in that image).&lt;/p&gt;&lt;p&gt;As you can see the Postgres container is reachable and we also know that it currently runs with the IP &lt;code&gt;172.19.0.2&lt;/code&gt;. This value might be different on your system, but it will match the information you get if you run &lt;code&gt;docker network inspect whale&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The point of all this talk about DNS is that we can now change the code of the Python application so that it connects to &lt;code&gt;whale-postgres&lt;/code&gt; instead of &lt;code&gt;localhost&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;connection_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="hll"&gt;    &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;whale-postgres&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;    &lt;span class="s2"&gt;&amp;quot;database&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;whale_db&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;whale_user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;password&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;whale_password&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Once this is done, rebuild the image and run it in the &lt;code&gt;whale&lt;/code&gt; network&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker build -t whaleapp .
[...]
$ docker run -it --rm --network=whale --name whale-app whaleapp
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can also take the network directly from another container, which is a useful shortcut.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker build -t whaleapp .
[...]
$ docker run -it --rm \
  --network=container:whale-postgres \
  --name whale-app whaleapp
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="run-time-configuration"&gt;Run time configuration&lt;a class="headerlink" href="#run-time-configuration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Hardcoding configuration values into the application is never a great idea, and while this is a very simple example it is worth pushing the setup a bit further to make it tidy.&lt;/p&gt;&lt;p&gt;In particular, we can replace the connection data &lt;code&gt;host&lt;/code&gt;, &lt;code&gt;database&lt;/code&gt;, and &lt;code&gt;user&lt;/code&gt; with environment variables, which allow us to reuse the application configuring it at run time. For simplicity's sake I will store the password in an environment variable as well, and pass it in clear text when we run the container. See the box for more information about how to manage secret values.&lt;/p&gt;&lt;p&gt;Reading values from environment variables is easy in Python&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;psycopg2&lt;/span&gt;

&lt;span class="n"&gt;DB_HOST&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;WHALEAPP__DB_HOST&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;DB_NAME&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;WHALEAPP__DB_NAME&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;DB_USER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;WHALEAPP__DB_USER&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;DB_PASSWORD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;WHALEAPP__DB_PASSWORD&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;connection_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;host&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DB_HOST&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;database&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DB_NAME&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DB_USER&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;password&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DB_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that I prefixed all environment variables with &lt;code&gt;WHALEAPP__&lt;/code&gt;. This is not mandatory, and has no special meaning for the operating system. In my experience, complicated systems can have many environment variables, and using prefixes is a simple and effective way to keep track of which part of the system needs that particular value.&lt;/p&gt;&lt;p&gt;We already know how to pass environment variables to Docker containers as we did it when we run the Postgres container. Build the image again, and then run it passing the correct variables&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker build -t whaleapp .
[...]
$ docker run -it --rm --network=whale \
  -e WHALEAPP__DB_HOST=whale-postgres \
  -e WHALEAPP__DB_NAME=whale_db \
  -e WHALEAPP__DB_USER=whale_user \
  -e WHALEAPP__DB_PASSWORD=password \
  --name whale-app whaleapp
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
Connecting to the PostgreSQL database...
[(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
Database connection closed.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div class="infobox"&gt;&lt;i class="fa fa-info-circle"&gt;&lt;/i&gt;&lt;div class="title"&gt;Managing secrets&lt;/div&gt;&lt;div&gt;&lt;p&gt;A "secret" is a value that should never be shown in plain text, as it is used to grant access to a system. This can be a password or a private key such as the ones you have to run SSH, and as happens with everything related to security, managing them is complicated. Please keep in mind that security is hard and that the best attitude to have is: &lt;em&gt;every time you think something in security is straightforward this means you got it wrong&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Generally speaking, you want secrets to be encrypted and stored in a safe place where access is granted to a narrow set of people. These secrets should be accessible to your application in a secure way, and it shouldn't be possible to access the secrets hosted in the memory of the application.&lt;/p&gt;
&lt;p&gt;For example, many posts online show how you can use AWS Secrets Manager to store your secrets and access them from your application using &lt;a href="https://stedolan.github.io/jq/"&gt;jq&lt;/a&gt; to fetch them at run time. While this works, if the JSON secret contains a syntax error, &lt;code&gt;jq&lt;/code&gt; dumps the whole value in the standard output of the application, which means that the logs contain the secret in plain text.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://hub.docker.com/_/vault"&gt;Vault&lt;/a&gt; is a tool created by Hashicorp that many use to store secrets needed by containers. It is interesting to read in the description of the image that with a specific configuration the container prevents memory from being swapped to disk, which would leak the unencrypted values. As you see, security is hard.&lt;/p&gt;
&lt;p&gt;Orchestration tools always provide a way to manage secrets and to pass them to containers. For example, see &lt;a href="https://docs.docker.com/engine/swarm/secrets/"&gt;Docker Swarm secrets&lt;/a&gt;, &lt;a href="https://kubernetes.io/docs/concepts/configuration/secret/"&gt;Kubernetes secrets&lt;/a&gt;, and &lt;a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html"&gt;secrets for AWS Elastic Container Service&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2 id="enter-docker-compose"&gt;Enter Docker Compose&lt;a class="headerlink" href="#enter-docker-compose" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The setup we created in the past sections is good, but is far from being optimal. We had to create a custom bridge network and then start the Postgres and the application containers connected to it. To stop the system we need to terminate containers manually and to remember to remove them to avoid blocking the container name. We also have to manually remove the network if we want to keep the system clean.&lt;/p&gt;&lt;p&gt;The next step would then be to create a bash script, then to evolve it to a Makefile or similar solution. Fortunately, Docker provides a better solution with Docker Compose.&lt;/p&gt;&lt;p&gt;Docker Compose can be described as a single-host orchestration tool. Orchestration tools are pieces of software that allow us to deal with the problems described previously, such as starting and terminating multiple containers, creating networks and volumes, managing secrets, and so on. Docker Compose works in a single-host mode, so it's a great solution for development environment, while for production multi-host environments it's better to move to more advanced tools such as AWS ECS or Kubernetes.&lt;/p&gt;&lt;p&gt;Docker Compose reads the configuration of a system from the file &lt;code&gt;docker-compose.yml&lt;/code&gt; (the default value, it can be changed) that captures all we did manually in the previous sections in a compact and readable way.&lt;/p&gt;&lt;p&gt;To install Docker Compose follow the instructions you find at &lt;a href="https://docs.docker.com/compose/install/"&gt;https://docs.docker.com/compose/install/&lt;/a&gt;. Before we start using Docker Compose make sure you kill the Postgres container if you are still running it, and remove the network we created&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker rm -f whale-postgres 
whale-postgres
$ docker network remove whale
whale
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Then create the file &lt;code&gt;docker-compose.yml&lt;/code&gt; in the project directory (not the app directory) and put the following code in it&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;docker-compose.yml&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#39;3.8&amp;#39;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This is not a valid Docker Compose file, yet, but you can see that there is a value that specifies the syntax version and one that lists services. You can find the Compose file reference at &lt;a href="https://docs.docker.com/compose/compose-file/"&gt;https://docs.docker.com/compose/compose-file/&lt;/a&gt;, together with a detailed description of the various versions.&lt;/p&gt;&lt;p&gt;The first service we want to run is Postgres, and a basic configuration for that is&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;docker-compose.yml&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#39;3.8&amp;#39;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;postgres:13&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;environment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_DB&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_db&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_password&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_USER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_user&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;volumes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt; &lt;span class="callout"&gt;2&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;dbdata:/var/lib/postgresql/data&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;volumes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt; &lt;span class="callout"&gt;1&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;dbdata&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see, this file contains the environment variables that we passed to the Postgres container and the volume configuration. The final &lt;code&gt;volumes&lt;/code&gt; &lt;span class="callout"&gt;1&lt;/span&gt; declares which volumes have to be present (so it creates them if they are not), while &lt;code&gt;volumes&lt;/code&gt; &lt;span class="callout"&gt;2&lt;/span&gt; inside the service &lt;code&gt;db&lt;/code&gt; creates the connection just like the option &lt;code&gt;-v&lt;/code&gt; did previously.&lt;/p&gt;&lt;p&gt;Now, from the project directory, you can run Docker Compose with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker-compose -p whale up -d
Creating network &amp;quot;whale_default&amp;quot; with the default driver
Creating whale_db_1 ... done
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The option &lt;code&gt;-p&lt;/code&gt; sets the name of the project, which otherwise would be by default that of the directory you are at the moment (which might or might not be meaningful), while the command &lt;code&gt;up -d&lt;/code&gt; starts all the containers in a detached mode.&lt;/p&gt;&lt;p&gt;As you can see from the output, Docker Compose creates a (bridge) network called &lt;code&gt;whale_default&lt;/code&gt;. Normally, you would see a message like &lt;code&gt;Creating volume &amp;quot;whale_dbdata&amp;quot; with default driver&lt;/code&gt; as well, but in this case the volume is already present as we created it previously. Both the network and the volume are prefixed with &lt;code&gt;PROJECTNAME_&lt;/code&gt;, and this is the reason why when we first created the volume I named it &lt;code&gt;whale_dbdata&lt;/code&gt;. Keep in mind however that all these default behaviours can be customised in the Compose file.&lt;/p&gt;&lt;p&gt;If you run &lt;code&gt;docker ps&lt;/code&gt; you will see that the container is named &lt;code&gt;whale_db_1&lt;/code&gt;. This comes from the project name (&lt;code&gt;whale_&lt;/code&gt;), the service name in the Compose file (&lt;code&gt;db_&lt;/code&gt;) and the container number, which is 1 because at the moment we are running only one container for that service.&lt;/p&gt;&lt;p&gt;To stop the services you have to run&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker-compose -p whale down
Stopping whale_db_1 ... done
Removing whale_db_1 ... done
Removing network whale_default
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see from the output, Docker Compose stops and removes the container, then removes the network. This is very convenient, as it already removes a lot of the work we had to do manually earlier.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;We can now add the application container to the Compose file&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#39;3.8&amp;#39;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;postgres:13&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;environment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_DB&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_db&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_password&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_USER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_user&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;volumes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;dbdata:/var/lib/postgresql/data&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="hll"&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;app&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;build&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;context&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whaleapp&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;dockerfile&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Dockerfile&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;environment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_HOST&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;db&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_NAME&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_db&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_USER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_user&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_password&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;
&lt;span class="nt"&gt;volumes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;dbdata&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This definition is slightly different, as the application container has to be built using the Dockerfile we created. Docker Compose allows us to store here the build configuration so that we don't need to pass al the options to &lt;code&gt;docker build&lt;/code&gt; manually, but please note that configuring the build here doesn't mean that Docker Compose will build the image for you every time. You still need to run &lt;code&gt;docker-compose -p whale build&lt;/code&gt; every time you need to rebuild it. &lt;/p&gt;&lt;p&gt;Please note that the variable &lt;code&gt;WHALEAPP__DB_HOST&lt;/code&gt; is set to the service name, and not to the container name. Now, when we run Docker Compose we get&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker-compose -p whale up -d
Creating network &amp;quot;whale_default&amp;quot; with the default driver
Creating whale_db_1  ... done
Creating whale_app_1 ... done
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;and the output tells us that also the container &lt;code&gt;whale_app_1&lt;/code&gt; has been created this time. We can see the logs of a container with &lt;code&gt;docker logs&lt;/code&gt;, but using &lt;code&gt;docker-compose&lt;/code&gt; allows us to call services by name instead of by ID&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker-compose -p whale logs -f app
Attaching to whale_app_1
app_1  | Connecting to the PostgreSQL database...
app_1  | [(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
app_1  | Database connection closed.
app_1  | Connecting to the PostgreSQL database...
app_1  | [(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
app_1  | Database connection closed.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="health-checks-and-dependencies"&gt;Health checks and dependencies&lt;a class="headerlink" href="#health-checks-and-dependencies" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You might have noticed that at the very beginning of the application logs there are some connection errors, and that after a while the application manages to connect to the database&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker-compose -p whale logs -f app
Attaching to whale_app_1
app_1  | Connecting to the PostgreSQL database...
app_1  | could not translate host name &amp;quot;db&amp;quot; to address: Name or service not known
app_1  | 
app_1  | Connecting to the PostgreSQL database...
app_1  | could not translate host name &amp;quot;db&amp;quot; to address: Name or service not known
app_1  | 
app_1  | Connecting to the PostgreSQL database...
app_1  | Connecting to the PostgreSQL database...
app_1  | could not connect to server: Connection refused
app_1  |        Is the server running on host &amp;quot;db&amp;quot; (172.31.0.3) and accepting
app_1  |        TCP/IP connections on port 5432?
app_1  | 
app_1  | Connecting to the PostgreSQL database...
app_1  | [(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
app_1  | Database connection closed.
app_1  | Connecting to the PostgreSQL database...
app_1  | [(1, &amp;#39;Tacos&amp;#39;), (2, &amp;#39;Tomato Soup&amp;#39;), (3, &amp;#39;Grilled Cheese&amp;#39;)]
app_1  | Database connection closed.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;These errors come from the fact that the application container is up and running before the database is ready to serve connections. In a production setup this usually doesn't happen because the database is up and running much before the application gets deployed for the first time, and then runs (hopefully) without interruption. In a development environment, instead, such a situation is normal.&lt;/p&gt;&lt;p&gt;Please note that this might not happen in your setup, as this is tightly connected with the speed of Docker Compose and the containers. Time-sensitive bugs are one of the worst types to deal with, and this is the reason why managing distributed systems is hard. It is important that you realise that even though this might work now on your system, the problem is there and we need to find a solution.&lt;/p&gt;&lt;p&gt;The standard solution when part of a system depends on another is to create a &lt;em&gt;health check&lt;/em&gt; that periodically tests the first service, and to start the second service only when the check is successful. We can do this in the Compose file using &lt;code&gt;healthcheck&lt;/code&gt; and &lt;code&gt;depends_on&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#39;3.8&amp;#39;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;postgres:13&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;environment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_DB&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_db&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_password&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;POSTGRES_USER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_user&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;volumes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;dbdata:/var/lib/postgresql/data&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="hll"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;healthcheck&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;test&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p p-Indicator"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;CMD-SHELL&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;pg_isready&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;interval&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;10s&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;timeout&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;5s&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;retries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;5&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;app&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;build&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;context&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whaleapp&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;dockerfile&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Dockerfile&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;environment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_HOST&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;db&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_NAME&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_db&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_USER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_user&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;WHALEAPP__DB_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;whale_password&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="hll"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;depends_on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;condition&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;service_healthy&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/span&gt;
&lt;span class="nt"&gt;volumes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;dbdata&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The health check for the Postgres container leverages the command line tool &lt;code&gt;pg_isready&lt;/code&gt; that is successful only when the database is ready to accept connections, and tries every 10 seconds for 5 times. Now, when you run &lt;code&gt;up -d&lt;/code&gt; this time you should notice a clear delay before the application is run, but the logs won't contain any connection error.&lt;/p&gt;&lt;h2 id="final-words"&gt;Final words&lt;a class="headerlink" href="#final-words" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Well, this was a long one, but I hope you enjoyed the trip and you ended up having a better picture of what problems Docker Compose solve, along with a feeling of how complicated it might be to design an architecture. Everything we did was for a "simple" development environment with a couple of containers, so you can figure what is involved when we get to live environments.&lt;/p&gt;&lt;h2 id="updates"&gt;Updates&lt;a class="headerlink" href="#updates" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;2022-03-17: Thanks to my colleague Joanna Stadnik for a thorough review, for spotting typos, and for giving me several suggestions based on her experience. Thank you!&lt;/p&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;&lt;p&gt;Cover picture by &lt;a href="https://unsplash.com/@verstappen_photography?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Verstappen Photography&lt;/a&gt; on &lt;a href="https://unsplash.com/s/photos/crane?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Unsplash&lt;/a&gt;.&lt;/p&gt;</content><category term="Programming"></category><category term="devops"></category><category term="Docker"></category><category term="infrastructure"></category><category term="Postgres"></category><category term="Python"></category></entry><entry><title>Public key cryptography: RSA keys</title><link href="https://www.thedigitalcatonline.com/blog/2018/04/25/rsa-keys/" rel="alternate"></link><published>2018-04-25T13:00:00+01:00</published><updated>2022-01-23T11:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2018-04-25:/blog/2018/04/25/rsa-keys/</id><summary type="html">&lt;p&gt; An in-depth discussion of the format of RSA keys, the PEM format, ASN, and PKCS&lt;/p&gt;</summary><content type="html">&lt;p&gt;I bet you created at least once an RSA key pair, usually because you needed to connect to GitHub and you wanted to avoid typing your password every time. You diligently followed the documentation on how to create SSH keys and after a couple of minutes your setup was complete.&lt;/p&gt;&lt;p&gt;But do you know what you actually did?&lt;/p&gt;&lt;p&gt;Do you know what the file &lt;code&gt;~/.ssh/id_rsa&lt;/code&gt; really contains? Why did ssh create two files with such a different format? Did you notice that one file begins with &lt;code&gt;ssh-rsa&lt;/code&gt;, while the other begins with &lt;code&gt;-----BEGIN RSA PRIVATE KEY-----&lt;/code&gt;? Have you noticed that sometimes the header of the second file misses the &lt;code&gt;RSA&lt;/code&gt; part and just says &lt;code&gt;BEGIN PRIVATE KEY&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;I believe that a minimum level of knowledge regarding the various formats of RSA keys is mandatory for every developer nowadays, not to mention the importance of understanding them deeply if you want to pursue a career in the infrastructure management world.&lt;/p&gt;&lt;h2 id="rsa-algorithm-and-key-pairs"&gt;RSA algorithm and key pairs&lt;a class="headerlink" href="#rsa-algorithm-and-key-pairs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Since the invention of public-key cryptography, various systems have been devised to create the key pair. One of the first ones is RSA, the creation of three brilliant cryptographers, that dates back to 1977. The story of RSA is quite interesting, as it was first invented by an English mathematician, Clifford Cocks, who was however forced to keep it secret by the British intelligence office he was working for.&lt;/p&gt;&lt;p&gt;Keeping in mind that RSA is not a synonym for public-key cryptography but only one of the possible implementations, I wanted to write a post on it because it is still, more than 40 years after its publication, one of the most widespread algorithms. In particular it is the standard algorithm used to generate SSH key pairs, and since nowadays every developer has their public key on GitHub, BitBucket, or similar systems, we may arguably say that RSA is pretty ubiquitous.&lt;/p&gt;&lt;p&gt;I will not cover the internals of the RSA algorithm in this article, however. If you are interested in the gory details of the mathematical framework you may find plenty of resources both on Internet and in the textbooks. The theory behind it is not trivial, but it is definitely worth the time if you want to be serious about the mathematical part of cryptography.&lt;/p&gt;&lt;p&gt;In this article I will instead explore two ways to create RSA key pairs and the formats used to store them. Applied cryptography is, like many other topics in computer science, a moving target, and the tools change often. Sometimes it is pretty easy to find out &lt;strong&gt;how&lt;/strong&gt; to do something (StackOverflow helps), but less easy to get a clear picture of what is going on.&lt;/p&gt;&lt;p&gt;All the examples shown in this post use a 2048-bits RSA key created for this purpose, so all the numbers you see come from a real example. The key has been obviously trashed after I wrote the article.&lt;/p&gt;&lt;h2 id="the-pem-format"&gt;The PEM format&lt;a class="headerlink" href="#the-pem-format" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's start the discussion about key pairs with the format used to store them. Nowadays the most widely accepted storage format is called PEM (Privacy-enhanced Electronic Mail). As the name suggests, this format was initially created for e-mail encryption but later became a general format to store cryptographic data like keys and certificates. It is described in &lt;a href="https://tools.ietf.org/html/rfc7468"&gt;RFC 7468&lt;/a&gt; ("Textual Encodings of PKIX, PKCS, and CMS Structures").&lt;/p&gt;&lt;p&gt;An example private key in PEM format is the following&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN PRIVATE KEY-----
MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQCy9f0/nwkXESzk
L4v4ftZ24VJYvkQ/Nt6vsLab3iSWtJXqrRsBythCcbAU6W95OGxjbTSFFtp0poqM
cPuogocMR7QhjY9JGG3fcnJ7nYDCGRHD4zfG5Af/tHwvJ2ew0WTYoemvlfZIG/jZ
7fsuOQSyUpJoxGAlb6/QpnfSmJjxCx0VEoppWDn8CO3VhOgzVhWx0dcne+ZcUy3K
kt3HBQN0hosRfqkVSRTvkpK4RD8TaW5PrVDe1r2Q5ab37TO+Ls4xxt16QlPubNxW
eH3dHVzXdmFAItuH0DuyLyMoW1oxZ6+NrKu+pAAERxM303gejFzKDqXid5m1EOTv
k4xhyqYNAgMBAAECggEBALJCVQAKagOQGCczNTlRHk9MIbpDy7cr8KUQYNThcZCs
UKhxxXUDmGaW1838uA0HJu/i1226Vd/cBCXgZMx1OBADXGoPl6o3qznnxiFbweWV
Ex0MN4LloRITtZ9CoQZ/jPQ8U4mS1r79HeP2KTzhjswRc8Tn1t1zYq1zI+eiGLX/
sPJF63ljJ8yHST7dE0I07V87FKTE2SN0WX9kptPLLBDwzS1X6Z9YyNKPIEnRQzzE
vWdwF60b3RyDz7j7foyP3PC0+3fee4KFdJzt+/1oePf3kwBz8PQq3cuoOF1+0Fzf
yqKiunV2AXI6liAf7MwuZcZeFPZfHTTW7N/j+FQBgAECgYEA4dFjib9u/3rkT2Vx
Bu2ByBpItfs1b4PdSiKehlS9wDZxa72dRt/RSYEyVFBUlYrKXP2nCdl8yMap6SA9
Bfe51F5oWhml9YJn/LF/z1ArMs/tuUyupY7l9j66XzPQmUbIZSEyNEQQ09ZYdIvK
4lbySJbCqa2TQNPIOSZS2o7XNG0CgYEAyuFVybOkVGtfw89MyA1TnVMcQGusXtgo
GOl3tJb59hTO+xF547+/qyK8p/iOu4ybEyeucBEyQt/whmNwtsdngtvVDb4f7psz
Frmqx7q7fPoKnvJsPJds9i2o9B7+BlRY3HwcvKePsctP96pQ0RbOFkCVak6J6t9S
k/qhOiNJ9CECgYEAvDuTMk5tku54g6o2ZiTyir9GHtOwviz3+AUViTn4FdIMB1g+
UsbcqN3V+ywe5ayUdKFHbNFqz92x4k7qLyBJObocWAaLLTQvxBadSE02RRvHuC8w
YXbVP8cYCaWiWzICdzINrD2UnVBN2ZBxZOw+970btN6oIWCnxOOqKt7oip0CgYAp
Fekhp9enoPcL2HdcLBa6zZHzGdsWef/ky6MKV2jXhO9FuQxOKw7NwYMjIRsGsDrX
bjnNSC49jMxQ6uJwoYE85vgGiHI/B/8YoxEK0a4WaSytc7qnqqLOWADXL0+SSJKW
VCwdqHFZOCtBpKQpM80YhIu9s5oKjp9SiHcOJwdbAQKBgDq047hBqyNFFb8KjS5A
+26VOJcC2DRHTprYSRJNxsHTQnONTnUQJl32t0TrqkqIp5lTRr7vBH2wJM6LKk45
I7BWY4mUirC7sDGHl3DaFPRBiut1rpg0kSKi2VNRF7Bb75OKEhGjvm6IKVe8Kl8d
5cpQwm9C7go4OiorY0DVLho2
-----END PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Basically, you can tell you are dealing with a PEM format from the typical header and footer that identify the content. While the hyphens and the two words &lt;code&gt;BEGIN&lt;/code&gt; and &lt;code&gt;END&lt;/code&gt; are always present, the &lt;code&gt;PRIVATE KEY&lt;/code&gt; part describes the content and can change if the PEM file contains something different from a key, for example an X.509 certificate for SSL.&lt;/p&gt;&lt;p&gt;The PEM format specifies that the the body of the content (the part between the header and the footer) is encoded using &lt;a href="https://en.wikipedia.org/wiki/Base64"&gt;Base64&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;If the private key has been encrypted with a password the header and the footer are different&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN ENCRYPTED PRIVATE KEY-----
MIIFHzBJBgkqhkiG9w0BBQ0wPDAbBgkqhkiG9w0BBQwwDgQIf75rXIakuSICAggA
MB0GCWCGSAFlAwQBKgQQf8HMdJ9FZJjwHkMQjkNA3gSCBNClWB7cJ5f8ThrQtmoA
t2WQCvEWTY9nRYwaTnL1SmXyuMDFrX5CWEuVFh/Zj77KB9jhBJaHw2XtFXxF8bV7
F10u93ih/n0S5QwN9CSPDhRp2kD5lIWB8WVG+VgtncqDrAfJRmpuPmzpjMJBxE2r
MvWJG5beMCS25qD0mAxihtbriqFoCtEygQ7vsSfeQpaBQvT5pKLOVaVgwFTFTf+7
cgqB8/UKKmPXSM4GMJ9VNAvUx0mAxI9MnUFlBWimK76OAzdlO9Si99R8OiRRS10x
AO1AwWSDHGWpbckK0g9K7wLgAgOw8LLVUJh67o9Mfg58DP9Ca0ZdPPVo0C7oavBD
NFlUsKqmSfqfgOAm4qGJ7GB3KgWGFdz+yexNLRLN63hE6qACAuQ1oLmwoorE8toh
MhT3c6IxnVWlYNXJkkb5iV9e8E2X/xzibvwv+CJJ9ulCU8uS7gp0rjlCKFwt/8d4
g3Cef/JWn9nI9YwRLNShJeQOe8hZkkLXHefUhBa2o2++C5C6mgWvuYLK6a0zfCMY
WCqjKKvDQfuxwDbeM03jJ97Je6dXy7rtJvJd10vYvpIVtHnNSdg1evpSiaAmWt4C
X5/AzbHNvwTIEvILfOtYvxLB/RdWqr1/VXuH4dJF6AYtHfQHjXetmL/fDA86Bqf6
Eb+uDr+PPuH4qw1tfJBdTSOOJzhhPqdT4ERYnOvfNxTKzsKYZT+kWvWXe9zyO13W
C0eceVi4rBjKpKpKecKDgFJGZ1u7jS0OW3FDIOfm/osu9z25g5CVIpuWU3JquWib
GatHET9wIEg7LRqC/i65q6tCnd9azevKtiur1I0tuh05iwP5kZ8drIzaGdObuvK1
/pbEPnj1ZcRlAZ34jnG841xvf4vofrOE+hGTNF5HypOCvO/8Lms3aB6NletIvHBE
99ynQyF9TAgSAFAumOws+qnRcnfVOF5lzIEE2pmeMVMqi5s7TT4hlhOuCbyfEFU8
xOXxNazT+0o7urIYOc77vA1LsWrk+9dAfm43CbBZvYav/gMoBc5fsLgAUAm1lkt5
5Hjaf+iMIN0v7aEKDrNDOtyQr13YdyuEClzXxeMtlhU+QfErpQHvH0jE4gywEgz7
tvVGwrbiLgg0y537+kg0/rS3N0eI94GhY0q/nR/QFObbN0nmoIYVVSGtufJx1r9v
YEVZA7HZE9pjnun1ylE1/SoYc/816rjBUcW5CCbkMDIz1LsFPr2SkQeHTNzK3/9J
Kny1lerfA+TA/hUyZ1KJjxuao+rJkH2fJ25qs3r6NP+PPbq3sAl1TPGhMCnNaFdo
YQWDDwz26ZR2ywfsquqLXMwnIEeUI/hQTng9ZxLkJMY22rQSA9nsdvR8S1b0U8Qu
ViYEjCTMWF8HEFFO721MlkTgchzq6fiF+9ZydCpVUJWolcfw1OgUvvTSI7Eyhelb
7fc1fTVFeEMsHrtjpu8dg+IaCNraBzv5QZx6MYW7SSoTVp8mJoPnzYbsZs9nHJGX
iQOFmO/sIryOoeJlpOCGT55yU74yRXrBsYZyLz0P9K1FDQS6l9W33BqmF9vSXujs
kSByq8v1OU0IqidnMmZtTDSRlpQL/oadqQnsA6jiWyMznuUEU8tfgUALE4DKRq8P
wBLKVfMiwcWAbl121M2DCLj9/g==
-----END ENCRYPTED PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;When the PEM format is used to store cryptographic keys the body of the content is in a format called PKCS #8. Initially a standard created by a private company (RSA Laboratories), it became a de facto standard so has been described in various RFCs, most notably &lt;a href="https://tools.ietf.org/html/rfc5208"&gt;RFC 5208&lt;/a&gt; ("Public-Key Cryptography Standards (PKCS) #8: Private-Key Information Syntax Specification Version 1.2").&lt;/p&gt;&lt;p&gt;The PKCS #8 format describes the content using a description language called &lt;a href="https://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One"&gt;ASN.1&lt;/a&gt; (Abstract Syntax Notation One) and the relative binary encoding &lt;a href="https://en.wikipedia.org/wiki/X.690"&gt;DER&lt;/a&gt; (Distinguished Encoding Rules) to serialise the resulting structure. This means that Base64-decoding the content will return some binary content that can be processed only by an ASN.1 parser.&lt;/p&gt;&lt;p&gt;Let me visually recap the structure&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN label-----
+--------------------------- Base64 ---------------------------+
|                                                              |
| PKCS #8 content:                                             |
| ASN.1 language serialised with DER                           |
|                                                              |
+--------------------------------------------------------------+
-----END label-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that, due to the structure of the underlying ASN.1 structure, RSA PEM bodies start always with the same characters: &lt;code&gt;MIG&lt;/code&gt; for 1024 bit keys, &lt;code&gt;MII&lt;/code&gt; for 2048 and 4096 bit ones.&lt;/p&gt;&lt;h3 id="openssl-and-asn.1"&gt;OpenSSL and ASN.1&lt;/h3&gt;&lt;p&gt;OpenSSL can directly decode a key in PEM format and show the underlying ASN.1 structure with the module &lt;code&gt;asn1parse&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl asn1parse -inform pem -in private.pem
    0:d=0  hl=4 l=1214 cons: SEQUENCE          
    4:d=1  hl=2 l=   1 prim: INTEGER           :00
    7:d=1  hl=2 l=  13 cons: SEQUENCE          
    9:d=2  hl=2 l=   9 prim: OBJECT            :rsaEncryption
   20:d=2  hl=2 l=   0 prim: NULL              
   22:d=1  hl=4 l=1192 prim: OCTET STRING      [HEX DUMP]:308204A40201000282010100B2F5FD3F9F0917112
   CE42F8BF87ED676E15258BE443F36DEAFB0B69BDE2496B495EAAD1B01CAD84271B014E96F79386C636D348516DA74A68
   A8C70FBA882870C47B4218D8F49186DDF72727B9D80C21911C3E337C6E407FFB47C2F2767B0D164D8A1E9AF95F6481BF
   8D9EDFB2E3904B2529268C460256FAFD0A677D29898F10B1D15128A695839FC08EDD584E8335615B1D1D7277BE65C532
   DCA92DDC7050374868B117EA9154914EF9292B8443F13696E4FAD50DED6BD90E5A6F7ED33BE2ECE31C6DD7A4253EE6CD
   C56787DDD1D5CD776614022DB87D03BB22F23285B5A3167AF8DACABBEA40004471337D3781E8C5CCA0EA5E27799B510E
   4EF938C61CAA60D02030100010282010100B24255000A6A03901827333539511E4F4C21BA43CBB72BF0A51060D4E1719
   0AC50A871C57503986696D7CDFCB80D0726EFE2D76DBA55DFDC0425E064CC753810035C6A0F97AA37AB39E7C6215BC1E
   595131D0C3782E5A11213B59F42A1067F8CF43C538992D6BEFD1DE3F6293CE18ECC1173C4E7D6DD7362AD7323E7A218B
   5FFB0F245EB796327CC87493EDD134234ED5F3B14A4C4D92374597F64A6D3CB2C10F0CD2D57E99F58C8D28F2049D1433
   CC4BD677017AD1BDD1C83CFB8FB7E8C8FDCF0B4FB77DE7B8285749CEDFBFD6878F7F7930073F0F42ADDCBA8385D7ED05
   CDFCAA2A2BA757601723A96201FECCC2E65C65E14F65F1D34D6ECDFE3F85401800102818100E1D16389BF6EFF7AE44F6
   57106ED81C81A48B5FB356F83DD4A229E8654BDC036716BBD9D46DFD1498132545054958ACA5CFDA709D97CC8C6A9E92
   03D05F7B9D45E685A19A5F58267FCB17FCF502B32CFEDB94CAEA58EE5F63EBA5F33D09946C8652132344410D3D658748
   BCAE256F24896C2A9AD9340D3C8392652DA8ED7346D02818100CAE155C9B3A4546B5FC3CF4CC80D539D531C406BAC5ED
   82818E977B496F9F614CEFB1179E3BFBFAB22BCA7F88EBB8C9B1327AE70113242DFF0866370B6C76782DBD50DBE1FEE9
   B3316B9AAC7BABB7CFA0A9EF26C3C976CF62DA8F41EFE065458DC7C1CBCA78FB1CB4FF7AA50D116CE1640956A4E89EAD
   F5293FAA13A2349F42102818100BC3B93324E6D92EE7883AA366624F28ABF461ED3B0BE2CF7F805158939F815D20C075
   83E52C6DCA8DDD5FB2C1EE5AC9474A1476CD16ACFDDB1E24EEA2F204939BA1C58068B2D342FC4169D484D36451BC7B82
   F306176D53FC71809A5A25B320277320DAC3D949D504DD9907164EC3EF7BD1BB4DEA82160A7C4E3AA2ADEE88A9D02818
   02915E921A7D7A7A0F70BD8775C2C16BACD91F319DB1679FFE4CBA30A5768D784EF45B90C4E2B0ECDC18323211B06B03
   AD76E39CD482E3D8CCC50EAE270A1813CE6F80688723F07FF18A3110AD1AE16692CAD73BAA7AAA2CE5800D72F4F92489
   296542C1DA87159382B41A4A42933CD18848BBDB39A0A8E9F5288770E27075B010281803AB4E3B841AB234515BF0A8D2
   E40FB6E95389702D834474E9AD849124DC6C1D342738D4E7510265DF6B744EBAA4A88A7995346BEEF047DB024CE8B2A4
   E3923B0566389948AB0BBB031879770DA14F4418AEB75AE98349122A2D9535117B05BEF938A1211A3BE6E882957BC2A5
   F1DE5CA50C26F42EE0A383A2A2B6340D52E1A36
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This that you see in the code snippet is then the private key in ASN.1 format. Remember that DER is only used to go from the text representation of ASN.1 to binary data, so we don't see it unless we decode the Base64 content into a file and open it with a binary editor.&lt;/p&gt;&lt;p&gt;Note that the ASN.1 structure contains the type of the object (&lt;code&gt;rsaEncryption&lt;/code&gt;, in this case). You can further decode the &lt;code&gt;OCTET STRING&lt;/code&gt; field, which is the actual key, specifying the offset&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl asn1parse -inform pem -in private.pem -strparse 22
    0:d=0  hl=4 l=1188 cons: SEQUENCE          
    4:d=1  hl=2 l=   1 prim: INTEGER           :00
    7:d=1  hl=4 l= 257 prim: INTEGER           :B2F5FD3F9F0917112CE42F8BF87ED676E15258BE443F36DEAFB
    0B69BDE2496B495EAAD1B01CAD84271B014E96F79386C636D348516DA74A68A8C70FBA882870C47B4218D8F49186DDF
    72727B9D80C21911C3E337C6E407FFB47C2F2767B0D164D8A1E9AF95F6481BF8D9EDFB2E3904B2529268C460256FAFD
    0A677D29898F10B1D15128A695839FC08EDD584E8335615B1D1D7277BE65C532DCA92DDC7050374868B117EA9154914
    EF9292B8443F13696E4FAD50DED6BD90E5A6F7ED33BE2ECE31C6DD7A4253EE6CDC56787DDD1D5CD776614022DB87D03
    BB22F23285B5A3167AF8DACABBEA40004471337D3781E8C5CCA0EA5E27799B510E4EF938C61CAA60D
  268:d=1  hl=2 l=   3 prim: INTEGER           :010001
  273:d=1  hl=4 l= 257 prim: INTEGER           :B24255000A6A03901827333539511E4F4C21BA43CBB72BF0A51
    060D4E17190AC50A871C57503986696D7CDFCB80D0726EFE2D76DBA55DFDC0425E064CC753810035C6A0F97AA37AB39
    E7C6215BC1E595131D0C3782E5A11213B59F42A1067F8CF43C538992D6BEFD1DE3F6293CE18ECC1173C4E7D6DD7362A
    D7323E7A218B5FFB0F245EB796327CC87493EDD134234ED5F3B14A4C4D92374597F64A6D3CB2C10F0CD2D57E99F58C8
    D28F2049D1433CC4BD677017AD1BDD1C83CFB8FB7E8C8FDCF0B4FB77DE7B8285749CEDFBFD6878F7F7930073F0F42AD
    DCBA8385D7ED05CDFCAA2A2BA757601723A96201FECCC2E65C65E14F65F1D34D6ECDFE3F854018001
  534:d=1  hl=3 l= 129 prim: INTEGER           :E1D16389BF6EFF7AE44F657106ED81C81A48B5FB356F83DD4A2
    29E8654BDC036716BBD9D46DFD1498132545054958ACA5CFDA709D97CC8C6A9E9203D05F7B9D45E685A19A5F58267FC
    B17FCF502B32CFEDB94CAEA58EE5F63EBA5F33D09946C8652132344410D3D658748BCAE256F24896C2A9AD9340D3C83
    92652DA8ED7346D
  666:d=1  hl=3 l= 129 prim: INTEGER           :CAE155C9B3A4546B5FC3CF4CC80D539D531C406BAC5ED82818E
    977B496F9F614CEFB1179E3BFBFAB22BCA7F88EBB8C9B1327AE70113242DFF0866370B6C76782DBD50DBE1FEE9B3316
    B9AAC7BABB7CFA0A9EF26C3C976CF62DA8F41EFE065458DC7C1CBCA78FB1CB4FF7AA50D116CE1640956A4E89EADF529
    3FAA13A2349F421
  798:d=1  hl=3 l= 129 prim: INTEGER           :BC3B93324E6D92EE7883AA366624F28ABF461ED3B0BE2CF7F80
    5158939F815D20C07583E52C6DCA8DDD5FB2C1EE5AC9474A1476CD16ACFDDB1E24EEA2F204939BA1C58068B2D342FC4
    169D484D36451BC7B82F306176D53FC71809A5A25B320277320DAC3D949D504DD9907164EC3EF7BD1BB4DEA82160A7C
    4E3AA2ADEE88A9D
  930:d=1  hl=3 l= 128 prim: INTEGER           :2915E921A7D7A7A0F70BD8775C2C16BACD91F319DB1679FFE4C
    BA30A5768D784EF45B90C4E2B0ECDC18323211B06B03AD76E39CD482E3D8CCC50EAE270A1813CE6F80688723F07FF18
    A3110AD1AE16692CAD73BAA7AAA2CE5800D72F4F92489296542C1DA87159382B41A4A42933CD18848BBDB39A0A8E9F5
    288770E27075B01
1061:d=1  hl=3 l= 128 prim: INTEGER           :3AB4E3B841AB234515BF0A8D2E40FB6E95389702D834474E9AD8
    49124DC6C1D342738D4E7510265DF6B744EBAA4A88A7995346BEEF047DB024CE8B2A4E3923B0566389948AB0BBB0318
    79770DA14F4418AEB75AE98349122A2D9535117B05BEF938A1211A3BE6E882957BC2A5F1DE5CA50C26F42EE0A383A2A
    2B6340D52E1A36
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Being this an RSA key the fields represent specific components of the algorithm. We find in order: the modulus &lt;code&gt;n = pq&lt;/code&gt;, the public exponent &lt;code&gt;e&lt;/code&gt;, the private exponent &lt;code&gt;d&lt;/code&gt;, the two prime numbers &lt;code&gt;p&lt;/code&gt; and &lt;code&gt;q&lt;/code&gt;, and the values &lt;code&gt;d_p&lt;/code&gt;, &lt;code&gt;d_q&lt;/code&gt;, and &lt;code&gt;q_inv&lt;/code&gt; (for the &lt;a href="https://en.wikipedia.org/wiki/Chinese_remainder_theorem"&gt;Chinese remainder theorem&lt;/a&gt; speed-up).&lt;/p&gt;&lt;p&gt;If the key has been encrypted there are fields with information about the cipher, and the &lt;code&gt;OCTET STRING&lt;/code&gt; fields cannot be further parsed because of the encryption.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl asn1parse -inform pem -in private-enc.pem
    0:d=0  hl=4 l=1311 cons: SEQUENCE          
    4:d=1  hl=2 l=  73 cons: SEQUENCE          
    6:d=2  hl=2 l=   9 prim: OBJECT            :PBES2
   17:d=2  hl=2 l=  60 cons: SEQUENCE          
   19:d=3  hl=2 l=  27 cons: SEQUENCE          
   21:d=4  hl=2 l=   9 prim: OBJECT            :PBKDF2
   32:d=4  hl=2 l=  14 cons: SEQUENCE          
   34:d=5  hl=2 l=   8 prim: OCTET STRING      [HEX DUMP]:7FBE6B5C86A4B922
   44:d=5  hl=2 l=   2 prim: INTEGER           :0800
   48:d=3  hl=2 l=  29 cons: SEQUENCE          
   50:d=4  hl=2 l=   9 prim: OBJECT            :aes-256-cbc
   61:d=4  hl=2 l=  16 prim: OCTET STRING      [HEX DUMP]:7FC1CC749F456498F01E43108E4340DE
   79:d=1  hl=4 l=1232 prim: OCTET STRING      [HEX DUMP]:A5581EDC2797FC4E1AD0B66A00B765900AF1164D8
   F67458C1A4E72F54A65F2B8C0C5AD7E42584B95161FD98FBECA07D8E1049687C365ED157C45F1B57B175D2EF778A1FE7
   D12E50C0DF4248F0E1469DA40F9948581F16546F9582D9DCA83AC07C9466A6E3E6CE98CC241C44DAB32F5891B96DE302
   4B6E6A0F4980C6286D6EB8AA1680AD132810EEFB127DE42968142F4F9A4A2CE55A560C054C54DFFBB720A81F3F50A2A6
   3D748CE06309F55340BD4C74980C48F4C9D41650568A62BBE8E0337653BD4A2F7D47C3A24514B5D3100ED40C164831C6
   5A96DC90AD20F4AEF02E00203B0F0B2D550987AEE8F4C7E0E7C0CFF426B465D3CF568D02EE86AF043345954B0AAA649F
   A9F80E026E2A189EC60772A058615DCFEC9EC4D2D12CDEB7844EAA00202E435A0B9B0A28AC4F2DA213214F773A2319D5
   5A560D5C99246F9895F5EF04D97FF1CE26EFC2FF82249F6E94253CB92EE0A74AE3942285C2DFFC77883709E7FF2569FD
   9C8F58C112CD4A125E40E7BC8599242D71DE7D48416B6A36FBE0B90BA9A05AFB982CAE9AD337C2318582AA328ABC341F
   BB1C036DE334DE327DEC97BA757CBBAED26F25DD74BD8BE9215B479CD49D8357AFA5289A0265ADE025F9FC0CDB1CDBF0
   4C812F20B7CEB58BF12C1FD1756AABD7F557B87E1D245E8062D1DF4078D77AD98BFDF0C0F3A06A7FA11BFAE0EBF8F3EE
   1F8AB0D6D7C905D4D238E2738613EA753E044589CEBDF3714CACEC298653FA45AF5977BDCF23B5DD60B479C7958B8AC1
   8CAA4AA4A79C283805246675BBB8D2D0E5B714320E7E6FE8B2EF73DB9839095229B9653726AB9689B19AB47113F70204
   83B2D1A82FE2EB9ABAB429DDF5ACDEBCAB62BABD48D2DBA1D398B03F9919F1DAC8CDA19D39BBAF2B5FE96C43E78F565C
   465019DF88E71BCE35C6F7F8BE87EB384FA1193345E47CA9382BCEFFC2E6B37681E8D95EB48BC7044F7DCA743217D4C0
   81200502E98EC2CFAA9D17277D5385E65CC8104DA999E31532A8B9B3B4D3E219613AE09BC9F10553CC4E5F135ACD3FB4
   A3BBAB21839CEFBBC0D4BB16AE4FBD7407E6E3709B059BD86AFFE032805CE5FB0B8005009B5964B79E478DA7FE88C20D
   D2FEDA10A0EB3433ADC90AF5DD8772B840A5CD7C5E32D96153E41F12BA501EF1F48C4E20CB0120CFBB6F546C2B6E22E0
   834CB9DFBFA4834FEB4B7374788F781A1634ABF9D1FD014E6DB3749E6A086155521ADB9F271D6BF6F60455903B1D913D
   A639EE9F5CA5135FD2A1873FF35EAB8C151C5B90826E4303233D4BB053EBD929107874CDCCADFFF492A7CB595EADF03E
   4C0FE15326752898F1B9AA3EAC9907D9F276E6AB37AFA34FF8F3DBAB7B009754CF1A13029CD6857686105830F0CF6E99
   476CB07ECAAEA8B5CCC2720479423F8504E783D6712E424C636DAB41203D9EC76F47C4B56F453C42E5626048C24CC585
   F0710514EEF6D4C9644E0721CEAE9F885FBD672742A555095A895C7F0D4E814BEF4D223B13285E95BEDF7357D3545784
   32C1EBB63A6EF1D83E21A08DADA073BF9419C7A3185BB492A13569F262683E7CD86EC66CF671C919789038598EFEC22B
   C8EA1E265A4E0864F9E7253BE32457AC1B186722F3D0FF4AD450D04BA97D5B7DC1AA617DBD25EE8EC912072ABCBF5394
   D08AA276732666D4C349196940BFE869DA909EC03A8E25B23339EE50453CB5F81400B1380CA46AF0FC012CA55F322C1C
   5806E5D76D4CD8308B8FDFE
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h3 id="openssl-and-rsa-keys"&gt;OpenSSL and RSA keys&lt;/h3&gt;&lt;p&gt;Another way to look into a private key with OpenSSL is to use the module &lt;code&gt;rsa&lt;/code&gt;. While the module &lt;code&gt;asn1parse&lt;/code&gt; is a generic ASN.1 parser, the module &lt;code&gt;rsa&lt;/code&gt; knows the structure of an RSA key and can properly output the field names&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl rsa -in private.pem -noout -text
Private-Key: (2048 bit)
modulus:
    00:b2:f5:fd:3f:9f:09:17:11:2c:e4:2f:8b:f8:7e:
    d6:76:e1:52:58:be:44:3f:36:de:af:b0:b6:9b:de:
    24:96:b4:95:ea:ad:1b:01:ca:d8:42:71:b0:14:e9:
    6f:79:38:6c:63:6d:34:85:16:da:74:a6:8a:8c:70:
    fb:a8:82:87:0c:47:b4:21:8d:8f:49:18:6d:df:72:
    72:7b:9d:80:c2:19:11:c3:e3:37:c6:e4:07:ff:b4:
    7c:2f:27:67:b0:d1:64:d8:a1:e9:af:95:f6:48:1b:
    f8:d9:ed:fb:2e:39:04:b2:52:92:68:c4:60:25:6f:
    af:d0:a6:77:d2:98:98:f1:0b:1d:15:12:8a:69:58:
    39:fc:08:ed:d5:84:e8:33:56:15:b1:d1:d7:27:7b:
    e6:5c:53:2d:ca:92:dd:c7:05:03:74:86:8b:11:7e:
    a9:15:49:14:ef:92:92:b8:44:3f:13:69:6e:4f:ad:
    50:de:d6:bd:90:e5:a6:f7:ed:33:be:2e:ce:31:c6:
    dd:7a:42:53:ee:6c:dc:56:78:7d:dd:1d:5c:d7:76:
    61:40:22:db:87:d0:3b:b2:2f:23:28:5b:5a:31:67:
    af:8d:ac:ab:be:a4:00:04:47:13:37:d3:78:1e:8c:
    5c:ca:0e:a5:e2:77:99:b5:10:e4:ef:93:8c:61:ca:
    a6:0d
publicExponent: 65537 (0x10001)
privateExponent:
    00:b2:42:55:00:0a:6a:03:90:18:27:33:35:39:51:
    1e:4f:4c:21:ba:43:cb:b7:2b:f0:a5:10:60:d4:e1:
    71:90:ac:50:a8:71:c5:75:03:98:66:96:d7:cd:fc:
    b8:0d:07:26:ef:e2:d7:6d:ba:55:df:dc:04:25:e0:
    64:cc:75:38:10:03:5c:6a:0f:97:aa:37:ab:39:e7:
    c6:21:5b:c1:e5:95:13:1d:0c:37:82:e5:a1:12:13:
    b5:9f:42:a1:06:7f:8c:f4:3c:53:89:92:d6:be:fd:
    1d:e3:f6:29:3c:e1:8e:cc:11:73:c4:e7:d6:dd:73:
    62:ad:73:23:e7:a2:18:b5:ff:b0:f2:45:eb:79:63:
    27:cc:87:49:3e:dd:13:42:34:ed:5f:3b:14:a4:c4:
    d9:23:74:59:7f:64:a6:d3:cb:2c:10:f0:cd:2d:57:
    e9:9f:58:c8:d2:8f:20:49:d1:43:3c:c4:bd:67:70:
    17:ad:1b:dd:1c:83:cf:b8:fb:7e:8c:8f:dc:f0:b4:
    fb:77:de:7b:82:85:74:9c:ed:fb:fd:68:78:f7:f7:
    93:00:73:f0:f4:2a:dd:cb:a8:38:5d:7e:d0:5c:df:
    ca:a2:a2:ba:75:76:01:72:3a:96:20:1f:ec:cc:2e:
    65:c6:5e:14:f6:5f:1d:34:d6:ec:df:e3:f8:54:01:
    80:01
prime1:
    00:e1:d1:63:89:bf:6e:ff:7a:e4:4f:65:71:06:ed:
    81:c8:1a:48:b5:fb:35:6f:83:dd:4a:22:9e:86:54:
    bd:c0:36:71:6b:bd:9d:46:df:d1:49:81:32:54:50:
    54:95:8a:ca:5c:fd:a7:09:d9:7c:c8:c6:a9:e9:20:
    3d:05:f7:b9:d4:5e:68:5a:19:a5:f5:82:67:fc:b1:
    7f:cf:50:2b:32:cf:ed:b9:4c:ae:a5:8e:e5:f6:3e:
    ba:5f:33:d0:99:46:c8:65:21:32:34:44:10:d3:d6:
    58:74:8b:ca:e2:56:f2:48:96:c2:a9:ad:93:40:d3:
    c8:39:26:52:da:8e:d7:34:6d
prime2:
    00:ca:e1:55:c9:b3:a4:54:6b:5f:c3:cf:4c:c8:0d:
    53:9d:53:1c:40:6b:ac:5e:d8:28:18:e9:77:b4:96:
    f9:f6:14:ce:fb:11:79:e3:bf:bf:ab:22:bc:a7:f8:
    8e:bb:8c:9b:13:27:ae:70:11:32:42:df:f0:86:63:
    70:b6:c7:67:82:db:d5:0d:be:1f:ee:9b:33:16:b9:
    aa:c7:ba:bb:7c:fa:0a:9e:f2:6c:3c:97:6c:f6:2d:
    a8:f4:1e:fe:06:54:58:dc:7c:1c:bc:a7:8f:b1:cb:
    4f:f7:aa:50:d1:16:ce:16:40:95:6a:4e:89:ea:df:
    52:93:fa:a1:3a:23:49:f4:21
exponent1:
    00:bc:3b:93:32:4e:6d:92:ee:78:83:aa:36:66:24:
    f2:8a:bf:46:1e:d3:b0:be:2c:f7:f8:05:15:89:39:
    f8:15:d2:0c:07:58:3e:52:c6:dc:a8:dd:d5:fb:2c:
    1e:e5:ac:94:74:a1:47:6c:d1:6a:cf:dd:b1:e2:4e:
    ea:2f:20:49:39:ba:1c:58:06:8b:2d:34:2f:c4:16:
    9d:48:4d:36:45:1b:c7:b8:2f:30:61:76:d5:3f:c7:
    18:09:a5:a2:5b:32:02:77:32:0d:ac:3d:94:9d:50:
    4d:d9:90:71:64:ec:3e:f7:bd:1b:b4:de:a8:21:60:
    a7:c4:e3:aa:2a:de:e8:8a:9d
exponent2:
    29:15:e9:21:a7:d7:a7:a0:f7:0b:d8:77:5c:2c:16:
    ba:cd:91:f3:19:db:16:79:ff:e4:cb:a3:0a:57:68:
    d7:84:ef:45:b9:0c:4e:2b:0e:cd:c1:83:23:21:1b:
    06:b0:3a:d7:6e:39:cd:48:2e:3d:8c:cc:50:ea:e2:
    70:a1:81:3c:e6:f8:06:88:72:3f:07:ff:18:a3:11:
    0a:d1:ae:16:69:2c:ad:73:ba:a7:aa:a2:ce:58:00:
    d7:2f:4f:92:48:92:96:54:2c:1d:a8:71:59:38:2b:
    41:a4:a4:29:33:cd:18:84:8b:bd:b3:9a:0a:8e:9f:
    52:88:77:0e:27:07:5b:01
coefficient:
    3a:b4:e3:b8:41:ab:23:45:15:bf:0a:8d:2e:40:fb:
    6e:95:38:97:02:d8:34:47:4e:9a:d8:49:12:4d:c6:
    c1:d3:42:73:8d:4e:75:10:26:5d:f6:b7:44:eb:aa:
    4a:88:a7:99:53:46:be:ef:04:7d:b0:24:ce:8b:2a:
    4e:39:23:b0:56:63:89:94:8a:b0:bb:b0:31:87:97:
    70:da:14:f4:41:8a:eb:75:ae:98:34:91:22:a2:d9:
    53:51:17:b0:5b:ef:93:8a:12:11:a3:be:6e:88:29:
    57:bc:2a:5f:1d:e5:ca:50:c2:6f:42:ee:0a:38:3a:
    2a:2b:63:40:d5:2e:1a:36
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The fields are the same we found in the ASN.1 structure, but in this representation we have a better view of the specific values of the RSA key. You can compare the two and see that the value of the fields are the same.&lt;/p&gt;&lt;p&gt;If you want to learn something about RSA, try to investigate the historical reasons behind the choice of 65537 as a common public exponent (as you can see here in the section &lt;code&gt;publicExponent&lt;/code&gt;).&lt;/p&gt;&lt;h3 id="pkcs-8-vs-pkcs-1"&gt;PKCS #8 vs PKCS #1&lt;/h3&gt;&lt;p&gt;The first version of the PKCS standard (PKCS #1) was specifically tailored to contain an RSA key. Its ASN.1 definition can be found in &lt;a href="https://tools.ietf.org/html/rfc8017"&gt;RFC 8017&lt;/a&gt; ("PKCS #1: RSA Cryptography Specifications Version 2.2")&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;RSAPublicKey ::= SEQUENCE {
    modulus           INTEGER,  -- n
    publicExponent    INTEGER   -- e
}

RSAPrivateKey ::= SEQUENCE {
    version           Version,
    modulus           INTEGER,  -- n
    publicExponent    INTEGER,  -- e
    privateExponent   INTEGER,  -- d
    prime1            INTEGER,  -- p
    prime2            INTEGER,  -- q
    exponent1         INTEGER,  -- d mod (p-1)
    exponent2         INTEGER,  -- d mod (q-1)
    coefficient       INTEGER,  -- (inverse of q) mod p
    otherPrimeInfos   OtherPrimeInfos OPTIONAL
}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Subsequently, as the need to describe new types of algorithms increased, the PKCS #8 standard was developed. This can contain different types of keys, and defines a specific field for the algorithm identifier. Its ASN.1 definition can be found in &lt;a href="https://tools.ietf.org/html/rfc5958"&gt;RFC 5958&lt;/a&gt; ("Asymmetric Key Packages")&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;OneAsymmetricKey ::= SEQUENCE {
     version                   Version,
     privateKeyAlgorithm       PrivateKeyAlgorithmIdentifier,
     privateKey                PrivateKey,
     attributes            [0] Attributes OPTIONAL,
     ...,
     [[2: publicKey        [1] PublicKey OPTIONAL ]],
     ...
   }

PrivateKey ::= OCTET STRING
                     -- Content varies based on type of key. The
                     -- algorithm identifier dictates the format of
                     -- the key.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The definition of the field &lt;code&gt;PrivateKey&lt;/code&gt; for the RSA algorithm is the same used in PKCS #1.&lt;/p&gt;&lt;p&gt;If the PEM format uses PKCS #8 its header and footer are&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN PRIVATE KEY-----
[...]
-----END PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;If it uses PKCS #1, however, there has to be an external identification of the algorithm, so the header and footer are&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN RSA PRIVATE KEY-----
[...]
-----END RSA PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The structure of PKCS #8 is the reason why we had to parse the field at offset 22 to access the RSA parameters when using the module &lt;code&gt;asn1parse&lt;/code&gt; of OpenSSL. If you are parsing a PKCS #1 key in PEM format you don't need this second step.&lt;/p&gt;&lt;h2 id="private-and-public-key"&gt;Private and public key&lt;a class="headerlink" href="#private-and-public-key" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In the RSA algorithm the public key is built using the modulus and the public exponent, which means that we can always derive the public key from the private key. OpenSSL can easily do this with the module &lt;code&gt;rsa&lt;/code&gt;, producing the public key in PEM format&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl rsa -in private.pem -pubout
writing RSA key
-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsvX9P58JFxEs5C+L+H7W
duFSWL5EPzber7C2m94klrSV6q0bAcrYQnGwFOlveThsY200hRbadKaKjHD7qIKH
DEe0IY2PSRht33Jye52AwhkRw+M3xuQH/7R8LydnsNFk2KHpr5X2SBv42e37LjkE
slKSaMRgJW+v0KZ30piY8QsdFRKKaVg5/Ajt1YToM1YVsdHXJ3vmXFMtypLdxwUD
dIaLEX6pFUkU75KSuEQ/E2luT61Q3ta9kOWm9+0zvi7OMcbdekJT7mzcVnh93R1c
13ZhQCLbh9A7si8jKFtaMWevjayrvqQABEcTN9N4Hoxcyg6l4neZtRDk75OMYcqm
DQIDAQAB
-----END PUBLIC KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can dump the information in the public key specifying the flag &lt;code&gt;-pubin&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl rsa -in public.pem -noout -text -pubin
Public-Key: (2048 bit)
Modulus:
    00:b2:f5:fd:3f:9f:09:17:11:2c:e4:2f:8b:f8:7e:
    d6:76:e1:52:58:be:44:3f:36:de:af:b0:b6:9b:de:
    24:96:b4:95:ea:ad:1b:01:ca:d8:42:71:b0:14:e9:
    6f:79:38:6c:63:6d:34:85:16:da:74:a6:8a:8c:70:
    fb:a8:82:87:0c:47:b4:21:8d:8f:49:18:6d:df:72:
    72:7b:9d:80:c2:19:11:c3:e3:37:c6:e4:07:ff:b4:
    7c:2f:27:67:b0:d1:64:d8:a1:e9:af:95:f6:48:1b:
    f8:d9:ed:fb:2e:39:04:b2:52:92:68:c4:60:25:6f:
    af:d0:a6:77:d2:98:98:f1:0b:1d:15:12:8a:69:58:
    39:fc:08:ed:d5:84:e8:33:56:15:b1:d1:d7:27:7b:
    e6:5c:53:2d:ca:92:dd:c7:05:03:74:86:8b:11:7e:
    a9:15:49:14:ef:92:92:b8:44:3f:13:69:6e:4f:ad:
    50:de:d6:bd:90:e5:a6:f7:ed:33:be:2e:ce:31:c6:
    dd:7a:42:53:ee:6c:dc:56:78:7d:dd:1d:5c:d7:76:
    61:40:22:db:87:d0:3b:b2:2f:23:28:5b:5a:31:67:
    af:8d:ac:ab:be:a4:00:04:47:13:37:d3:78:1e:8c:
    5c:ca:0e:a5:e2:77:99:b5:10:e4:ef:93:8c:61:ca:
    a6:0d
Exponent: 65537 (0x10001)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="generating-key-pairs-with-openssl"&gt;Generating key pairs with OpenSSL&lt;a class="headerlink" href="#generating-key-pairs-with-openssl" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;If you want to generate an RSA private key you can do it with OpenSSL&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl genpkey -algorithm RSA -out private.pem \
  -pkeyopt rsa_keygen_bits:2048
......................................................................+++
..........+++ 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Since OpenSSL is a collection of modules, we specify &lt;code&gt;genpkey&lt;/code&gt; to generate a private key. The option &lt;code&gt;-algorithm&lt;/code&gt; specifies which algorithm we want to use to generate the key (RSA in this case), &lt;code&gt;-out&lt;/code&gt; specifies the name of the output file, and &lt;code&gt;-pkeyopt&lt;/code&gt; allows us to set the value for specific key options. In this case the length of the RSA key in bits.&lt;/p&gt;&lt;p&gt;If you want an encrypted key you can generate one specifying the cipher (for example &lt;code&gt;-aes-256-cbc&lt;/code&gt;)&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ openssl genpkey -algorithm RSA -out private-enc.pem \
  -aes-256-cbc -pkeyopt rsa_keygen_bits:2048
...........................+++
..........+++
Enter PEM pass phrase:
Verifying - Enter PEM pass phrase:
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can see the list of supported ciphers with &lt;code&gt;openssl list-cipher-algorithms&lt;/code&gt;. In both cases you can then extract the public key with the method shown previously. OpenSSL private keys are created using PKCS #8, so unencrypted keys will be in the form&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN PRIVATE KEY-----
[...]
-----END PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;and encrypted ones in the form&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN ENCRYPTED PRIVATE KEY-----
[...]
-----END ENCRYPTED PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="generating-key-pairs-with-openssh"&gt;Generating key pairs with OpenSSH&lt;a class="headerlink" href="#generating-key-pairs-with-openssh" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Another tool that you can use to generate key pairs is ssh-keygen, which is a tool included in the SSH suite that is specifically used to create and manage SSH keys. As SSH keys are standard asymmetrical keys we can use the tool to create keys for other purposes.&lt;/p&gt;&lt;p&gt;To create a key pair just run&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh-keygen -m PEM -t rsa -b 2048 -f key
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The option &lt;code&gt;-m&lt;/code&gt; specifies the key format. By default OpenSSH uses its own format specified in &lt;a href="https://tools.ietf.org/html/rfc4716"&gt;RFC 4716&lt;/a&gt; ("The Secure Shell (SSH) Public Key File Format").&lt;/p&gt;&lt;p&gt;The option &lt;code&gt;-t&lt;/code&gt; specifies the key generation algorithm (RSA in this case), while the option &lt;code&gt;-b&lt;/code&gt; specifies the length of the key in bits.&lt;/p&gt;&lt;p&gt;The option &lt;code&gt;-f&lt;/code&gt; sets the name of the output file. If not present, ssh-keygen will ask the name of the file, offering to save it to the default file &lt;code&gt;~/.ssh/id_rsa&lt;/code&gt;. The tool always asks for a password to encrypt the key, but you are allowed to enter an empty one to skip the encryption.&lt;/p&gt;&lt;p&gt;This tool creates two files. One is the private key file, named as requested, and the second is the public key file, named like the private key one but with the extension &lt;code&gt;.pub&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The value &lt;code&gt;PEM&lt;/code&gt; specified for the option &lt;code&gt;-m&lt;/code&gt; writes the private key using the PKCS #1 format, so the key will be in the form&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN RSA PRIVATE KEY-----
[...]
-----END RSA PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Using &lt;code&gt;-m PKCS8&lt;/code&gt; instead uses PKCS #8 and the key will be in the form&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----BEGIN PRIVATE KEY-----
[...]
-----END PRIVATE KEY-----
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h3 id="the-openssh-public-key-format"&gt;The OpenSSH public key format&lt;/h3&gt;&lt;p&gt;The public key saved by ssh-keygen is written in the so-called SSH-format, which is not a standard in the cryptography world. It's structure is &lt;code&gt;ALGORITHM KEY COMMENT&lt;/code&gt;, where the &lt;code&gt;KEY&lt;/code&gt; part of the format is encoded with Base64.&lt;/p&gt;&lt;p&gt;For example&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCy9f0/nwkXESzkL4v4ftZ24VJYvkQ/Nt6vsLab3iSWtJXqrRsBythCcbAU6W9
5OGxjbTSFFtp0poqMcPuogocMR7QhjY9JGG3fcnJ7nYDCGRHD4zfG5Af/tHwvJ2ew0WTYoemvlfZIG/jZ7fsuOQSyUpJoxGAlb6
/QpnfSmJjxCx0VEoppWDn8CO3VhOgzVhWx0dcne+ZcUy3Kkt3HBQN0hosRfqkVSRTvkpK4RD8TaW5PrVDe1r2Q5ab37TO+Ls4xx
t16QlPubNxWeH3dHVzXdmFAItuH0DuyLyMoW1oxZ6+NrKu+pAAERxM303gejFzKDqXid5m1EOTvk4xhyqYN user@host
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;To manually decode the central part of the key you can use &lt;code&gt;base64&lt;/code&gt; and &lt;code&gt;hexdump&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat key.pub | cut -d &amp;quot; &amp;quot; -f2 | \
  base64 -d | hexdump -ve &amp;#39;/1 &amp;quot;%02x &amp;quot;&amp;#39; -e &amp;#39;2/8 &amp;quot;\n&amp;quot;&amp;#39;
00 00 00 07 73 73 68 2d 72 73 61 00 00 00 03 01
00 01 00 00 01 01 00 b2 f5 fd 3f 9f 09 17 11 2c
e4 2f 8b f8 7e d6 76 e1 52 58 be 44 3f 36 de af
b0 b6 9b de 24 96 b4 95 ea ad 1b 01 ca d8 42 71
b0 14 e9 6f 79 38 6c 63 6d 34 85 16 da 74 a6 8a
8c 70 fb a8 82 87 0c 47 b4 21 8d 8f 49 18 6d df
72 72 7b 9d 80 c2 19 11 c3 e3 37 c6 e4 07 ff b4
7c 2f 27 67 b0 d1 64 d8 a1 e9 af 95 f6 48 1b f8
d9 ed fb 2e 39 04 b2 52 92 68 c4 60 25 6f af d0
a6 77 d2 98 98 f1 0b 1d 15 12 8a 69 58 39 fc 08
ed d5 84 e8 33 56 15 b1 d1 d7 27 7b e6 5c 53 2d
ca 92 dd c7 05 03 74 86 8b 11 7e a9 15 49 14 ef
92 92 b8 44 3f 13 69 6e 4f ad 50 de d6 bd 90 e5
a6 f7 ed 33 be 2e ce 31 c6 dd 7a 42 53 ee 6c dc
56 78 7d dd 1d 5c d7 76 61 40 22 db 87 d0 3b b2
2f 23 28 5b 5a 31 67 af 8d ac ab be a4 00 04 47
13 37 d3 78 1e 8c 5c ca 0e a5 e2 77 99 b5 10 e4
ef 93 8c 61 ca a6 0d
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The structure of this binary file is pretty simple, and is described in two different RFCs. &lt;a href="https://tools.ietf.org/html/rfc4253"&gt;RFC 4253&lt;/a&gt; ("SSH Transport Layer Protocol") states in section 6.6 that&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;The &amp;quot;ssh-rsa&amp;quot; key format has the following specific encoding:

      string    &amp;quot;ssh-rsa&amp;quot;
      mpint     e
      mpint     n
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;while the definition of the types &lt;code&gt;string&lt;/code&gt; and &lt;code&gt;mpint&lt;/code&gt; can be found in &lt;a href="https://tools.ietf.org/html/rfc4251"&gt;RFC 4251&lt;/a&gt; ("SSH Protocol Architecture"), section 5&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;string

    [...] They are stored as a uint32 containing its length
    (number of bytes that follow) and zero (= empty string) or more
    bytes that are the value of the string.  Terminating null
    characters are not used. [...]

mpint

    Represents multiple precision integers in two&amp;#39;s complement format,
    stored as a string, 8 bits per byte, MSB first. [...]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This means that the above sequence of bytes is interpreted as 4 bytes of length (32 bits of the type &lt;code&gt;uint32&lt;/code&gt;) followed by that number of bytes of content.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(4 bytes)   00 00 00 07          = 7
(7 bytes)   73 73 68 2d 72 73 61 = &amp;quot;ssh-rsa&amp;quot; (US-ASCII)
(4 bytes)   00 00 00 03          = 3
(3 bytes)   01 00 01             = 65537 (a common value for the RSA exponent)
(4 bytes)   00 00 01 01          = 257
(257 bytes) 00 b2 .. ca a6 0d    = The key modulus
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that since we created a key of 2048 bits we should have a modulus of 256 bytes. Instead this key uses 257 bytes prefixing the number with a byte &lt;code&gt;00&lt;/code&gt; to avoid it being interpreted as negative (two's complement format).&lt;/p&gt;&lt;p&gt;The structure shown above is the reason why all the RSA public SSH keys start with the same 12 characters &lt;code&gt;AAAAB3NzaC1y&lt;/code&gt;. This string, converted in Base64 gives the initial 9 bytes &lt;code&gt;00 00 00 07 73 73 68 2d 72&lt;/code&gt; (Base64 characters are not a one-to-one mapping of the source bytes). If the exponent is the standard 65537 the key starts with &lt;code&gt;AAAAB3NzaC1yc2EAAAADAQAB&lt;/code&gt;, which encoded gives the fist 18 bytes &lt;code&gt;00 00 00 07 73 73 68 2d 72 73 61 00 00 00 03 01 00 01&lt;/code&gt;. &lt;/p&gt;&lt;h2 id="converting-between-pem-and-openssh-format"&gt;Converting between PEM and OpenSSH format&lt;a class="headerlink" href="#converting-between-pem-and-openssh-format" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We often need to convert files created with one tool to a different format, so this is a list of the most common conversions you might need. I prefer to consider the key format instead of the source tool, but I give a short description of the reason why you should want to perform the conversion.&lt;/p&gt;&lt;h3 id="pempkcs1-to-pempkcs8"&gt;PEM/PKCS#1 to PEM/PKCS#8&lt;/h3&gt;&lt;p&gt;This is useful to convert OpenSSH private keys to a newer format.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;openssl pkcs8 -topk8 -inform PEM -outform PEM -in pkcs1.pem -out pkcs8.pem
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h3 id="openssh-public-to-pempkcs8"&gt;OpenSSH public to PEM/PKCS#8&lt;/h3&gt;&lt;p&gt;To convert public OpenSSH keys in a PEM format using PKCS #8 (prints to stdout)&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh-keygen -e -f public.pub -m PKCS8
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This is easy to remember because &lt;code&gt;-e&lt;/code&gt; stands for export. Note that you can also use &lt;code&gt;-m PEM&lt;/code&gt; to convert the key into a PEM format that uses PKCS #1.&lt;/p&gt;&lt;h3 id="pempkcs8-to-openssh-public"&gt;PEM/PKCS#8 to OpenSSH public&lt;/h3&gt;&lt;p&gt;If you need to use in SSH a key pair created with another system &lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh-keygen -i -f public.pem -m PKCS8
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This is easy to remember because &lt;code&gt;-i&lt;/code&gt; stands for import. As happened when exporting the key, you can import a PEM/PKCS #1 key using &lt;code&gt;-m PEM&lt;/code&gt;.&lt;/p&gt;&lt;h2 id="reading-rsa-keys-in-python"&gt;Reading RSA keys in Python&lt;a class="headerlink" href="#reading-rsa-keys-in-python" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In Python you can use the package &lt;code&gt;pycrypto&lt;/code&gt; to access a PEM file containing an RSA key with the function &lt;code&gt;RSA.importKey&lt;/code&gt;. Now you can hopefully understand the &lt;a href="https://www.dlitz.net/software/pycrypto/api/current/Crypto.PublicKey.RSA-module.html"&gt;documentation&lt;/a&gt; that says&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;externKey (string) - The RSA key to import, encoded as a string.

An RSA public key can be in any of the following formats:
    * X.509 subjectPublicKeyInfo DER SEQUENCE (binary or PEM encoding)
    * PKCS#1 RSAPublicKey DER SEQUENCE (binary or PEM encoding)
    * OpenSSH (textual public key only)

An RSA private key can be in any of the following formats:
    * PKCS#1 RSAPrivateKey DER SEQUENCE (binary or PEM encoding)
    * PKCS#8 PrivateKeyInfo DER SEQUENCE (binary or PEM encoding)
    * OpenSSH (textual public key only)

For details about the PEM encoding, see RFC1421/RFC1423.

In case of PEM encoding, the private key can be encrypted with DES or 3TDES
according to a certain pass phrase. Only OpenSSL-compatible pass phrases are
supported.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In practice what you can do with a file &lt;code&gt;private.pem&lt;/code&gt; is&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;Crypto.PublicKey&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RSA&lt;/span&gt;

&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;private.pem&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RSA&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;importKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;and the variable &lt;code&gt;key&lt;/code&gt; will contain an instance of &lt;code&gt;_RSAobj&lt;/code&gt; (not a very pythonic name, to be honest). This instance contains the RSA parameters as attributes as stated in the &lt;a href="https://www.dlitz.net/software/pycrypto/api/current/Crypto.PublicKey.RSA._RSAobj-class.html"&gt;documentation&lt;/a&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;modulus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;
&lt;span class="n"&gt;public_exponent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;
&lt;span class="n"&gt;private_exponent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;
&lt;span class="n"&gt;first_prime_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;
&lt;span class="n"&gt;second_prime_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;
&lt;span class="n"&gt;q_inv_crt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;u&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="final-words"&gt;Final words&lt;a class="headerlink" href="#final-words" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I keep finding on StackOverflow (and on other boards) messages of users that are confused by RSA keys, the output of the various tools, and by the subtle but important differences between the formats, so I hope this post helped you to get a better understanding of the matter.&lt;/p&gt;&lt;h2 id="resources"&gt;Resources&lt;a class="headerlink" href="#resources" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;The Wikipedia article on &lt;a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)"&gt;RSA&lt;/a&gt;&lt;/li&gt;&lt;li&gt;OpenSSL documentation: &lt;a href="https://www.openssl.org/docs/man1.1.1/man1/asn1parse.html"&gt;asn1parse&lt;/a&gt;, &lt;a href="https://www.openssl.org/docs/man1.1.1/man1/rsa.html"&gt;rsa&lt;/a&gt;, &lt;a href="https://www.openssl.org/docs/man1.1.1/man1/genpkey.html"&gt;genpkey&lt;/a&gt;&lt;/li&gt;&lt;li&gt;The &lt;a href="https://en.wikipedia.org/wiki/Base64"&gt;Base64&lt;/a&gt; encoding&lt;/li&gt;&lt;li&gt;The Abstract Syntax Notation One &lt;a href="https://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One"&gt;ASN.1&lt;/a&gt; interface description language&lt;/li&gt;&lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc4251"&gt;RFC 4251 - The Secure Shell (SSH) Protocol Architecture&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc4253"&gt;RFC 4253 - The Secure Shell (SSH) Transport Layer Protocol&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc4716"&gt;RFC 4716 - The Secure Shell (SSH) Public Key File Format&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc5208"&gt;RFC 5208 - Public-Key Cryptography Standards (PKCS) #8: Private-Key Information Syntax Specification Version 1.2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc5958"&gt;RFC 5958 - Asymmetric Key Packages&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc7468"&gt;RFC 7468 - Textual Encodings of PKIX, PKCS, and CMS Structures&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc8017"&gt;RFC 8017 - PKCS #1: RSA Cryptography Specifications Version 2.2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.dlitz.net/software/pycrypto/"&gt;PyCrypto&lt;/a&gt; - The Python Cryptography Toolkit&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;</content><category term="Programming"></category><category term="algorithms"></category><category term="cryptography"></category><category term="devops"></category><category term="SSL"></category><category term="SSH"></category><category term="RSA"></category><category term="Python"></category></entry><entry><title>Exploring the Amiga - Part 2</title><link href="https://www.thedigitalcatonline.com/blog/2018/05/28/exploring-the-amiga-2/" rel="alternate"></link><published>2018-05-28T15:00:00+01:00</published><updated>2021-12-21T08:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2018-05-28:/blog/2018/05/28/exploring-the-amiga-2/</id><summary type="html">&lt;p&gt;The jump table of libraries in the Amiga system, types and structures of Kickstart 1.3&lt;/p&gt;</summary><content type="html">&lt;h2 id="the-library-jump-table"&gt;The library jump table&lt;a class="headerlink" href="#the-library-jump-table" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As already mentioned when a library is loaded in memory a jump table is created just before the library base address. This table contains the addresses of the functions exposed by the library, and Exec itself has one.&lt;/p&gt;&lt;p&gt;The jump table functions order for the Exec library is specified in one of the include files provided by the NDK, namely &lt;code&gt;include_i/exec/exec_lib.i&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    FUNCDEF Supervisor
    FUNCDEF execPrivate1
    FUNCDEF execPrivate2
    FUNCDEF execPrivate3
    ...
    FUNCDEF OpenLibrary
    ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see this file makes use of the &lt;code&gt;FUNCDEF&lt;/code&gt; macro, which is not provided and has to be implemented by the coder. The idea of the macro is very simple: as the order of the jump table does not change we can just replace the first &lt;code&gt;FUNCDEF&lt;/code&gt; with the offset of the first function in the library and then increment this offset with the default size of the jump address. The expected output of the macro is&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    _LVOSupervisor     EQU     -30
    _LVOexecPrivate1   EQU     -36
    _LVOexecPrivate2   EQU     -42
    _LVOexecPrivate3   EQU     -48
    ...
    _LVOOpenLibrary    EQU     -552
    ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that the name of the function has been replaced by another string prepending &lt;code&gt;_LVO&lt;/code&gt; to avoid clashes with the actual function definition (LVO stands for Library Vector Offset).&lt;/p&gt;&lt;p&gt;The above figures come from the "Special Constants" section contained in the &lt;code&gt;include_i/exec/libraries.i&lt;/code&gt; file&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;*------ Special Constants ---------------------------------------
LIB_VECTSIZE    EQU 6       ;Each library entry takes 6 bytes
LIB_RESERVED    EQU 4       ;Exec reserves the first 4 vectors
LIB_BASE        EQU -LIB_VECTSIZE
LIB_USERDEF     EQU LIB_BASE-(LIB_RESERVED*LIB_VECTSIZE) ;First user func
LIB_NONSTD      EQU LIB_USERDEF
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;AS you can see from the comments, Exec reserves the first 4 vectors, so the first function's address is &lt;code&gt;LIB_USERDEF&lt;/code&gt;. To understand why the addresses are negative and how the offset is computed let's get a snapshot of the library once it has been loaded in memory&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                               HIGHER MEMORY ADDRESSES
                             +-------------------------+
Last byte of the             | End of the library      |
library loaded in ---------&amp;gt; +-------------------------+
memory                       | [...]                   |
                             +-------------------------+
                             | Content of the library  |
                             +-------------------------+
                             | Library structure       |
Library base address ------&amp;gt; +-------------------------+
                             | 1st reserved vector     | 
                             +-------------------------+ &amp;lt;--- LIB_BASE
                             | 2nd reserved vector     | 
                             +-------------------------+ &amp;lt;--+
                             | 3rd reserved vector     |    | LIB_VECTSIZE
                             +-------------------------+ &amp;lt;--+
                             | 4th reserved vector     | 
                             +-------------------------+ 
                             | 1st defined function    | 
                             +-------------------------+ &amp;lt;--- LIB_USERDEF
                             | 2nd defined function    |
                             +-------------------------+
                             | [...]                   |
                             +-------------------------+
First byte of the            | End of the jump table   |
library loaded in ---------&amp;gt; +-------------------------+
memory                         LOWER MEMORY ADDRESSES
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can find an official version of this in the &lt;a href="http://amigadev.elowar.com/read/ADCD_2.1/AmigaMail_Vol2_guide/node0189.html"&gt;documentation &lt;/a&gt;. Pay attention that the picture in the documentation represents memory upside down, with lower memory addresses towards the top of the page.&lt;/p&gt;&lt;p&gt;As you can see the library is loaded as expected from the base address towards the higher memory addresses, but at the same time the jump table is prefixed &lt;em&gt;in reverse order&lt;/em&gt;. This is done to allow you to find the address of a function with a simple (negative) indexing instead of a more complex algorithm. Function number 1 is at address &lt;code&gt;-1 * address_size&lt;/code&gt;, function number 2 at address &lt;code&gt;-2 * address_size&lt;/code&gt;, etc.&lt;/p&gt;&lt;p&gt;This is why we use negative offsets to call library functions but positive ones to access the library data and structures.&lt;/p&gt;&lt;p&gt;You can also see from the figure where the Special Constants &lt;code&gt;LIB_BASE&lt;/code&gt; and &lt;code&gt;LIB_USERDEF&lt;/code&gt; are located. The actual values are&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;LIB_BASE    EQU -6
LIB_USERDEF EQU -30
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;A good definition of the &lt;code&gt;FUNCDEF&lt;/code&gt; macro, thus, is the following&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    INCLUDE &amp;quot;exec/libraries.i&amp;quot;

    MACRO   FUNCDEF
_LVO\1      EQU      FUNC_CNT
FUNC_CNT    SET      FUNC_CNT-LIB_VECTSIZE
    ENDM

FUNC_CNT    SET      LIB_USERDEF
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The last line initialises the &lt;code&gt;FUNC_CNT&lt;/code&gt; symbol with the &lt;code&gt;LIB_USERDEF&lt;/code&gt; value. Then each call of the &lt;code&gt;FUNCDEF &amp;lt;arg&amp;gt;&lt;/code&gt; macro does two things:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Creates the &lt;code&gt;_LVO&amp;lt;arg&amp;gt;&lt;/code&gt; symbol with value &lt;code&gt;FUNC_CNT&lt;/code&gt; (e.g. &lt;code&gt;_LVOSupervisor EQU -30&lt;/code&gt;)&lt;/li&gt;&lt;li&gt;Decrements the &lt;code&gt;FUNC_CNT&lt;/code&gt; symbol by &lt;code&gt;LIB_VECTSIZE&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Please note that the example &lt;code&gt;FUNCDEF&lt;/code&gt; that you can find (commented) in &lt;code&gt;libraries.i&lt;/code&gt; won't work out of the box as &lt;code&gt;FUNC_CNT&lt;/code&gt; is defined inside the macro itself, while it has to be already defined before the first use of the macro.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;*------ FUNCDEF is used to parse library offset tables.  Many applications
*------ need a special version of FUNCDEF - you provide your own macro
*------ to match your needs.  Here is an example:
*
*    FUNCDEF     MACRO
*    _LVO\1      EQU    FUNC_CNT
*    FUNC_CNT    SET    FUNC_CNT-6  * Standard offset-6 bytes each
*    FUNC_CNT    EQU    LIB_USERDEF * Skip 4 standard vectors
*                ENDM
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can put the &lt;code&gt;FUNCDEF&lt;/code&gt; macro code in a local include file like &lt;code&gt;funcdef.i&lt;/code&gt;. Including it your code allows you to use &lt;code&gt;_LVO&lt;/code&gt; prefixed labels for the functions that you want to load&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    INCLUDE &amp;quot;funcdef.i&amp;quot;
    INCLUDE &amp;quot;exec/exec_lib.i&amp;quot;

    move.l  4.w,a6
    clr.l   d0
    move.l  #libname,a1
    jsr     _LVOOpenLibrary(a6)

libname:
    dc.b &amp;quot;somename.library&amp;quot;,0
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Finally, if you want to be even more explicit you can use the &lt;code&gt;CALLLIB&lt;/code&gt; macro defined in &lt;code&gt;libraries.i&lt;/code&gt; and write&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    INCLUDE &amp;quot;funcdef.i&amp;quot;
    INCLUDE &amp;quot;exec/exec_lib.i&amp;quot;
    INCLUDE &amp;quot;exec/libraries.i&amp;quot;

    move.l  4.w,a6
    clr.l   d0
    move.l  #libname,a1
    CALLLIB _LVOOpenLibrary

libname:
    dc.b &amp;quot;somename.library&amp;quot;,0
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;h2 id="the-four-reserved-vectors"&gt;The four reserved vectors&lt;a class="headerlink" href="#the-four-reserved-vectors" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As we saw, the Amiga system reserves 4 vectors at the beginning of the jump table of a library. These 4 spaces host 3 standard functions that shall be provided by any library, &lt;code&gt;Open()&lt;/code&gt;, &lt;code&gt;Close()&lt;/code&gt;, and &lt;code&gt;Expunge()&lt;/code&gt;. The fourth slot is kept for possible future expansions and must contain a function that returns 0.&lt;/p&gt;&lt;p&gt;The offsets of these functions are contained in the &lt;code&gt;include_i/exec/libraries.i&lt;/code&gt; file&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;*----------------------------------------------------------------
*
*   Standard Library Functions
*
*----------------------------------------------------------------

    LIBINIT LIB_BASE

    LIBDEF  LIB_OPEN
    LIBDEF  LIB_CLOSE
    LIBDEF  LIB_EXPUNGE ; must exist in all libraries
    LIBDEF  LIB_EXTFUNC ; for future expansion - must return zero.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;the effect of the above macros with the previous constants is&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;LIB_OPEN        EQU     -6
LIB_CLOSE       EQU     -12
LIB_EXPUNGE     EQU     -18
LIB_EXTFUNC     EQU     -24
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can try to follow the definitions of the &lt;code&gt;LIBINIT&lt;/code&gt; and &lt;code&gt;LIBDEF&lt;/code&gt; macros to obtain the same result.&lt;/p&gt;&lt;h2 id="types-and-structures"&gt;Types and structures&lt;a class="headerlink" href="#types-and-structures" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's see how the Exec library defines its types, which are the base components of the Amiga system. The main entry point for this investigation is the &lt;code&gt;include_i/exec/types.i&lt;/code&gt; file.&lt;/p&gt;&lt;p&gt;When working with data structures in Assembly, everything is expressed in terms of offsets. The main idea behind structures is to create something like this&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;STRUCT1         EQU     0
OFFS            SET     0
FIELD1          EQU     OFFS
OFFS            EQU     OFFS+SIZE_OF_FIELD1
FIELD2          EQU     OFFS
OFFS            EQU     OFFS+SIZE_OF_FIELD2
; ...
STRUCT1_SIZE    EQU     OFFS
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;which, once run through the macro expansion, creates the following code&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;STRUCT1         EQU     0
FIELD1          EQU     0
FIELD2          EQU     SIZE_OF_FIELD1
FIIELD3         EQU     SIZE_OF_FIELD1+SIZE_OF_FIELD2
; ...
STRUCT1_SIZE    EQU     SIZE_OF_FIELD1+...+SIZE_OF_FIELDn
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;So, the type macros are all defined with code like this&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TYPENAME    MACRO
\1          EQU     SOFFSET
SOFFSET     SET     SOFFSET+SIZE_OF_TYPE
            ENDM
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;For example the &lt;code&gt;BYTE&lt;/code&gt; macro is&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;BYTE        MACRO       ; byte (8 bits)
\1          EQU     SOFFSET
SOFFSET     SET     SOFFSET+1
            ENDM
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Note that the field is defined with &lt;code&gt;EQU&lt;/code&gt; to avoid unwanted overwrites, while &lt;code&gt;SOFFSET&lt;/code&gt; uses &lt;code&gt;SET&lt;/code&gt; that allows to redefine the symbol.&lt;/p&gt;&lt;p&gt;Let's see now how a real structure is defined. A good example is &lt;code&gt;LN&lt;/code&gt; defined in &lt;code&gt;include_i/exec/nodes.i&lt;/code&gt; which represents a node of a linked list.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;   STRUCTURE    LN,0    ; List Node
    APTR    LN_SUCC ; Pointer to next (successor)
    APTR    LN_PRED ; Pointer to previous (predecessor)
    UBYTE   LN_TYPE
    BYTE    LN_PRI  ; Priority, for sorting
    APTR    LN_NAME ; ID string, null terminated
    LABEL   LN_SIZE ; Note: word aligned
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;STRUCTURE&lt;/code&gt; macro is defined in &lt;code&gt;types.i&lt;/code&gt; as&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;STRUCTURE   MACRO       ; structure name, initial offset
\1          EQU     0
SOFFSET     SET     \2
            ENDM
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;And the resulting declarations, once the macros have been expanded, are the following&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;LN          EQU     0
LN_SUCC     EQU     0
LN_PRED     EQU     4
LN_TYPE     EQU     8
LN_PRI      EQU     9
LN_NAME     EQU     10
LN_SIZE     EQU     14
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see the field names are just offsets inside the structure, and there is no specific padding at the end to align the structure. In this case there is no need, as the structure size is already a multiple of a word (14 bytes).&lt;/p&gt;&lt;h3 id="how-to-align-structures"&gt;How to align structures&lt;/h3&gt;&lt;p&gt;If we need to align the bytes however we can use a little binary trick. If you ignore the least significant bit of a binary number you convert it to the nearest even number (downwards). An example in Python is&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;0b1101&amp;#39;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;0b1100&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can ignore the least significant bits with a simple bitwise AND&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s1"&gt;&amp;#39;0b1110&amp;#39;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="mb"&gt;0b1100&lt;/span&gt;
&lt;span class="mi"&gt;12&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;So, given the current offset, if we increase it by one and round down to the nearest integer we are aligning the offset to multiples of a word (2 bytes). The &lt;code&gt;ALIGNWORD&lt;/code&gt; macro in the &lt;code&gt;include_i/exec/types.i&lt;/code&gt; file implements exactly this algorithm&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ALIGNWORD   MACRO       ; Align structure offset to nearest word
SOFFSET     SET     (SOFFSET+1)&amp;amp;$fffffffe
            ENDM
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This can be seen in action in the &lt;code&gt;CardHandle&lt;/code&gt; structure defined in &lt;code&gt;include_i/resources/card.i&lt;/code&gt;. The same algorithm is implemented in other parts of the Kickstart code, for example in the &lt;code&gt;AddMemList&lt;/code&gt; function that adds memory space to the free memory pool.&lt;/p&gt;&lt;h2 id="markus-wandels-work"&gt;Markus Wandel's work&lt;a class="headerlink" href="#markus-wandels-work" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;After three years since I began this investigation I came across the work of Marcus Wandel (&lt;a href="http://wandel.ca"&gt;http://wandel.ca&lt;/a&gt;), advertised on &lt;a href="http://amigan.1emu.net/aw/TransactorUK-sep89.pdf"&gt;Amiga Transactor September 1989&lt;/a&gt;. Mr Wandel disassembled the whole Kickstart 1.2 ROM back in 1989, and you can find the result of his effort on his website at &lt;a href="http://wandel.ca/homepage/execdis/index.html"&gt;http://wandel.ca/homepage/execdis/index.html&lt;/a&gt;. I'm currently using his comments to check what I find out on my own, because I don't want to spoil the joy of discovery, and so far they confirmed I'm on the right path.&lt;/p&gt;&lt;p&gt;I think what Mr Wandel did is a great example of what computer science truly is. I'm sure his impressive contribution helped people to understand the Amiga system back in the ages, and it's definitely helping me 32 years later. Without the effort and the passion of people like Marcus Wandel, computer science would be just another corporate-owned environment.&lt;/p&gt;&lt;p&gt;Marcus's name is not as famous as that of other big players, but I consider his work extremely important. Thanks Marcus for your work and thanks to all the people who contributed to the Amiga, and to the rise of microcomputers.&lt;/p&gt;&lt;h2 id="whats-next"&gt;What's next&lt;a class="headerlink" href="#whats-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The next article will describe in depth how the jump table of the Exec library is created through the &lt;code&gt;MakeFunctions&lt;/code&gt; routine. This will be shown step by step discussing the reverse engineering method followed to discover the mechanism and the relevant code.&lt;/p&gt;&lt;h2 id="resources"&gt;Resources&lt;a class="headerlink" href="#resources" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;Amiga System Programmers Guide, Abacus - &lt;a href="https://archive.org/details/Amiga_System_Programmers_Guide_1988_Abacus"&gt;https://archive.org/details/Amiga_System_Programmers_Guide_1988_Abacus&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://amigadev.elowar.com"&gt;AmigaOS Developer Docs&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://wandel.ca/homepage/execdis/index.html"&gt;Marcus Wandel&amp;#x27;s disassmbly of Kickstart 1.2&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;</content><category term="Retro"></category><category term="assembly"></category><category term="amiga"></category><category term="retroprogramming"></category></entry><entry><title>Exploring the Amiga - Part 8</title><link href="https://www.thedigitalcatonline.com/blog/2019/02/19/exploring-the-amiga-8/" rel="alternate"></link><published>2019-02-19T14:00:00+01:00</published><updated>2021-12-20T08:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2019-02-19:/blog/2019/02/19/exploring-the-amiga-8/</id><summary type="html">&lt;p&gt;Branching in the M68k Assembly, memory list management in Kickstart 1.3&lt;/p&gt;</summary><content type="html">&lt;h2 id="branching"&gt;Branching&lt;a class="headerlink" href="#branching" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As branching is one of the most important ways to control the program flow it is worth discussing how it works in the Motorola 68000 processor, and review what options we have.&lt;/p&gt;&lt;p&gt;Contrary to what happens in higher level languages, in Assembly we do not have a way to represent logical expressions. In a language like C we can compare two integers with something like &lt;code&gt;a &amp;gt; b&lt;/code&gt; which tells us if the first number is greater than the second. But in Assembly there is no such syntax, so we have to rely on processor flags; these are bits that the processor sets according to the result of some operation, be it a direct comparison of two values or another instruction that manages integer numbers.&lt;/p&gt;&lt;p&gt;The Motorola 68000 flags are kept in the 5 least significant bits of the Status Register (SR). The latter is not available during the normal operations in user mode, but these 5 bits, called Condition Code Register (CCR) are always accessible. The 5 bits are named &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;N&lt;/code&gt;, &lt;code&gt;Z&lt;/code&gt;, &lt;code&gt;V&lt;/code&gt;, and &lt;code&gt;C&lt;/code&gt;. Of these, the ones we need to take into consideration for branching are the rightmost 4.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;N&lt;/code&gt; (Negative) is set to the value of the most significant bit of the result of an instruction, to show that a negative number was produced.&lt;/li&gt;&lt;li&gt;&lt;code&gt;Z&lt;/code&gt; (Zero) is set if the result is zero.&lt;/li&gt;&lt;li&gt;&lt;code&gt;V&lt;/code&gt; (Overflow) is set when an arithmetic operation results in a number that cannot be represented with the size of the operand.&lt;/li&gt;&lt;li&gt;&lt;code&gt;C&lt;/code&gt; (Carry) is set when an addition or a subtraction need to carry a bit (carry out or borrow).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;To branch according to the value of these flags we can use the &lt;code&gt;Bcc&lt;/code&gt; family of instruction, where &lt;code&gt;cc&lt;/code&gt; is a two-letter mnemonic that represents the condition that is under test. For example the condition &lt;code&gt;MI&lt;/code&gt; stands for &lt;code&gt;MInus&lt;/code&gt; and tests if the &lt;code&gt;N&lt;/code&gt; flag is set. Thus, &lt;code&gt;bmi &amp;lt;address&amp;gt;&lt;/code&gt; will branch to &lt;code&gt;&amp;lt;address&amp;gt;&lt;/code&gt; if the result of the previous instruction was negative, because that instruction set the &lt;code&gt;N&lt;/code&gt; flag.&lt;/p&gt;&lt;p&gt;There are multiple families of instructions that use the CCR: &lt;code&gt;Bcc&lt;/code&gt;, &lt;code&gt;DBcc&lt;/code&gt;, &lt;code&gt;Scc&lt;/code&gt;, and &lt;code&gt;TRAPcc&lt;/code&gt;. The following table lists all the possible conditions we can test on the Motorola 68000 and their meaning&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| Instruction | Full name        | Tested condition  | Notes                 |
|-------------|------------------|-------------------|-----------------------|
| CC          | Carry Clear      | C == 0            |                       |
| CS          | Carry Set        | C == 1            |                       |
| EQ          | EQual            | Z == 1            |                       |
| F           | False            | Always false      | Not available for Bcc |
| GE          | Greater or Equal | N == V            |                       |
| GT          | Greater Than     | N == V and Z == 0 |                       |
| HI          | HIgher than      | C == 0 and Z == 0 |                       |
| LE          | Less or Equal    | Z == 1 or N != V  |                       |
| LS          | Lower or Same    | C == 1 or Z == 1  |                       |
| LT          | Less Than        | N != V            |                       |
| MI          | MInus            | N == 1            |                       |
| NE          | Not Equal        | Z == 0            |                       |
| PL          | PLus             | N == 0            |                       |
| T           | True             | Always true       | Not available for Bcc |
| VC          | V Clear          | V == 0            |                       |
| VS          | V Set            | V == 1            |                       |
|-------------|------------------|-------------------|-----------------------|
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The reason why the &lt;code&gt;T&lt;/code&gt; and &lt;code&gt;F&lt;/code&gt; conditions are not available for &lt;code&gt;Bcc&lt;/code&gt; instructions is simple: &lt;code&gt;bt&lt;/code&gt; would mean "branch always", and the &lt;code&gt;bra&lt;/code&gt; instruction does exactly this, while &lt;code&gt;bf&lt;/code&gt; would mean "never branch" and it's arguably useless.&lt;/p&gt;&lt;p&gt;Let's see an example of use with a standard comparison instruction: &lt;code&gt;cmp&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cmp.w   d0,d1
beq.b   0x1522
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Here, the processor compares &lt;code&gt;d0&lt;/code&gt; and &lt;code&gt;d1&lt;/code&gt; computing the subtraction &lt;code&gt;d1 - d0&lt;/code&gt; and setting the CCR flags according to the nature of the result. The processors manual (Programmer's Reference Manual, section 4-75, page 179) tells us that the flags are affected according to these rules&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;X&lt;/code&gt; — Not affected.&lt;/li&gt;&lt;li&gt;&lt;code&gt;N&lt;/code&gt; — Set if the result is negative; cleared otherwise.&lt;/li&gt;&lt;li&gt;&lt;code&gt;Z&lt;/code&gt; — Set if the result is zero; cleared otherwise.&lt;/li&gt;&lt;li&gt;&lt;code&gt;V&lt;/code&gt; — Set if an overflow occurs; cleared otherwise.&lt;/li&gt;&lt;li&gt;&lt;code&gt;C&lt;/code&gt; — Set if a borrow occurs; cleared otherwise.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The &lt;code&gt;beq&lt;/code&gt; instruction on the second line checks only the &lt;code&gt;Z&lt;/code&gt; flag, however, so what we are checking here is if &lt;code&gt;d0&lt;/code&gt; and &lt;code&gt;d1&lt;/code&gt; have the same value.&lt;/p&gt;&lt;p&gt;A less straightforward example involves &lt;code&gt;move&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;move.w  0x1c(a1),d0
beq.b   0x151e
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The first line moves the value at &lt;code&gt;a1 + 0x1c&lt;/code&gt; into &lt;code&gt;d0&lt;/code&gt;. The &lt;code&gt;move&lt;/code&gt; instruction page (Programmer's Reference Manual, section 4-116, page 220) says that it affects only the &lt;code&gt;N&lt;/code&gt; and &lt;code&gt;Z&lt;/code&gt; flags&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;X&lt;/code&gt; — Not affected.&lt;/li&gt;&lt;li&gt;&lt;code&gt;N&lt;/code&gt; — Set if the result is negative; cleared otherwise.&lt;/li&gt;&lt;li&gt;&lt;code&gt;Z&lt;/code&gt; — Set if the result is zero; cleared otherwise.&lt;/li&gt;&lt;li&gt;&lt;code&gt;V&lt;/code&gt; — Always cleared.&lt;/li&gt;&lt;li&gt;&lt;code&gt;C&lt;/code&gt; — Always cleared.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Here, the tested result is the value that has been moved. So, the next line branches only if the address &lt;code&gt;a1 + 0x1c&lt;/code&gt; (and later &lt;code&gt;d0&lt;/code&gt;) contains a zero.&lt;/p&gt;&lt;p&gt;Pay attention that &lt;code&gt;GE&lt;/code&gt;, &lt;code&gt;GT&lt;/code&gt;, &lt;code&gt;LE&lt;/code&gt;, and &lt;code&gt;LT&lt;/code&gt; read &lt;code&gt;N&lt;/code&gt;, so they should be used only with signed integers Unsigned integers, instead, should be compared using &lt;code&gt;HI&lt;/code&gt; and &lt;code&gt;LS&lt;/code&gt;.&lt;/p&gt;&lt;h2 id="enqueue"&gt;Enqueue&lt;a class="headerlink" href="#enqueue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In the previous article we discussed the structure of a memory node created by &lt;code&gt;AddMemList&lt;/code&gt; and I briefly mentioned &lt;code&gt;Enqueue&lt;/code&gt; and a protected version of it. &lt;code&gt;Enqueue&lt;/code&gt; is the function that Exec uses to add a node into a linked list, following a simple schema based on priorities, but it turns out &lt;code&gt;AddMemList&lt;/code&gt; does not use it directly, resorting to a version of it wrapped by two other functions, namely &lt;code&gt;Forbid&lt;/code&gt; and &lt;code&gt;Permit&lt;/code&gt; that are connected to task rescheduling. For the time being, however, we may forget the wrappers and jump directly to &lt;code&gt;Enqueue&lt;/code&gt; and learn how the Amiga operating system was managing linked lists.&lt;/p&gt;&lt;p&gt;If the list we are managing is a singly linked list, where each node points to the successor only, we are forced to find the node &lt;em&gt;after which&lt;/em&gt; we want to insert the new one. This is mandatory, as we have to change its outgoing pointer, redirecting it to the new inserted node. In a doubly linked list such the ones used by the Amiga system this is not a problem, as from any point in the list we can start traversing it either forward or backward.&lt;/p&gt;&lt;p&gt;The following drawing is a simple representation of what happens in the Kickstart code when the &lt;code&gt;Enqueue&lt;/code&gt; function is executed. &lt;code&gt;Ins&lt;/code&gt; is the node we want to insert, &lt;code&gt;Pred&lt;/code&gt; is the node after which we will insert &lt;code&gt;Ins&lt;/code&gt;, and &lt;code&gt;Next&lt;/code&gt; is the node before which we will insert &lt;code&gt;Ins&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                                  TAILPRED  TAIL
                                     |       |
                                     v       v
BEFORE:       HEAD -&amp;gt; Node -&amp;gt; Pred -&amp;gt; Next -&amp;gt; Node -&amp;gt; 0x0


                                         TAILPRED  TAIL
                                            |       |
                                            v       v
AFTER:        HEAD -&amp;gt; Node -&amp;gt; Pred           Next -&amp;gt; Node -&amp;gt; 0x0
                                  |         ^
                                  |         |
                                  +-&amp;gt; Ins --+
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see there are several pointers that need to be changed. Both the &lt;code&gt;LN_SUCC&lt;/code&gt; of &lt;code&gt;Pred&lt;/code&gt; and &lt;code&gt;Ins&lt;/code&gt;, but also the &lt;code&gt;LN_PRED&lt;/code&gt; of &lt;code&gt;Next&lt;/code&gt; and &lt;code&gt;Ins&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Enqueue&lt;/code&gt; has a very simple prototype&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Enqueue(list, node)
        aO    a1
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;where &lt;code&gt;a0&lt;/code&gt; and &lt;code&gt;a1&lt;/code&gt; are pointers respectively to the list header and to the node we are going to insert. It is worth recalling how the list header status is at the time when the first insertion happens, that is when either the chip or expansion memory are added to the system memory pool, managed through &lt;code&gt;MemList&lt;/code&gt;. The latter is a list header &lt;code&gt;LH&lt;/code&gt; structure and the actual values are the following&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    0xe +-------+ 0x150
        |       |
    0xd +-------+ 0x14f (LH_pad)
        | 0xa   |
    0xc +-------+ 0x14e (LH_TYPE)
        | 0x142 |
    0x8 +-------+ 0x14a (LH_TAILPRED)
        | 0x0   |
    0x4 +-------+ 0x146 (LH_TAIL)
        | 0x146 |
    0x0 +-------+ 0x142 (LH_HEAD)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;With this structure in mind, let's dive into the source code of &lt;code&gt;Enqueue&lt;/code&gt;. The function is defined at &lt;code&gt;0xfc1670&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001670: 1229 0009                 move.b  0x9(a1),d1
00001674: 2010                      move.l  (a0),d0
00001676: 2040                      movea.l d0,a0
00001678: 2010                      move.l  (a0),d0
0000167a: 6706                      beq.b   0x1682
0000167c: b228 0009                 cmp.b   0x9(a0),d1
00001680: 6ff4                      ble.b   0x1676
00001682: 2028 0004                 move.l  0x4(a0),d0
00001686: 2149 0004                 move.l  a1,0x4(a0)
0000168a: 2288                      move.l  a0,(a1)
0000168c: 2340 0004                 move.l  d0,0x4(a1)
00001690: 2040                      movea.l d0,a0
00001692: 2089                      move.l  a1,(a0)
00001694: 4e75                      rts     
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;And it can be roughly divided into three sections, according to the internal jumps.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Init:
00001670: 1229 0009                 move.b  0x9(a1),d1
00001674: 2010                      move.l  (a0),d0

FindPos:
00001676: 2040                      movea.l d0,a0
00001678: 2010                      move.l  (a0),d0
0000167a: 6706                      beq.b   InsertNode
0000167c: b228 0009                 cmp.b   0x9(a0),d1
00001680: 6ff4                      ble.b   FindPos

InsertNode:
00001682: 2028 0004                 move.l  0x4(a0),d0
00001686: 2149 0004                 move.l  a1,0x4(a0)
0000168a: 2288                      move.l  a0,(a1)
0000168c: 2340 0004                 move.l  d0,0x4(a1)
00001690: 2040                      movea.l d0,a0
00001692: 2089                      move.l  a1,(a0)
00001694: 4e75                      rts     
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The first section, &lt;code&gt;Init&lt;/code&gt;, prepares the execution of the rest of the function. The rest bla&lt;/p&gt;&lt;p&gt;As I did for other functions in the previous articles, I'm going to dissect this line by line. Let's start from the &lt;code&gt;Init&lt;/code&gt; part.&lt;/p&gt;&lt;h3 id="init"&gt;Init&lt;/h3&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Init:
00001670: 1229 0009                 move.b  0x9(a1),d1
00001674: 2010                      move.l  (a0),d0
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Since &lt;code&gt;a1&lt;/code&gt; points to the node to be inserted, &lt;code&gt;0x9(a1)&lt;/code&gt; is the &lt;code&gt;LN_PRI&lt;/code&gt; field of that node, that is the priority. The first line thus stores it in &lt;code&gt;d1&lt;/code&gt; because it will be used to search for the insertion point, as the list is maintained in priority order.&lt;/p&gt;&lt;p&gt;The second line is the core or the node traversal algorithm. Since &lt;code&gt;a0&lt;/code&gt; points to a &lt;code&gt;LH&lt;/code&gt; structure, it is also the address of the first field &lt;code&gt;LH_HEAD&lt;/code&gt;. &lt;code&gt;(a0)&lt;/code&gt;, thus, is the dereferencing of that address, which means the address of the first node in the list. Given the figures I showed before for &lt;code&gt;MemList&lt;/code&gt;, &lt;code&gt;a0&lt;/code&gt; is &lt;code&gt;0x142&lt;/code&gt; so a &lt;code&gt;move a0,d0&lt;/code&gt; would store &lt;code&gt;0x142&lt;/code&gt; (the value of &lt;code&gt;a0&lt;/code&gt;) in &lt;code&gt;d0&lt;/code&gt;. &lt;code&gt;(a0)&lt;/code&gt;, instead, is the content of that address in memory, namely &lt;code&gt;0x146&lt;/code&gt;, so &lt;code&gt;move (a0),d0&lt;/code&gt; stores &lt;code&gt;0x146&lt;/code&gt; (the content of &lt;code&gt;0x142&lt;/code&gt;) in &lt;code&gt;d0&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Putting aside the intricacies of the addressing modes, the second line stores the address of the first node in the list, which is the part of the header that starts with &lt;code&gt;LH_TAIL&lt;/code&gt;. The header thus acts as the first node of the list.&lt;/p&gt;&lt;h3 id="findpos"&gt;FindPos&lt;/h3&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FindPos:
00001676: 2040                      movea.l d0,a0
00001678: 2010                      move.l  (a0),d0
0000167a: 6706                      beq.b   InsertNode
0000167c: b228 0009                 cmp.b   0x9(a0),d1
00001680: 6ff4                      ble.b   FindPos
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The first two lines repeat the same algorithm. The address of the current node (&lt;code&gt;d0&lt;/code&gt;) is moved to &lt;code&gt;a0&lt;/code&gt; and the dereferencing operation &lt;code&gt;(a0)&lt;/code&gt; puts in &lt;code&gt;d0&lt;/code&gt; the address of the following node. The reason why we do it in two lines is that the Address Register Indirect Mode can be used only with &lt;code&gt;An&lt;/code&gt; registers. At this point &lt;code&gt;d0&lt;/code&gt; contains the address of the second node, the successor of the header.&lt;/p&gt;&lt;p&gt;If the list contains at least one node, &lt;code&gt;d0&lt;/code&gt; contains its address. But if the list is empty at this point &lt;code&gt;d0&lt;/code&gt; contains &lt;code&gt;0x0&lt;/code&gt;, and this is the condition tested by the &lt;code&gt;beq.b&lt;/code&gt; instruction. If &lt;code&gt;d0&lt;/code&gt; is empty we reached the end of the list, which means that there was no better place to insert the node, and we jump to the actual node insertion code, &lt;code&gt;InsertNode&lt;/code&gt;. If the value is not zero, the current node has a proper successor, so let's check it's priority to see if we need to go on or if we can stop here. The code compares the priorities of the current node and of the &lt;code&gt;Ins&lt;/code&gt; node, and if the latter is less than the former we can loop back to &lt;code&gt;FindPos&lt;/code&gt; and move to the next node. Remember that priorities are expressed with negative numbers only, so "less than" actually means "higher priority".&lt;/p&gt;&lt;h3 id="insertnode"&gt;InsertNode&lt;/h3&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;InsertNode:
00001682: 2028 0004                 move.l  0x4(a0),d0
00001686: 2149 0004                 move.l  a1,0x4(a0)
0000168a: 2288                      move.l  a0,(a1)
0000168c: 2340 0004                 move.l  d0,0x4(a1)
00001690: 2040                      movea.l d0,a0
00001692: 2089                      move.l  a1,(a0)
00001694: 4e75                      rts     
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In either case, when we reach the tail or when the priority of the next node is lower than the one of the new node, we reach &lt;code&gt;InsertNode&lt;/code&gt;. At this point &lt;code&gt;a0&lt;/code&gt; points to &lt;code&gt;Next&lt;/code&gt; and we can access &lt;code&gt;Pred&lt;/code&gt; through &lt;code&gt;0x4(a0)&lt;/code&gt; (that is &lt;code&gt;LN_SUCC&lt;/code&gt; of &lt;code&gt;Next&lt;/code&gt;).&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001682: 2028 0004                 move.l  0x4(a0),d0
00001686: 2149 0004                 move.l  a1,0x4(a0)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This first stores the aforementioned address of &lt;code&gt;Pred&lt;/code&gt; in &lt;code&gt;d0&lt;/code&gt;, then replaces it with the value of &lt;code&gt;a1&lt;/code&gt;. The result is that the predecessor of &lt;code&gt;Next&lt;/code&gt; becomes &lt;code&gt;Ins&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;----m68k 0000168a: 2288                      move.l  a0,(a1) 0000168c: 2340 0004                 move.l  d0,0x4(a1) ----&lt;/p&gt;&lt;p&gt;This moves &lt;code&gt;a0&lt;/code&gt;, the address of &lt;code&gt;Next&lt;/code&gt;, into the first field of &lt;code&gt;Ins&lt;/code&gt;, that is &lt;code&gt;Next&lt;/code&gt; becomes the successor of &lt;code&gt;Ins&lt;/code&gt;. The second line moves &lt;code&gt;d0&lt;/code&gt; (the address of &lt;code&gt;Pred&lt;/code&gt;) into the &lt;code&gt;LN_PRED&lt;/code&gt; of &lt;code&gt;Ins&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001690: 2040                      movea.l d0,a0
00001692: 2089                      move.l  a1,(a0)
00001694: 4e75                      rts     
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Last, the address of &lt;code&gt;Ins&lt;/code&gt; becomes the &lt;code&gt;LN_SUCC&lt;/code&gt; of &lt;code&gt;Pred&lt;/code&gt;, so we move &lt;code&gt;d0&lt;/code&gt; into &lt;code&gt;a0&lt;/code&gt; because, as I already mentioned, the Address Register Indirect Mode can be used only with &lt;code&gt;An&lt;/code&gt; registers. After this the function returns to the caller.&lt;/p&gt;&lt;h2 id="remove"&gt;Remove&lt;a class="headerlink" href="#remove" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Since we reviewed the code of &lt;code&gt;Enqueue&lt;/code&gt; it makes sense to have a look at the opposite function, &lt;code&gt;Remove&lt;/code&gt;. A protected version of this exists as well, but here I will just show the code of the pure function without the wrapper.&lt;/p&gt;&lt;p&gt;Removing a node is simpler than adding it, as all we have to do is to make &lt;code&gt;Pred&lt;/code&gt; point to &lt;code&gt;Next&lt;/code&gt; and vice versa, so the function is much shorter. It's worth noting that while the function accepts the address of the node in &lt;code&gt;a1&lt;/code&gt; the value in this register is eventually overwritten, so the address has to be kept elsewhere when the function is called.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0000163c: 2051                      movea.l (a1),a0
0000163e: 2269 0004                 movea.l 0x4(a1),a1
00001642: 2288                      move.l  a0,(a1)
00001644: 2149 0004                 move.l  a1,0x4(a0)
00001648: 4e75 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The first two lines store the address of &lt;code&gt;Next&lt;/code&gt; in &lt;code&gt;a0&lt;/code&gt; and of &lt;code&gt;Pred&lt;/code&gt; in &lt;code&gt;a1&lt;/code&gt; (overwriting the input value). The third line makes &lt;code&gt;Next&lt;/code&gt; the successor of &lt;code&gt;Pred&lt;/code&gt; and the fourth line makes &lt;code&gt;Pred&lt;/code&gt; the predecessor of &lt;code&gt;Next&lt;/code&gt;. Then the function returns to the caller.&lt;/p&gt;&lt;h2 id="addlibrary"&gt;AddLibrary&lt;a class="headerlink" href="#addlibrary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In the &lt;a href="https://www.thedigitalcatonline.com/blog/2018/06/25/exploring-the-amiga-6/"&gt;6th post&lt;/a&gt; of this series we left Kickstart just after it finished adding the physical memory to the system pool. The last instruction we mentioned was a call to &lt;code&gt;AddLibrary&lt;/code&gt;, and this is then the next function I will explore.&lt;/p&gt;&lt;p&gt;The code of the function is at &lt;code&gt;fc1448&lt;/code&gt;, and required some work before I was able to read it (see the section "Manual decompilation").&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001448: 41ee 017a                 lea 0x17a(a6),a0
0000144c: 6100 0270                 bsr.w 0x16be
00001450: 6100 0082                 bsr.w 0x14d4
00001454: 4e75                      rts     
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The first line loads the absolute address of an object &lt;code&gt;0x17a&lt;/code&gt; bytes after the ExecBase address, and looking up this displacement in the library structure published in both the fifth and sixth instalment we find, rather unsurprisingly, that this is the address of &lt;code&gt;LibList&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The following lines call the protected version of &lt;code&gt;Enqueue&lt;/code&gt; and &lt;code&gt;SumLibrary&lt;/code&gt;, after which the routine returns to the caller. The call to &lt;code&gt;Enqueue&lt;/code&gt; follows what I explained at the beginning of this post, where this time &lt;code&gt;a0&lt;/code&gt; points to the library system list and &lt;code&gt;a1&lt;/code&gt; points to the base address of Exec, set just before the call to &lt;code&gt;AddLibrary&lt;/code&gt;. So the Exec library itself is added to the system libraries through this routine.&lt;/p&gt;&lt;p&gt;&lt;code&gt;SumLibrary&lt;/code&gt;, as the name suggests, computes the checksum of a library, or checks the existing one.&lt;/p&gt;&lt;h2 id="manual-decompilation"&gt;Manual decompilation&lt;a class="headerlink" href="#manual-decompilation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When I was following the call to &lt;code&gt;AddLibrary&lt;/code&gt; from the main body of Kickstart I was surprised to find this code&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001446: 0000 41ee                 ori.b   #-0x12,d0
0000144a: 017a 6100                 bchg    d0,0x754c(pc)
0000144e: 0270 6100 0082            andi.w  #0x6100,(-0x7e,a0,d0.w)
00001454: 4e75                      rts     
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;which at first glance doesn't look like a basic function, as the instructions are too convoluted. Furthermore, the branch uses the address &lt;code&gt;0x1448&lt;/code&gt;, which is thus supposed to be the beginning of the function. A quick look at the hexadecimal values reveals the truth: at &lt;code&gt;0x1446&lt;/code&gt; Kickstart contains a padding word &lt;code&gt;0000&lt;/code&gt; that confused the decompiler. To see the code of the function I had to manually decompile the machine code, and since the process is very interesting I decided to show it in detail here.&lt;/p&gt;&lt;p&gt;When you try to manually decompile some machine code you need a cheat sheet and the processor manual (see the resources section), which can help you to quickly track down the meaning of the single bits. The values we are interested in are&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001448: 41ee
0000144a: 017a
0000144c: 6100
0000144e: 0270
00001450: 6100
00001452: 0082
00001454: 4e75
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;since &lt;code&gt;fc1456&lt;/code&gt; is listed as the address of the &lt;code&gt;RemLibrary&lt;/code&gt; function. The binary representation of these values is&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001448: 0100 0001 1110 1110
0000144a: 0000 0001 0111 1010
0000144c: 0110 0001 0000 0000
0000144e: 0000 0010 0111 0000
00001450: 0110 0001 0000 0000
00001452: 0000 0000 1000 0010
00001454: 0100 1110 0111 0101
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Now, the first 4 bits of any Motorola 68k instruction are the instruction code. While multiple instructions share the same 4 bits (for example &lt;code&gt;andi&lt;/code&gt; and &lt;code&gt;subi&lt;/code&gt;), those bits are never used for addressing or to specify modes, so they are a good starting point.&lt;/p&gt;&lt;p&gt;The instruction at &lt;code&gt;0x1448&lt;/code&gt; starts with &lt;code&gt;0100&lt;/code&gt; followed by a &lt;code&gt;0&lt;/code&gt;, and this narrows the selection to a bunch of instructions: some types of &lt;code&gt;move&lt;/code&gt;, &lt;code&gt;negx&lt;/code&gt;, &lt;code&gt;clr&lt;/code&gt;, &lt;code&gt;neg&lt;/code&gt;, &lt;code&gt;not&lt;/code&gt;, &lt;code&gt;lea&lt;/code&gt;, &lt;code&gt;chk&lt;/code&gt;. Among these, only &lt;code&gt;lea&lt;/code&gt; or &lt;code&gt;chk&lt;/code&gt; can be followed by &lt;code&gt;0001&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Both instructions use the following 3 bits to specify a register (&lt;code&gt;An&lt;/code&gt; for &lt;code&gt;lea&lt;/code&gt;, &lt;code&gt;Dn&lt;/code&gt; for &lt;code&gt;chk&lt;/code&gt;), but then the first has a fixed group &lt;code&gt;111&lt;/code&gt;, while the second has a group &lt;code&gt;110&lt;/code&gt;. This means that we are looking at a &lt;code&gt;lea&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The three bits after &lt;code&gt;0100&lt;/code&gt; are &lt;code&gt;000&lt;/code&gt;, which translates to &lt;code&gt;a0&lt;/code&gt; as a target. The last 6 bits are the addressing mode and the register, and the cheat sheet tells us that &lt;code&gt;101 110&lt;/code&gt; corresponds to Address Register Indirect with Displacement Mode on &lt;code&gt;a6&lt;/code&gt;. &lt;code&gt;101&lt;/code&gt; is labelled as &lt;code&gt;(d16, An)&lt;/code&gt;, while &lt;code&gt;110&lt;/code&gt; is the number 6. The following word is thus the &lt;code&gt;d16&lt;/code&gt; displacement from &lt;code&gt;a6&lt;/code&gt;, which means that &lt;code&gt;41ee 017a&lt;/code&gt; translates to &lt;code&gt; lea 0x17a(a6),a0&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;lea   a0   (d16,An)         0x17a
 |    |       |               |
 v    v       v      |-----------------|
0100 000 111 101 110 0000 0001 0111 1010
          ^       ^
	  |       |
	fixed     a6

00001448: 41ee 017a     lea 0x17a(a6),a0
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The second instruction starts at &lt;code&gt;0x144c&lt;/code&gt; with &lt;code&gt;0110&lt;/code&gt;, which is the signature of all the branch commands: &lt;code&gt;bra&lt;/code&gt;, &lt;code&gt;bsr&lt;/code&gt;, and all the condition-based ones like &lt;code&gt;bgt&lt;/code&gt;, &lt;code&gt;blt&lt;/code&gt;, and so on. Since the following 4 bits are &lt;code&gt;0001&lt;/code&gt; we know this is a &lt;code&gt;bsr&lt;/code&gt;, branch to subroutine. Now, in this instruction the 8 least significant bits tell us what the displacement is, and thus the type of the operand (Programmer's Manual, section 4-59, page 163). In this case they are all &lt;code&gt;0&lt;/code&gt;, which means a word displacement, which is in the next 16 bits. Pay attention that, as we discussed for &lt;code&gt;lea&lt;/code&gt; in the &lt;a href="https://www.thedigitalcatonline.com/blog/2018/05/28/exploring-the-amiga-1/"&gt;first post&lt;/a&gt; the Program Counter contains the address of the first displacement word. In this case the displacement is &lt;code&gt;0x270&lt;/code&gt; at address &lt;code&gt;0x144e&lt;/code&gt;, so the branch address is the sum of the two, that is &lt;code&gt;0x16be&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;   bsr   displacement
    |         |
|-------| |-------|
0110 0001 0000 0000 0000 0010 0111 0000
                    |-----------------|
		             |
			   0x270 (+ 0x144e = 0x16be)

0000144c: 6100 0270     bsr.w 0x16be
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The third instruction is again a &lt;code&gt;bsr&lt;/code&gt; and following the same process we find out that the branch address is the sum between &lt;code&gt;0x82&lt;/code&gt; and &lt;code&gt;0x1452&lt;/code&gt;, that is &lt;code&gt;0x14d4&lt;/code&gt;.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;   bsr   displacement
    |         |
|-------| |-------|
0110 0001 0000 0000 0000 0000 1000 0010
                    |-----------------|
		             |
			    0x82 (+ 0x1452 = 0x14d4)

00001450: 6100 0082     bsr.w 0x14d4
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The final instruction is an &lt;code&gt;rts&lt;/code&gt;, as we expected, and as the decompiler correctly told us. The disassembled code is then what we used in the previous section&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;00001448: 41ee 017a                 lea 0x17a(a6),a0
0000144c: 6100 0270                 bsr.w 0x16be
00001450: 6100 0082                 bsr.w 0x14d4
00001454: 4e75                      rts     
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The most important thing to keep in mind when manually reading instructions is the position of the Program Counter. As we already saw two times, with &lt;code&gt;lea&lt;/code&gt; and with &lt;code&gt;bsr&lt;/code&gt;, the PC moves as soon as the 16-bit instruction has been read, which means that when a displacement is given we have to use the address of the displacement itself as a base for our calculations.&lt;/p&gt;&lt;h2 id="resources"&gt;Resources&lt;a class="headerlink" href="#resources" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;Motorola M68000 Family Programmer's Reference Manual - &lt;a href="https://www.nxp.com/docs/en/reference-manual/M68000PRM.pdf"&gt;https://www.nxp.com/docs/en/reference-manual/M68000PRM.pdf&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Motorola 68000 Opcodes Cheat Sheet - &lt;a href="http://goldencrystal.free.fr/M68kOpcodes-v2.3.pdf"&gt;http://goldencrystal.free.fr/M68kOpcodes-v2.3.pdf&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;</content><category term="Retro"></category><category term="assembly"></category><category term="amiga"></category><category term="retroprogramming"></category></entry><entry><title>Clean architectures in Python: a step-by-step example</title><link href="https://www.thedigitalcatonline.com/blog/2016/11/14/clean-architectures-in-python-a-step-by-step-example/" rel="alternate"></link><published>2016-11-14T19:00:00+00:00</published><updated>2021-09-24T12:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2016-11-14:/blog/2016/11/14/clean-architectures-in-python-a-step-by-step-example/</id><summary type="html">&lt;p&gt;How to create software that can be easily changed and adapted, following the clean architecture principles&lt;/p&gt;</summary><content type="html">&lt;p&gt;In 2015 I was introduced by my friend &lt;a href="https://github.com/gekorob"&gt;Roberto Ciatti&lt;/a&gt; to the concept of Clean Architecture, as it is called by Robert Martin. The well-known Uncle Bob talks a lot about this concept at conferences and wrote some very interesting posts about it. What he calls "Clean Architecture" is a way of structuring a software system, a set of consideration (more than strict rules) about the different layers and the role of the actors in it.&lt;/p&gt;&lt;p&gt;As he clearly states in a post aptly titled &lt;a href="https://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html"&gt;The Clean Architecture&lt;/a&gt;, the idea behind this design is not new. As a matter of fact, it is a set of concepts that have been pushed by many software engineers over the last 3 decades. One of the first implementations may be found in the Boundary-Control-Entity model proposed by Ivar Jacobson in his masterpiece &lt;a href="https://www.ivarjacobson.com/publications/books/object-oriented-software-engineering-1992"&gt;Object-Oriented Software Engineering: A Use Case Driven Approach&lt;/a&gt; published in 1992, but Martin lists other more recent versions of this architecture.&lt;/p&gt;&lt;p&gt;I will not repeat here what he had already explained better than I can do, so I will just point out some resources you may check to start exploring these concepts:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html"&gt;The Clean Architecture&lt;/a&gt; a post by Robert Martin that concisely describes the goals of the architecture. It also lists resources that describe similar architectures.&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.8thlight.com/uncle-bob/2014/05/12/TheOpenClosedPrinciple.html"&gt;The Open Closed Principle&lt;/a&gt; a post by Robert Martin not strictly correlated with the Clean Architecture concept but important for the separation concept.&lt;/li&gt;&lt;li&gt;Hakka Labs: Robert "Uncle Bob" Martin - &lt;a href="https://www.youtube.com/watch?v=HhNIttd87xs"&gt;Architecture: The Lost Years&lt;/a&gt; a video of Robert Martin from Hakka Labs.&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.taimila.com/blog/ddd-and-testing-strategy/"&gt;DDD &amp;amp; Testing Strategy&lt;/a&gt; by Lauri Taimila&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Clean-Architecture-Robert-C-Martin-x/dp/0134494164/ref=la_B000APG87E_1_3?s=books&amp;amp;ie=UTF8&amp;amp;qid=1479146201&amp;amp;sr=1-3"&gt;Clean Architecture&lt;/a&gt; by Robert Martin, published by Prentice Hall.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="a-day-in-the-life-of-a-clean-system"&gt;A day in the life of a clean system&lt;a class="headerlink" href="#a-day-in-the-life-of-a-clean-system" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I will introduce here a (very simple) system designed with a clean architecture. The purpose of this section is to familiarise with main concepts like &lt;em&gt;separation of concerns&lt;/em&gt; and &lt;em&gt;inversion of control&lt;/em&gt;, which are paramount in system design. While I describe how data flows in the system, I will purposefully omit details, so that we can focus on the global idea and not worry too much about the implementation.&lt;/p&gt;&lt;h3 id="the-data-flow"&gt;The data flow&lt;/h3&gt;&lt;p&gt;In the rest of the book, we will design together part of a simple web application that provides a room renting system. So, let's consider that our "Rent-o-Matic" application (inspired by the Sludge-O-Matic™ from Day of the Tentacle) is running at &lt;a href="https://www.rentomatic.com"&gt;https://www.rentomatic.com&lt;/a&gt;, and that a user wants to see the available rooms. They open the browser and type the address, then clicking on menus and buttons they reach the page with the list of all the rooms that our company rents.&lt;/p&gt;&lt;p&gt;Let's assume that this URL is &lt;code&gt;/rooms?status=available&lt;/code&gt;. When the user's browser accesses that URL, an HTTP request reaches our system, where there is a component that is waiting for HTTP connections. Let's call this component "web framework".&lt;/p&gt;&lt;p&gt;The purpose of the web framework is to understand the HTTP request and to retrieve the data that we need to provide a response. In this simple case there are two important parts of the request, namely the endpoint itself (&lt;code&gt;/rooms&lt;/code&gt;), and a single query string parameter, &lt;code&gt;status=available&lt;/code&gt;. Endpoints are like commands for our system, so when a user accesses one of them, they signal to the system that a specific service has been requested, which in this case is the list of all the rooms that are available for rent.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure01.svg" alt="The web framework serving HTTP"&gt;&lt;div class="title"&gt;The web framework serving HTTP&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The domain in which the web framework operates is that of the HTTP protocol, so when the web framework has decoded the request it should pass the relevant information to another component that will process it. This other component is called &lt;em&gt;use case&lt;/em&gt;, and it is the crucial and most important component of the whole clean system as it implements the &lt;em&gt;business logic&lt;/em&gt;.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure02.svg" alt="The business logic"&gt;&lt;div class="title"&gt;The business logic&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The business logic is an important concept in system design. You are creating a system because you have some knowledge that you think might be useful to the world, or at the very least marketable. This knowledge is, at the end of the day, a way to process data, a way to extract or present data that maybe others don't have. A search engine can find all the web pages that are related to the terms in a query, a social network shows you the posts of people you follow and sorts them according to a specific algorithm, a travel company finds the best options for your journey between two locations, and so on. All these are good examples of business logic.&lt;/p&gt;&lt;div class="admonition tip"&gt;&lt;i class="fa fa-lightbulb"&gt;&lt;/i&gt;&lt;div class="content"&gt;&lt;div class="title"&gt;Business logic&lt;/div&gt;&lt;div&gt;&lt;p&gt;Business logic is the specific algorithm or process that you want to implement, the way you transform data to provide a service. It is the most important part of the system.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The use case implements a very specific part of the whole business logic. In this case we have a use case to search for rooms with a given value of the parameter &lt;code&gt;status&lt;/code&gt;. This means that the use case has to extract all the rooms that are managed by our company and filter them to show only the ones that are available.&lt;/p&gt;&lt;p&gt;Why can't the web framework do it? Well, the main purpose of a good system architecture is to &lt;em&gt;separate concerns&lt;/em&gt;, that is to keep different responsibilities and domains separated. The web framework is there to process the HTTP protocol, and is maintained by programmers that are concerned with that specific part of the system, and adding the business logic to it mixes two very different fields.&lt;/p&gt;&lt;div class="admonition tip"&gt;&lt;i class="fa fa-lightbulb"&gt;&lt;/i&gt;&lt;div class="content"&gt;&lt;div class="title"&gt;Separation of concerns&lt;/div&gt;&lt;div&gt;&lt;p&gt;Different parts a system should manage different parts of the process. Whenever two separate parts of a system work on the same data or the same part of a process they are &lt;em&gt;coupled&lt;/em&gt;. While coupling is unavoidable, the higher the coupling between two components the harder is to change one without affecting the other.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As we will see, separating layers allows us to maintain the system with less effort, making single parts of it more testable and easily replaceable.&lt;/p&gt;&lt;p&gt;In the example that we are discussing here, the use case needs to fetch all the rooms that are in an available state, extracting them from a source of data. This is the business logic, and in this case it is very straightforward, as it will probably consist of a simple filtering on the value of an attribute. This might however not be the case. An example of a more advanced business logic might be an ordering based on a recommendation system, which might require the use case to connect with more components than just the data source.&lt;/p&gt;&lt;p&gt;So, the information that the use case wants to process is stored somewhere. Let's call this component &lt;em&gt;storage system&lt;/em&gt;. Many of you probably already pictured a database in your mind, maybe a relational one, but that is just one of the possible data sources. The abstraction represented by the storage system is: anything that the use case can access and that can provide data is a source. It might be a file, a database (either relational or not), a network endpoint, or a remote sensor.&lt;/p&gt;&lt;div class="admonition tip"&gt;&lt;i class="fa fa-lightbulb"&gt;&lt;/i&gt;&lt;div class="content"&gt;&lt;div class="title"&gt;Abstraction&lt;/div&gt;&lt;div&gt;&lt;p&gt;When designing a system, it is paramount to think in terms of abstractions, or building blocks. A component has a role in the system, regardless of the specific implementation of that component. The higher the level of the abstraction, the less detailed are the components. Clearly, high-level abstractions don't consider practical problems, which is why the abstract design has to be then implemented using specific solutions or technologies.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;For simplicity's sake, let's use a relational database like Postgres in this example, as it is likely to be familiar to the majority of readers, but keep in mind the more generic case.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure03.svg"&gt;&lt;div class="title"&gt;The storage&lt;/div&gt;&lt;/div&gt;&lt;p&gt;How does the use case connect with the storage system? Clearly, if we hard code into the use case the calls to a specific system (e.g. using SQL) the two components will be &lt;em&gt;strongly coupled&lt;/em&gt;, which is something we try to avoid in system design. Coupled components are not independent, they are tightly connected, and changes occurring in one of the two force changes in the second one (and vice versa). This also means that testing components is more difficult, as one component cannot live without the other, and when the second component is a complex system like a database this can severely slow down development.&lt;/p&gt;&lt;p&gt;For example, let's assume the use case called directly a specific Python library to access PostgreSQL such as &lt;a href="https://www.psycopg.org/"&gt;psycopg&lt;/a&gt;. This would couple the use case with that specific source, and a change of database would result in a change of its code. This is far from being ideal, as the use case contains the business logic, which has not changed moving from one database system to the other. Parts of the system that do not contain the business logic should be treated like implementation details.&lt;/p&gt;&lt;div class="admonition tip"&gt;&lt;i class="fa fa-lightbulb"&gt;&lt;/i&gt;&lt;div class="content"&gt;&lt;div class="title"&gt;Implementation detail&lt;/div&gt;&lt;div&gt;&lt;p&gt;A specific solution or technology is called a &lt;em&gt;detail&lt;/em&gt; when it is not central to the design as a whole. The word doesn't refer to the inherent complexity of the subject, which might be greater than that of more central parts.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;A relational database is hundred of times richer and more complex than an HTTP endpoint, and this in turn is more complex than ordering a list of objects, but the core of the application is the use case, not the way we store data or the way we provide access to that. Usually, implementation details are mostly connected with performances or usability, while the core parts implement the pure business logic.&lt;/p&gt;&lt;p&gt;How can we avoid strong coupling? A simple solution is called &lt;em&gt;inversion of control&lt;/em&gt;, and I will briefly sketch it here, and show a proper implementation in a later section of the book, when we will implement this very example.&lt;/p&gt;&lt;p&gt;Inversion of control happens in two phases. First, the called object (the database in this case) is wrapped with a standard interface. This is a set of functionalities shared by every implementation of the target, and each interface translates the functionalities to calls to the specific language&lt;sup&gt;[&lt;a id="fr--8148833" href="#fd--8148833"&gt;1&lt;/a&gt;]&lt;/sup&gt; of the wrapped implementation.&lt;/p&gt;&lt;div class="admonition tip"&gt;&lt;i class="fa fa-lightbulb"&gt;&lt;/i&gt;&lt;div class="content"&gt;&lt;div class="title"&gt;Inversion of control&lt;/div&gt;&lt;div&gt;&lt;p&gt;A technique used to avoid strong coupling between components of a system, that involves wrapping them so that they expose a certain interface. A component expecting that interface can then connect to them without knowing the details of the specific implementation, and thus being strongly coupled to the interface instead of the specific implementation.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;A real world example of this is that of power plugs: electric appliances are designed to be connected not with specific power plugs, but to any power plug that is build according to the specification (size, number of poles, etc). When you buy a TV in the UK, you expect it to come with a UK plug (BS 1363). If it doesn't, you need an &lt;em&gt;adapter&lt;/em&gt; that allows you to plug electronic devices into sockets of a foreign nation. In this case, we need to connect the use case (TV) to a database (power system) that has not been designed to match a common interface.&lt;/p&gt;&lt;p&gt;In the example we are discussing, the use case needs to extract all rooms with a given status, so the database wrapper needs to provide a single entry point that we might call &lt;code&gt;list_rooms_with_status&lt;/code&gt;.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure04.svg" alt="The storage interface"&gt;&lt;div class="title"&gt;The storage interface&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In the second phase of inversion of control the caller (the use case) is modified to avoid hard coding the call to the specific implementation, as this would again couple the two. The use case accepts an incoming object as a parameter of its constructor, and receives a concrete instance of the adapter at creation time. The specific technique used to implement this depends greatly on the programming language we use. Python doesn't have an explicit syntax for interfaces, so we will just assume the object we pass implements the required methods.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure05.svg" alt="Inversion of control on the storage interface"&gt;&lt;div class="title"&gt;Inversion of control on the storage interface&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Now the use case is connected with the adapter and knows the interface, and it can call the entry point &lt;code&gt;list_rooms_with_status&lt;/code&gt; passing the status &lt;code&gt;available&lt;/code&gt;. The adapter knows the details of the storage system, so it converts the method call and the parameter in a specific call (or set of calls) that extract the requested data, and then converts them in the format expected by the use case. For example, it might return a Python list of dictionaries that represent rooms.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure06.svg" alt="The business logic extracts data from the storage"&gt;&lt;div class="title"&gt;The business logic extracts data from the storage&lt;/div&gt;&lt;/div&gt;&lt;p&gt;At this point, the use case has to apply the rest of the business logic, if needed, and return the result to the web framework.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure07.svg" alt="The business logic returns processed data to the web framework"&gt;&lt;div class="title"&gt;The business logic returns processed data to the web framework&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The web framework converts the data received from the use case into an HTTP response. In this case, as we are considering an endpoint that is supposed to be reached explicitly by the user of the website, the web framework will return an HTML page in the body of the response, but if this was an internal endpoint, for example called by some asynchronous JavaScript code in the front-end, the body of the response would probably just be a JSON structure.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure08.svg" alt="The web framework returns the data in an HTTP response"&gt;&lt;div class="title"&gt;The web framework returns the data in an HTTP response&lt;/div&gt;&lt;/div&gt;&lt;h3 id="advantages-of-a-layered-architecture"&gt;Advantages of a layered architecture&lt;/h3&gt;&lt;p&gt;As you can see, the stages of this process are clearly separated, and there is a great deal of data transformation between them. Using common data formats is one of the way we achieve independence, or loose coupling, between components of a computer system.&lt;/p&gt;&lt;p&gt;To better understand what loose coupling means for a programmer, let's consider the last picture. In the previous paragraphs I gave an example of a system that uses a web framework for the user interface and a relational database for the data source, but what would change if the front-end part was a command-line interface? And what would change if, instead of a relational database, there was another type of data source, for example a set of text files?&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure09.svg" alt="The web framework replaced by a CLI"&gt;&lt;div class="title"&gt;The web framework replaced by a CLI&lt;/div&gt;&lt;/div&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure10.svg" alt="A database replaced by a more trivial file-based storage"&gt;&lt;div class="title"&gt;A database replaced by a more trivial file-based storage&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see, both changes would require the replacement of some components. After all, we need different code to manage a command line instead of a web page. But the external shape of the system doesn't change, neither does the way data flows. We created a system in which the user interface (web framework, command-line interface) and the data source (relational database, text files) are details of the implementation, and not core parts of it.&lt;/p&gt;&lt;p&gt;The main immediate advantage of a layered architecture, however, is testability. When you clearly separate components you clearly establish the data each of them has to receive and produce, so you can ideally disconnect a single component and test it in isolation. Let's take the Web framework component that we added and consider it for a moment forgetting the rest of the architecture. We can ideally connect a tester to its inputs and outputs as you can see in the figure&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure11.svg" alt="Testing the web layer in isolation"&gt;&lt;div class="title"&gt;Testing the web layer in isolation&lt;/div&gt;&lt;/div&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/figure12.svg" alt="Detailed setup of the web layer testing, width=80%"&gt;&lt;div class="title"&gt;Detailed setup of the web layer testing&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We know that the Web framework receives an HTTP request &lt;span class="callout"&gt;1&lt;/span&gt; with a specific target and a specific query string, and that it has to call &lt;span class="callout"&gt;2&lt;/span&gt; a method on the use case passing specific parameters. When the use case returns data &lt;span class="callout"&gt;3&lt;/span&gt;, the Web framework has to convert that into an HTTP response &lt;span class="callout"&gt;4&lt;/span&gt;. Since this is a test we can have a fake use case, that is an object that just mimics what the use case does without really implementing the business logic. We will then test that the Web framework calls the method &lt;span class="callout"&gt;2&lt;/span&gt; with the correct parameters, and that the HTTP response &lt;span class="callout"&gt;4&lt;/span&gt; contains the correct data in the proper format, and all this will happen without involving any other part of the system.&lt;/p&gt;&lt;h2 id="clean-architectures-in-python-the-book"&gt;Clean Architectures in Python: the book&lt;a class="headerlink" href="#clean-architectures-in-python-the-book" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I hope you found this introduction useful. What you read so far was the first chapter of the book "Clean Architectures in Python" that you can read online at &lt;a href="https://www.thedigitalcatbooks.com/pycabook-introduction/"&gt;The Digital Cat Books&lt;/a&gt;. The book is available as PDF and ebook &lt;a href="https://leanpub.com/clean-architectures-in-python"&gt;on Leanpub&lt;/a&gt;.&lt;/p&gt;&lt;div class="imageblock"&gt;&lt;img src="/images/cabook/cover.jpg" alt="The book cover"&gt;&lt;/div&gt;&lt;p&gt;Chapter 2 of the book briefly discusses the &lt;strong&gt;components&lt;/strong&gt; and the ideas behind this software architecture. Chapter 3 runs through &lt;strong&gt;a concrete example&lt;/strong&gt; of clean architecture and chapter 4 expands the example adding a &lt;strong&gt;web application&lt;/strong&gt; on top of it. Chapter 5 discusses &lt;strong&gt;error management&lt;/strong&gt; and improvements to the Python code developed in the previous chapters. Chapters 6 and 7 show how to plug &lt;strong&gt;different database systems&lt;/strong&gt; to the web service created previously, and chapter 8 wraps up the example showing how to run the application with a &lt;strong&gt;production-ready configuration&lt;/strong&gt;.&lt;/p&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;</content><category term="Programming"></category><category term="OOP"></category><category term="pytest"></category><category term="Python"></category><category term="Python2"></category><category term="Python3"></category><category term="TDD"></category><category term="architectures"></category></entry><entry><title>Versioning - An underrated discipline</title><link href="https://www.thedigitalcatonline.com/blog/2013/03/20/versioning-an-underrated-discipline/" rel="alternate"></link><published>2013-03-20T10:02:00+01:00</published><updated>2021-09-23T12:00:00+01:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2013-03-20:/blog/2013/03/20/versioning-an-underrated-discipline/</id><summary type="html">&lt;h2 id="overture"&gt;Overture&lt;a class="headerlink" href="#overture" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Whoever uses a computer has to deal every day with software version numbers, and even occasional users shall sooner or later introduce the word &lt;em&gt;version&lt;/em&gt; in their speech. Alas, this made it one of those concepts so pervading that it is now taken for granted, and so widespread that …&lt;/p&gt;</summary><content type="html">&lt;h2 id="overture"&gt;Overture&lt;a class="headerlink" href="#overture" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Whoever uses a computer has to deal every day with software version numbers, and even occasional users shall sooner or later introduce the word &lt;em&gt;version&lt;/em&gt; in their speech. Alas, this made it one of those concepts so pervading that it is now taken for granted, and so widespread that even professionals often forget or do not even know the complexity hidden behind it. This article is an attempt to shine a light on this topic.&lt;/p&gt;&lt;p&gt;This post started as a collection of some thoughts that aimed to summarise my experience in more than 20 years of software development. As usual, short sentences proved to be too short and became long sentences, then paragraphs, and the short list was already a long article. However, despite the length, my analysis does not claim to be either complete or exact. It simply represents an attempt to introduce the reader to the complexity of a matter which is always relevant in the software world.&lt;/p&gt;&lt;h2 id="a-known-concept"&gt;A known concept?&lt;a class="headerlink" href="#a-known-concept" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Isn't versioning just a simple concept that everybody knows?&lt;/p&gt;&lt;p&gt;Almost all computer users around the world can roughly deal with different versions of the most common programs. Windows 10 is more recent than Windows 8, Photoshop 2020 has been replaced by Photoshop 2021, and so on.&lt;/p&gt;&lt;p&gt;Certain software products, however, have more complicated version numbers. For example, the latest Chrome version at the time of writing is 93.0.4577.63, and the Linux kernel that I am running on my notebook is 5.4.0-81-generic. Whoever approaches software development for the first time might be surprised by such complicated numbers, and fail to grasp the reason behind them.&lt;/p&gt;&lt;p&gt;I think that as software developers we need to be aware of what is in a version number, and the reasons behind the choice of one scheme or another.&lt;/p&gt;&lt;h3 id="an-example-of-product-versioning"&gt;An example of product versioning&lt;/h3&gt;&lt;p&gt;To show that things are a bit more complicated than they appear at a first glance, let's have a look at a simple example of versioning outside the pure software world. In 1994, Sony created the Playstation and has since then released 5 versions of it, named Playstation, Playstation 2, Playstation 3, Playstation 4, and Playstation 5. A simple and effective versioning scheme.&lt;/p&gt;&lt;p&gt;In 2000, Sony released the PS One, which was a redesigned version of the original Playstation, but as you can see the name doesn't fit the initial simple list. Even different configurations of the following models fall outside the main naming scheme: the Playstation 2 Slim, the Playstation 3 Super Slim, the Playstation 4 Pro, and the Playstation 5 Digital Edition are examples of such configurations.&lt;/p&gt;&lt;p&gt;Even though such names do not follow strict rules, it's still pretty easy to identify the so-called major versions and to decide which is newer, as any configuration of the Playstation 3 (standard, Slim, and Super Slim) is more modern than any configuration of the Playstation 2. It is not so simple to know where to put the Playstation One, though, without knowing the history of the product.&lt;/p&gt;&lt;p&gt;In 2001 Microsoft entered the market with the Xbox, one year after Sony introduced the Playstation 2. About four years later, Sony was planning to release the third version of Playstation, and Microsoft answered with Xbox 360. The third version of Xbox was initially nicknamed Xbox 720, but it hit the market with the official name of Xbox One, followed 7 years later by the Xbox Series S and Series X.&lt;/p&gt;&lt;p&gt;In this case, it's not so trivial to identify which console came first. While the Playstation One was a new version of the original console, the Xbox One belongs to the third generation of that product line, and without being into the console world, it might be tough to guess whether the Xbox 360 came before or after the Series S.&lt;/p&gt;&lt;h2 id="a-formal-definition-of-versioning"&gt;A formal definition of versioning&lt;a class="headerlink" href="#a-formal-definition-of-versioning" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;So far, I have leveraged an intuitive understanding of the concepts of versioning and versioning scheme, but it's time to try to give a formal definition to them.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Versioning&lt;/em&gt; means labelling the state of an object at a given moment in time according to a set of rules. This set of rules is called &lt;em&gt;versioning scheme&lt;/em&gt; or versioning system. Versioning schemes can be formal and strict, such as those used in software products, or weak, such as those used in marketing. A weak system can just use arbitrary labels, as we saw in the example of consoles, while strong versioning schemes have to clearly establish the rules that version numbers are meant to follow.&lt;/p&gt;&lt;p&gt;A versioning scheme has two main characteristics that we want to take into account, which I called expressivity and coverage. The first is the amount of information that you can obtain just by looking at a certain version number or comparing two, while the second measures how well the versioning scheme covers all the possible states in which the versioned object can be.&lt;/p&gt;&lt;p&gt;Back to the example drawn from the console world, the Playstation versioning scheme has a certain amount of expressivity, as it is at least easy to decide which console came first, while the Xbox version codes can't truly be compared. From the point of view of coverage, both schemes are pretty weak, as they don't establish a strict way to identify minor configuration changes. Please also note that neither scheme allows us to know which components changed between major versions just by looking at the version number itself.&lt;/p&gt;&lt;p&gt;As mentioned before, such shortcomings are perfectly acceptable in the context of marketing but must be avoided in a more formal engineering context such as that of software development.&lt;/p&gt;&lt;h2 id="a-simple-example"&gt;A simple example&lt;a class="headerlink" href="#a-simple-example" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let us consider an example of software versioning so that we can better visualise the problems we face. The simplest versioning scheme we can conceive is made of a single integer number, such as that used by Sony with its Playstation. The first version of the software will be labelled version &lt;code&gt;1&lt;/code&gt;, the next version will be version &lt;code&gt;2&lt;/code&gt;, then version &lt;code&gt;3&lt;/code&gt; and so on.&lt;/p&gt;&lt;p&gt;Such a scheme seems to work well, and as we saw it has been successfully used for commercial products. When it comes to software products, however, we need to be aware that both the expressivity and the coverage of this system can be problematic.&lt;/p&gt;&lt;p&gt;With such a scheme, it is impossible to grasp the type and amount of changes that occurred between two versions just by comparing the two version numbers. For example, both fixing a minor bug and a complete rewrite of the graphical interface will increase the version number by one. Thus, the impact of the changes between version X and Y are unknown until we check the release notes that will hopefully clarify the matter.&lt;/p&gt;&lt;p&gt;Things are not much better when it comes to the coverage. Let's consider the case of a piece of software that has two major versions available on the market at the same time, labelled &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;2&lt;/code&gt; according to the scheme. If both versions are actively maintained, bugs have to be fixed and a new version has to be released. This is often the case with software: as an example take the Python programming language, whose versions 2 and 3 have been actively maintained together for 12 years while large codebases were migrated to the newest major version.&lt;/p&gt;&lt;p&gt;In such a scenario, developers might find a bug that affects both versions, thus requiring a new version to be created. The new release of version &lt;code&gt;2&lt;/code&gt; will be called &lt;code&gt;3&lt;/code&gt; according to the versioning scheme, but what would happen to version &lt;code&gt;1&lt;/code&gt;? It cannot be called version &lt;code&gt;2&lt;/code&gt; since that label has already been assigned to another state of the code.&lt;/p&gt;&lt;p&gt;Now, the fact that both the expressivity and the coverage of this versioning scheme proved low doesn't mean it cannot be used. Always remember that shortcomings are such in relation to some requirements. For example, if you never have two different versions available at the same time, the above scheme might be a good solution.&lt;/p&gt;&lt;h2 id="an-improved-example"&gt;An improved example&lt;a class="headerlink" href="#an-improved-example" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The first thing that comes to mind to improve the previous example is to add a secondary component to the version number that can be changed without affecting the primary one. A very broadly accepted and used method to add a new component to a version number is to add digits separating them from other components with a single dot (e.g. version &lt;code&gt;1.2&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;As soon as we decide to introduce a new component we need also to decide the role of each of the two parts of the version. For now, let's simplify the matter by calling them "major" and "minor" without giving a formal definition, which will come later.&lt;/p&gt;&lt;p&gt;So, the first version of the software will be &lt;code&gt;1.0&lt;/code&gt; (Major version &lt;code&gt;1&lt;/code&gt;, minor version &lt;code&gt;0&lt;/code&gt;). A minor change will increase the rightmost number, producing versions &lt;code&gt;1.1&lt;/code&gt;, &lt;code&gt;1.2&lt;/code&gt;, and so on, while a major one will increase the leftmost number and reset the rightmost, producing versions &lt;code&gt;2.0&lt;/code&gt;, &lt;code&gt;3.0&lt;/code&gt;, and so on. A typical version trail might be for example &lt;code&gt;1.0&lt;/code&gt;, &lt;code&gt;1.1&lt;/code&gt;, &lt;code&gt;1.2&lt;/code&gt;, &lt;code&gt;2.0&lt;/code&gt;, &lt;code&gt;2.1&lt;/code&gt;, &lt;code&gt;3.0&lt;/code&gt;, and so on.&lt;/p&gt;&lt;p&gt;From the point of view of the expressivity, comparing version numbers in this scheme tells us more about the changes that occurred. Version &lt;code&gt;1.3&lt;/code&gt; that follows version &lt;code&gt;1.2&lt;/code&gt; will have minor changes, while a jump from &lt;code&gt;1.3&lt;/code&gt; to &lt;code&gt;2.0&lt;/code&gt; will contain code with a greater impact. Please note, however, that we still have to define what "major" and "minor" mean in this context, and that "greater impact" is thus still a vague concept. When we consider coverage we also see improvements in this scheme when compared to the previous one. If both versions &lt;code&gt;1.0&lt;/code&gt; and &lt;code&gt;2.0&lt;/code&gt; are actively maintained, a minor change that affects both will simple generate versions &lt;code&gt;1.1&lt;/code&gt; and &lt;code&gt;2.1&lt;/code&gt;.&lt;/p&gt;&lt;h2 id="about-numbering"&gt;About numbering&lt;a class="headerlink" href="#about-numbering" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I think it is important at this point to discuss numbering systems a bit more in-depth. If you are not very familiar with software versioning you might have been surprised by the version trail shown above: why is version &lt;code&gt;1.0&lt;/code&gt; the first one and not &lt;code&gt;1.1&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;Generally, we start counting from 1, and if you ask someone to tell you the first ten numbers, he or she will likely answer with the sequence 1, 2, 3, ..., 10. Base-10 numerals, however, go from 0 to 9, so we might argue that zero should be considered the first number. You might be surprised to discover that this debate is all but simple and that there are many different conventions and opinions on the matter.&lt;/p&gt;&lt;p&gt;In particular, in computer programming, there are languages that index arrays from 0 (e.g. Lisp, C, Python, JavaScript), and languages that opted for 1-indexed arrays (e.g. Fortran, COBOL, MATLAB). While it might be argued that indexing from zero is exactly what we do when we consider all numbers with a given amount of digits, there is an ambiguity in the common language since we name positions in a list starting from 1, thus mixing the cardinal and ordinal system. For example, in English, the word "third" comes from three, "fourth" comes from four ("the first” comes from "the foremost" and “the second” comes from the Latin secundus), so if we used 0-indexed sequences we would end up with the third element having index 2, the fourth having index 3, and so on.&lt;/p&gt;&lt;p&gt;This ambiguity comes from the rather late introduction of the number zero in western culture, officially around 1200, and if you think this doesn't affect your everyday life please consider how you read the clock. The day starts at 00:00, not at 01:01. Indeed "the first hour" is hour number 0.&lt;/p&gt;&lt;p&gt;When it comes to versioning, it's commonly accepted that the first version of a piece of software is &lt;code&gt;1.0&lt;/code&gt;, and as you can see if that's true there is inconsistency between the way we treat the first digit and the second one. Versions starting with 0 exist but they are usually considered belonging to the early stages of development and thus being "unstable". I will come back to this point later.&lt;/p&gt;&lt;h2 id="incompatibility-and-versioning"&gt;Incompatibility and versioning&lt;a class="headerlink" href="#incompatibility-and-versioning" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Previously I talked about changes that introduce an incompatibility, but I did not formally define this concept. &lt;em&gt;Incompatibility&lt;/em&gt;, in the computer world, is the complete or partial impossibility of using a version of a piece of software (or hardware) in place of another. &lt;/p&gt;&lt;p&gt;Let’s consider a simple example taken from the everyday life of a common computer user. I can write a document using Microsoft Word 2007 and save it in its native format, namely DOCX. Then I send the file to another person, who can only use Word 2003 and he or she cannot open it. Why? Simply because the changes introduced in Office 2007 to the file format are incompatible, that is they change the file format to such an extent that a previous version of the software cannot even show a part of the content.&lt;/p&gt;&lt;p&gt;As you can imagine, the fields where incompatibility problems can arise are many. Speaking in general every part of a piece of software (or hardware) that is exposed to external systems can be affected by incompatibility issues. Such parts are altogether known as &lt;em&gt;interfaces&lt;/em&gt;, and according to the field of application, you can have network interfaces, programming interfaces, hardware interfaces, etc.&lt;/p&gt;&lt;p&gt;An example borrowed from the hardware world will make this clear. If you design a new version of a webcam, replacing the internal components to provide a much better picture quality but keeping the same connector (e.g. USB-A) it used previously, every user will be able to instantly switch to the new version. If you change the connector (e.g. from USB-A to USB-C) users might have to buy an adapter, if their notebook doesn't have ports with the new interface.&lt;/p&gt;&lt;p&gt;It should be noted at this point that not every change to an interface introduces an incompatibility. A &lt;em&gt;backward compatible interface&lt;/em&gt; can act both as the new version and the old one (or ones), either automatically or manually driven. For example, the previously mentioned Office 2007 is backwards compatible with Office 2003 since it can automatically read the old file format and can manually be driven to save a file in that format.&lt;/p&gt;&lt;p&gt;Users will always take for granted that your software is backwards compatible with its previous versions. So it would be highly desirable for a versioning scheme to be able to clearly show possible incompatibilities in its interfaces when moving between versions to the next. The details of the incompatibility would still require to be clarified in the documentation, but the version numbers would act as a first warning.&lt;/p&gt;&lt;h2 id="example-semantic-versioning"&gt;Example: semantic versioning&lt;a class="headerlink" href="#example-semantic-versioning" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;A well-known and widespread versioning scheme is Semantic Versioning (also known as SemVer), which full documentation can be found at &lt;a href="https://semver.org/"&gt;https://semver.org/&lt;/a&gt;. The central idea of this scheme is to use three numbers separated by dots and to assign to each of them a meaning that is strictly connected with the changes to the interfaces.&lt;/p&gt;&lt;p&gt;As you can read in the official documentation, a SemVer version is expressed as &lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt; where a change of the &lt;code&gt;MAJOR&lt;/code&gt; number signals an incompatible change, a change of the &lt;code&gt;MINOR&lt;/code&gt; a compatible change, and a change of &lt;code&gt;PATCH&lt;/code&gt; a bugfix (again, backward compatible).&lt;/p&gt;&lt;p&gt;As you can see, it's very easy to understand what we should expect from an upgrade just by looking at the version numbers. An upgrade from version &lt;code&gt;2.3.0&lt;/code&gt; to version &lt;code&gt;2.3.1&lt;/code&gt; is supposed to just fix issues and thus can be done safely. An upgrade from version &lt;code&gt;2.3.0&lt;/code&gt; to version &lt;code&gt;2.4.0&lt;/code&gt; will introduce new features or mark some as deprecated (but still keeping them active), which means that we can upgrade safely, but we should have a good look at the documentation to know what is going on. Last, a change from version &lt;code&gt;2.3.0&lt;/code&gt; to version &lt;code&gt;3.0.0&lt;/code&gt; is supposed to be destructive, so it has to be planned carefully.&lt;/p&gt;&lt;p&gt;SemVer allows to label pre-releases and to append build metadata, and the versioning system documentation has been versioned with SemVer itself, having reached version 2.0.0 in 2013.&lt;/p&gt;&lt;p&gt;Please note, however, that the documentation states that "Software using Semantic Versioning MUST declare a public API", which makes it clear that the scheme is well suited for libraries and may be less useful or appropriate for user-facing tools like frameworks and programming languages.&lt;/p&gt;&lt;h2 id="example-calendar-versioning"&gt;Example: calendar versioning&lt;a class="headerlink" href="#example-calendar-versioning" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;While semantic versioning proposes a pretty strict approach and set of rules, Calendar versioning (CalVer) is more intended to be a set of guidelines to design your own versioning scheme. Despite the name, calendar versioning is not strictly connected with objective time but rather tries to make the release number more connected with the release calendar of the piece of software you maintain.&lt;/p&gt;&lt;p&gt;As such, CalVer versions usually incorporate a part that is time-related, and other numbers that are more similar to the ones used by SemVer in that they try to capture and communicate the extent of changes made in a version.&lt;/p&gt;&lt;p&gt;You can read CalVer documentation at &lt;a href="https://calver.org/"&gt;https://calver.org/&lt;/a&gt;.&lt;/p&gt;&lt;h2 id="versioning-is-a-discipline"&gt;Versioning is a discipline&lt;a class="headerlink" href="#versioning-is-a-discipline" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Versioning is not a set of fixed rules, but a &lt;em&gt;methodology&lt;/em&gt;. When a development group follows a new methodology it both adopts and adapts it. Adopting means shifting the work procedures to follow those proposed by the methodology while adapting means changing the methodology to fit the environment where it is supposed to be used.&lt;/p&gt;&lt;p&gt;Versioning is a &lt;em&gt;discipline&lt;/em&gt;, a way of thinking, where rules are the product of general concepts modelled after the scope and the environment where they are used. So the versioning scheme of a product can vary over time since product or user requirements change.&lt;/p&gt;&lt;p&gt;Software is one of the environments where design is faster, always changing, and distributed among several people, so many things need to be versioned, not just the final product. The latter, indeed, could have a life cycle of several years, but in the meantime, bug fixes could be released, experimental code produced, tools and documentation enhanced. All those things can, and many times they should, be versioned.&lt;/p&gt;&lt;p&gt;Do not assume that one single versioning scheme can fit all your needs. The method for dealing with an object is imposed by the object itself, so the versioning scheme is imposed by the versioned object. Your documentation probably needs a different scheme from a software tool.&lt;/p&gt;&lt;p&gt;Thus, the following guidelines must be shaped by the specific needs of the development group, and these are forced by the product, the size of the team, the market and several other surrounding conditions of which each team manager should take account. &lt;/p&gt;&lt;p&gt;1. &lt;strong&gt;Versioning rules and procedures should take into account not only current needs but also future ones&lt;/strong&gt;, to avoid as much as possible to be forced to change them. When you design something it is advisable to consider the matter from several points of view and to explore different “what if?” scenarios.&lt;/p&gt;&lt;p&gt;2. &lt;strong&gt;Versioning rules must be clearly explained&lt;/strong&gt; and written in an easily accessible document (e.g. on an intranet in HTML format). Rules must be short, and you should provide use cases and answers to frequently asked questions.&lt;/p&gt;&lt;p&gt;3. &lt;strong&gt;Versioning rules must be quickly changed if they are no more suitable&lt;/strong&gt; to the use cases that the developers have to deal with. One of the Extreme Programming mantras, “embrace change”, must be the spirit of any rule system which aims to be useful.&lt;/p&gt;&lt;p&gt;4. &lt;strong&gt;The change of versioning rules should be fully backwards compatible if possible.&lt;/strong&gt; Every time the system evolves, it should thus become a superset of the previous rules. This way the technical shock originated by the change can be easily absorbed. Backward compatibility is not always possible to achieve, and in such cases, the two systems should possibly be marked so that a version number is unequivocally connected to one of them (using a prefix, for example). The date when the new system takes over the old one must be recorded.&lt;/p&gt;&lt;h2 id="finale"&gt;Finale&lt;a class="headerlink" href="#finale" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As you can see there is much to say about this subject, and this article only scratches the surface of the matter. However, I hope it helped you to have a big picture of the different aspects that hide behind those simple labels or numbers called versions.&lt;/p&gt;&lt;p&gt;If you are managing a project and are looking for a tool to manage the versions you might want to have a look at &lt;a href="https://github.com/lgiordani/punch"&gt;punch&lt;/a&gt;, a highly configurable tool written in Python that can automatically increase the version number in any file according to the versioning rules you defined.&lt;/p&gt;&lt;h2 id="resources"&gt;Resources&lt;a class="headerlink" href="#resources" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;The Wikipedia article on &lt;a href="https://en.wikipedia.org/wiki/Software_versioning"&gt;Software versioning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;The official page of &lt;a href="https://semver.org/"&gt;Semantic Versionining&lt;/a&gt;&lt;/li&gt;&lt;li&gt;The official page of &lt;a href="https://calver.org/"&gt;Calendar Versionining&lt;/a&gt;&lt;/li&gt;&lt;li&gt;The Wikipedia article on &lt;a href="https://en.wikipedia.org/wiki/Zero-based_numbering"&gt;Zero-based_numbering&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;</content><category term="Programming"></category><category term="versioning"></category></entry><entry><title>Clean Architectures in Python: the book</title><link href="https://www.thedigitalcatonline.com/blog/2018/12/20/cabook/" rel="alternate"></link><published>2018-12-20T08:00:00+01:00</published><updated>2021-08-22T08:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2018-12-20:/blog/2018/12/20/cabook/</id><summary type="html">&lt;p&gt;A practical approach to better software design&lt;/p&gt;</summary><content type="html">&lt;p&gt;The second edition of the book "Clean Architectures in Python. A practical approach to better software design" is out!&lt;/p&gt;
&lt;div class="center-image"&gt;
&lt;img src="/images/cabook/cover.jpg" alt="Cover" /&gt;
&lt;/div&gt;

&lt;p&gt;You can read the book online on the new website &lt;a href="https://www.thedigitalcatbooks.com/"&gt;The Digital Cat Books&lt;/a&gt; or download a PDF version &lt;a href="https://leanpub.com/clean-architectures-in-python"&gt;from Leanpub&lt;/a&gt;. If you enjoy it, please tweet about it with the &lt;code&gt;#pycabook&lt;/code&gt; hashtag.&lt;/p&gt;
&lt;p&gt;So far more than 16,000 readers downloaded the book. Thank you all!&lt;/p&gt;</content><category term="Projects"></category><category term="OOP"></category><category term="Python"></category><category term="Python2"></category><category term="Python3"></category><category term="TDD"></category><category term="testing"></category><category term="architectures"></category></entry><entry><title>Flask project setup: TDD, Docker, Postgres and more - Part 1</title><link href="https://www.thedigitalcatonline.com/blog/2020/07/05/flask-project-setup-tdd-docker-postgres-and-more-part-1/" rel="alternate"></link><published>2020-07-05T13:00:00+01:00</published><updated>2021-08-22T10:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2020-07-05:/blog/2020/07/05/flask-project-setup-tdd-docker-postgres-and-more-part-1/</id><summary type="html">&lt;p&gt;A step-by-step tutorial on how to setup a Flask project with TDD, Docker and Postgres&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are tons of tutorials on Internet that tech you how to use a web framework and how to create Web applications, and many of these cover Flask, first of all the impressive &lt;a href="https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world"&gt;Flask Mega-Tutorial&lt;/a&gt; by Miguel Grinberg (thanks Miguel!). &lt;/p&gt;&lt;p&gt;Why another tutorial, then? Recently I started working on a small personal project and decided that it was a good chance to refresh my knowledge of the framework. For this reason I temporarily dropped the &lt;a href="https://www.thedigitalcatbooks.com/pycabook-introduction/"&gt;clean architecture&lt;/a&gt; I often recommend, and started from scratch following some tutorials. My development environment quickly became very messy, and after a while I realised I was very unsatisfied by the global setup.&lt;/p&gt;&lt;p&gt;So, I decided to start from scratch again, this time writing down some requirements I want from my development setup. I also know very well how complicated the deploy of an application in production can be, so I want my setup to be "deploy-friendly" as much as possible. Having seen too many project suffer from legacy setups, and knowing that many times such issues can be avoided with a minimum amount of planning, I thought this might be interesting for other developers as well. I consider this setup by no means &lt;em&gt;better&lt;/em&gt; than others, it simply addresses different concerns.&lt;/p&gt;&lt;h2 id="what-you-will-learn"&gt;What you will learn&lt;a class="headerlink" href="#what-you-will-learn" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This post contains a step-by-step description of how I set up a real Flask project that I am working on. It's important that you understand that this is just one of many possible setups, and that my choices are both a matter of personal taste and dictated by some goals that I will state in this section. Changing the requirements would clearly result in a change of the structure. The target of the post is then to show that the setup of a project can take into account many things upfront, without leaving them to an undetermined future when it will likely be too late to tackle them properly.&lt;/p&gt;&lt;p&gt;The requirements of my setup are the following:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Use the same database engine in production, in development and for tests&lt;/li&gt;&lt;li&gt;Run test on an ephemeral database&lt;/li&gt;&lt;li&gt;Run in production with no changes other that the static configuration&lt;/li&gt;&lt;li&gt;Have a command to initialise databases and manage migrations&lt;/li&gt;&lt;li&gt;Have a way to spin up "scenarios" starting from an empty database, to create a sandbox where I can test queries&lt;/li&gt;&lt;li&gt;Possible simulate production in the local environment&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;As for the technologies, I will use Flask, obviously, as the web framework. I will also use Gunicorn as HTTP server (in production) and Postgres for the database part. I won't show here how to create the production infrastructure, but as I work daily with AWS, I will take into account some of its requirements, trying however not to be too committed to a specific solution.&lt;/p&gt;&lt;h2 id="a-general-advice"&gt;A general advice&lt;a class="headerlink" href="#a-general-advice" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Proper setup is an investment for the future. As we do in TDD, where we decide to spend time now (writing tests) to avoid spending tenfold later (to find and correct bugs), setting up a project requires time, and might frustrate the desire of "see things happen". Proper setup is a discipline that requires patience and commitment!&lt;/p&gt;&lt;p&gt;If you are ready to go, join me for this journey towards a great setup of a Flask application.&lt;/p&gt;&lt;h2 id="the-golden-rule"&gt;The golden rule&lt;a class="headerlink" href="#the-golden-rule" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The golden rule of any proper infrastructural work is: there has to be a single source of information. The configuration of you project shouldn't be scattered among different files or repositories (not considering secrets, that have to be stored securely). The configuration has to be accessible and easy to convert into different formats to accommodate the needs of different tools. For this reason, the configuration should be stored in a static file format like JSON, YAML, INI, or similar, which can be read and processed by different programming languages and tools.&lt;/p&gt;&lt;p&gt;My format of choice for this tutorial is JSON, as it can be read by both Python and Terraform, and is natively used by ECS on AWS.&lt;/p&gt;&lt;h2 id="step-1---requirements-and-editor"&gt;Step 1 - Requirements and editor&lt;a class="headerlink" href="#step-1---requirements-and-editor" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;My standard structure for Python requirements uses 3 files: &lt;code&gt;production.txt&lt;/code&gt;, &lt;code&gt;development.txt&lt;/code&gt;, and &lt;code&gt;testing.txt&lt;/code&gt;. They are all stored in the same directory called &lt;code&gt;requirements&lt;/code&gt;, and are hierarchically connected. &lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;requirements/production.txt&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;## This file is currently empty
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;requirements/testing.txt&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-r production.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;requirements/development.txt&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-r testing.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;There is also a final file &lt;code&gt;requirements.txt&lt;/code&gt; that points to the production one.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;requirements.txt&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-r requirements/production.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see this allows me to separate the requirements to avoid installing unneeded packages, which greatly speeds up the deploy in production and keeps things as essential as possible. Production contains the minimum requirements needed to run the project, testing adds to those the packages used to test the code, and development adds to the latter the tools needed during development. A minor shortcoming of this setup is that I might not need in development everything I need in production, for example the HTTP server. I don't think this is significantly affecting my local setup, though, and if I have to decide between production and development, I prefer to keep the former lean and tidy.&lt;/p&gt;&lt;p&gt;I have my linters already installed system-wide, but as I'm using black to format the code I have to configure flake8 to accept what I'm doing&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;.flake8&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[flake8]
# Recommend matching the black line length (default 88),
# rather than using the flake8 default of 79:
max-line-length = 100
ignore = E231
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This is clearly a very personal choice, and you might have different requirements. Take your time to properly configure the editor and the linter(s). Remember that the editor for a programmer is like the violin for the violinist. You need to know it, and to take care of it. So, set it up properly.&lt;/p&gt;&lt;p&gt;At this point I also create my virtual environment and activate it.&lt;/p&gt;&lt;h3 id="git-commit"&gt;Git commit&lt;/h3&gt;&lt;p&gt;You can see the changes made in this step through &lt;a href="https://github.com/lgiordani/flask_project_setup/commit/a6c8e7acde7d5d5d89fad22224fff707d625ebe3"&gt;this Git commit&lt;/a&gt; or &lt;a href="https://github.com/lgiordani/flask_project_setup/tree/a6c8e7acde7d5d5d89fad22224fff707d625ebe3"&gt;browse the files&lt;/a&gt;.&lt;/p&gt;&lt;h3 id="resources"&gt;Resources&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://packaging.python.org/tutorials/installing-packages/"&gt;Installing packages in Python&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://flake8.pycqa.org/en/latest/"&gt;flake8&lt;/a&gt; - A tool for style guide enforcement&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/psf/black"&gt;black&lt;/a&gt; - The uncompromising Python code formatter&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="step-2---flask-project-boilerplate"&gt;Step 2 - Flask project boilerplate&lt;a class="headerlink" href="#step-2---flask-project-boilerplate" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As this will be a Flask application the first thing to do is to install Flask itself. That goes in the production requirements, as that is needed at every stage.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;requirements/production.txt&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Flask
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Now, install the development requirements with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ pip install -r requirements/development.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As we saw before, that file automatically installs the testing and production requirements as well.&lt;/p&gt;&lt;p&gt;Then we need a directory where to keep all the code that is directly connected with the Flask framework, and where we will start creating the configuration for the application. Create the directory &lt;code&gt;application&lt;/code&gt; and the file &lt;code&gt;config.py&lt;/code&gt; in it.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;application/config.py&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Base configuration&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ProductionConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Production configuration&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DevelopmentConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Development configuration&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestingConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Testing configuration&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="n"&gt;TESTING&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;There are many ways to configure a Flask application, one of which is using Python objects. This allows me to leverage inheritance to avoid duplication (which is always good), so it's my method of choice.&lt;/p&gt;&lt;p&gt;It's important to understand the variables and the parameters involved in the configuration. As the documentation clearly states, &lt;code&gt;FLASK_ENV&lt;/code&gt; and &lt;code&gt;FLASK_DEBUG&lt;/code&gt; have to be initialised outside the application as the code might misbehave if they are changed once the engine has been started. Furthermore the variable &lt;code&gt;FLASK_ENV&lt;/code&gt; can have only the two values &lt;code&gt;development&lt;/code&gt; and &lt;code&gt;production&lt;/code&gt;, and the main difference is in performances. The most important thing we need to be aware of is that if &lt;code&gt;FLASK_ENV&lt;/code&gt; is &lt;code&gt;development&lt;/code&gt;, then &lt;code&gt;FLASK_DEBUG&lt;/code&gt; becomes automatically &lt;code&gt;True&lt;/code&gt;. To sum up we have the following guidelines:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It's pointless to set &lt;code&gt;DEBUG&lt;/code&gt; and &lt;code&gt;ENV&lt;/code&gt; in the application configuration, they have to be environment variables.&lt;/li&gt;&lt;li&gt;Generally you don't need to set &lt;code&gt;FLASK_DEBUG&lt;/code&gt;, just set &lt;code&gt;FLASK_ENV&lt;/code&gt; to &lt;code&gt;development&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;Testing doesn't need the debug server turned on, so you can set &lt;code&gt;FLASK_ENV&lt;/code&gt; to &lt;code&gt;production&lt;/code&gt; during that phase. It needs &lt;code&gt;TESTING&lt;/code&gt; set to &lt;code&gt;True&lt;/code&gt;, though, and that has to be done inside the application.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We need now to create the application and to properly configure it.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;application/app.py&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_app&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config_name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="callout"&gt;1&lt;/span&gt;

    &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;config_module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;application.config.&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;config_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;capitalize&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;Config&amp;quot;&lt;/span&gt; &lt;span class="callout"&gt;2&lt;/span&gt;

    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config_module&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="nd"&gt;@app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="callout"&gt;3&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hello_world&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Hello, World!&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;I decided to use an application factory &lt;span class="callout"&gt;1&lt;/span&gt; that accepts a string &lt;code&gt;config_name&lt;/code&gt; that is then converted into the name of the config object &lt;span class="callout"&gt;2&lt;/span&gt;. For example, if &lt;code&gt;config_name&lt;/code&gt; is &lt;code&gt;development&lt;/code&gt; the variable &lt;code&gt;config_module&lt;/code&gt; becomes &lt;code&gt;application.config.DevelopmentConfig&lt;/code&gt; so that &lt;code&gt;app.config.from_object&lt;/code&gt; can import it. I also added the standard "Hello, world!" route &lt;span class="callout"&gt;3&lt;/span&gt; to have a quick way to see if the server is working or not.&lt;/p&gt;&lt;p&gt;Last, we need something that initializes the application running the application factory and passing the correct value for the parameter &lt;code&gt;config_name&lt;/code&gt;. The Flask development server can automatically use any file named &lt;code&gt;wsgi.py&lt;/code&gt; in the root directory, and since WSGI is a standard specification using that makes me sure that any HTTP server we will use in production (for example Gunicorn or uWSGI) will be immediately working.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;wsgi.py&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;application.app&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;create_app&lt;/span&gt;

&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_app&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;FLASK_CONFIG&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Here, I decided to read the value of &lt;code&gt;config_name&lt;/code&gt; from the variable &lt;code&gt;FLASK_CONFIG&lt;/code&gt;. This is not a variable requested by the framework, but I decided to use the prefix &lt;code&gt;FLASK_&lt;/code&gt; anyway because it is tightly connected with the structure of the Flask application.&lt;/p&gt;&lt;p&gt;At this point we can happily run the Flask development server with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nv"&gt;FLASK_CONFIG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; flask run
 * Environment: production
   WARNING: This is a development server. Do not use it &lt;span class="k"&gt;in&lt;/span&gt; a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on http://127.0.0.1:5000/ &lt;span class="o"&gt;(&lt;/span&gt;Press CTRL+C to quit&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Please note that it says &lt;code&gt;Environment: production&lt;/code&gt; because we haven't configured &lt;code&gt;FLASK_ENV&lt;/code&gt; yet. If you head to &lt;a href="http://127.0.0.1:5000/"&gt;http://127.0.0.1:5000/&lt;/a&gt; with your browser you can see the greetings message.&lt;/p&gt;&lt;h3 id="git-commit"&gt;Git commit&lt;/h3&gt;&lt;p&gt;You can see the changes made in this step through &lt;a href="https://github.com/lgiordani/flask_project_setup/commit/656621980f6f2c2aac3c526b37dca6ac32363bd5"&gt;this Git commit&lt;/a&gt; or &lt;a href="https://github.com/lgiordani/flask_project_setup/tree/656621980f6f2c2aac3c526b37dca6ac32363bd5"&gt;browse the files&lt;/a&gt;.&lt;/p&gt;&lt;h3 id="resources"&gt;Resources&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://flask.palletsprojects.com/en/1.1.x/config/"&gt;Flask configuration documentation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://flask.palletsprojects.com/en/1.1.x/patterns/appfactories/"&gt;Flask application factories&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://wsgi.readthedocs.io/en/latest/what.html"&gt;WSGI&lt;/a&gt; - The Python Web Server Gateway Interface&lt;/li&gt;&lt;li&gt;My post &lt;a href="https://www.thedigitalcatonline.com/blog/2020/02/16/dissecting-a-web-stack/"&gt;Dissecting a web stack&lt;/a&gt; includes a section on WSGI&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="step-3---application-configuration"&gt;Step 3 - Application configuration&lt;a class="headerlink" href="#step-3---application-configuration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As I mentioned in the introduction, I am going to use a static JSON configuration file. The choice of JSON comes from the fact that it is a widespread file format, accessible from many programming languages, included Terraform, which I plan to use to create my production infrastructure.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;config/development.json&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;FLASK_ENV&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;FLASK_CONFIG&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;I obviously need a script that extracts variables from the JSON file and converts them into environment variables, so it's time to start writing my own &lt;code&gt;manage.py&lt;/code&gt; file. This is a pretty standard concept in the world of Python web frameworks, a tradition initiated by Django. The idea is to centralise all the management functions like starting/stopping the development server or managing database migrations. As in flask this is partially done by the command &lt;code&gt;flask&lt;/code&gt; itself, for the time being I just need to wrap it providing suitable environment variables.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;manage.py&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#! /usr/bin/env python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;signal&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;click&lt;/span&gt;


&lt;span class="c1"&gt;# Ensure an environment variable exists and has a value&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;setenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="n"&gt;setenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;APPLICATION_CONFIG&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="callout"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# Read configuration from the relative JSON file&lt;/span&gt;
&lt;span class="n"&gt;config_json_filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;APPLICATION_CONFIG&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.json&amp;quot;&lt;/span&gt; &lt;span class="callout"&gt;2&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;config&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config_json_filename&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Convert the config into a usable Python dictionary&lt;/span&gt;
&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;setenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;


&lt;span class="nd"&gt;@cli&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;context_settings&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ignore_unknown_options&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;subcommand&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nargs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subcommand&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="callout"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;cmdline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;flask&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subcommand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Popen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmdline&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;send_signal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SIGINT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;flask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Remember to make the script executable with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ chmod &lt;span class="m"&gt;775&lt;/span&gt; manage.py
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see I'm using &lt;code&gt;click&lt;/code&gt;, which is the recommended way to implement Flask commands. As I might use it to customise subcommands of the flask main script, I decided to stick to one tool and use it for the script &lt;code&gt;manage.py&lt;/code&gt; as well.&lt;/p&gt;&lt;p&gt;The variable &lt;code&gt;APPLICATION_CONFIG&lt;/code&gt; &lt;span class="callout"&gt;1&lt;/span&gt; is the only one that I need to specify, and its default value is &lt;code&gt;development&lt;/code&gt;. From that variable I infer the name of the JSON file with the full configuration &lt;span class="callout"&gt;2&lt;/span&gt; and load environment variables from that. The function &lt;code&gt;flask&lt;/code&gt; &lt;span class="callout"&gt;3&lt;/span&gt; simply wraps the command &lt;code&gt;flask&lt;/code&gt; provided by Flask so that I can run &lt;code&gt;./manage.py flask SUBCOMMAND&lt;/code&gt; to run it using the configuration &lt;code&gt;development&lt;/code&gt; or &lt;code&gt;APPLICATION_CONFIG=&amp;quot;foobar&amp;quot; ./manage.py flask SUBCOMMAND&lt;/code&gt; to use the &lt;code&gt;foobar&lt;/code&gt; one.&lt;/p&gt;&lt;p&gt;A clarification, to be sure you don't confuse environment variables with each other:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;APPLICATION_CONFIG&lt;/code&gt; is strictly related to my project and is used &lt;em&gt;only&lt;/em&gt; to load a JSON configuration file with the name specified in the variable itself.&lt;/li&gt;&lt;li&gt;&lt;code&gt;FLASK_CONFIG&lt;/code&gt; is used to select the Python object that contains the configuration for the Flask application (see &lt;code&gt;application/app.py&lt;/code&gt; and &lt;code&gt;application/config.py&lt;/code&gt;). The value of the variable is converted into the name of a class.&lt;/li&gt;&lt;li&gt;&lt;code&gt;FLASK_ENV&lt;/code&gt; is a variable used by Flask itself, and its values are dictated by it. See the configuration documentation mentioned in the resources of the previous section.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Now we can run the development server&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./manage.py flask run
 * Environment: development
 * Debug mode: on
 * Running on http://127.0.0.1:5000/ &lt;span class="o"&gt;(&lt;/span&gt;Press CTRL+C to quit&lt;span class="o"&gt;)&lt;/span&gt;
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: &lt;span class="m"&gt;172&lt;/span&gt;-719-201
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Note that it now says &lt;code&gt;Environment: development&lt;/code&gt; because of &lt;code&gt;FLASK_ENV&lt;/code&gt; has been set to &lt;code&gt;development&lt;/code&gt; in the configuration. As we did before, a quick visit to &lt;a href="http://127.0.0.1:5000/"&gt;http://127.0.0.1:5000/&lt;/a&gt; shows us that everything is up and running.&lt;/p&gt;&lt;h3 id="git-commit"&gt;Git commit&lt;/h3&gt;&lt;p&gt;You can see the changes made in this step through &lt;a href="https://github.com/lgiordani/flask_project_setup/commit/8330e792aa55d2903fd4846487c64de12530c0d3"&gt;this Git commit&lt;/a&gt; or &lt;a href="https://github.com/lgiordani/flask_project_setup/tree/8330e792aa55d2903fd4846487c64de12530c0d3"&gt;browse the files&lt;/a&gt;.&lt;/p&gt;&lt;h3 id="resources"&gt;Resources:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/3.0/ref/django-admin/"&gt;Django&amp;#x27;s management script&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://click.palletsprojects.com/en/7.x/"&gt;Click&lt;/a&gt; - A Python package for creating command line interfaces &lt;/li&gt;&lt;/ul&gt;&lt;h2 id="step-4---containers-and-orchestration"&gt;Step 4 - Containers and orchestration&lt;a class="headerlink" href="#step-4---containers-and-orchestration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;There is no better way to simplify your development than using Docker.&lt;/p&gt;&lt;p&gt;There is also no better way to complicate your life than using Docker.&lt;/p&gt;&lt;p&gt;As you might guess, I have mixed feelings about Docker. Don't get me wrong, Linux containers are an amazing concept, and Docker is very useful. It's also a complex technology that sometimes requires a lot of work to get properly configured. In this case the setup will be pretty simple, but there is a major complication with using a database server that I will describe later.&lt;/p&gt;&lt;p&gt;Running the application in a Docker container allows me to isolate it and to simulate the way I will run it in production. I will use docker-compose, as I expect to have other containers running in my development setup (at least the database), so I can leverage the fact that the docker-compose configuration file can interpolate environment variables. Once again through the environment variable &lt;code&gt;APPLICATION_CONFIG&lt;/code&gt; I will select the correct JSON file, load its values in environment variables and then run the docker-compose file.&lt;/p&gt;&lt;p&gt;First of all we need an image for the Flask application&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;docker/Dockerfile&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;python:3&lt;/span&gt;

&lt;span class="k"&gt;ENV&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;PYTHONUNBUFFERED &lt;span class="m"&gt;1&lt;/span&gt;

&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;mkdir /opt/code
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;mkdir /opt/requirements
&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/opt/code&lt;/span&gt;

&lt;span class="k"&gt;ADD&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;requirements /opt/requirements
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pip install -r /opt/requirements/development.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see the requirements directory is copied into the image, so that Docker can run the command &lt;code&gt;pip install&lt;/code&gt; at creation time. The whole code directory will be mounted live into the image at run time.&lt;/p&gt;&lt;p&gt;This clearly means that every time we change the development requirements we need to rebuild the image. This is not a complicated process, so I will keep it as a manual process for now. To run the image we can create a configuration file for docker-compose.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;docker/development.yml&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#39;3.4&amp;#39;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;web&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;build&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;context&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;${PWD}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;dockerfile&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;docker/Dockerfile&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;environment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;FLASK_ENV&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;${FLASK_ENV}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;FLASK_CONFIG&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;${FLASK_CONFIG}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;command&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;flask run --host 0.0.0.0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;volumes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;${PWD}:/opt/code&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;ports&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;5000:5000&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As you can see, the docker-compose configuration file can read environment variables natively. To run it we first need to add docker-compose itself to the development requirements.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;requirements/development.txt&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-r testing.txt

docker-compose
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Install it with &lt;code&gt;pip install -r requirements/development.txt&lt;/code&gt;, then build the image with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nv"&gt;FLASK_ENV&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; &lt;span class="nv"&gt;FLASK_CONFIG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; docker-compose -f docker/development.yml build web
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This will take some time, as Docker has to download all the required layers and install the requirements.&lt;/p&gt;&lt;p&gt;We are explicitly passing environment variables here, as we have not wrapped docker-compose in the manage script yet. Once the image has been build, we can run it with the command &lt;code&gt;up&lt;/code&gt;&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nv"&gt;FLASK_ENV&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; &lt;span class="nv"&gt;FLASK_CONFIG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; docker-compose -f docker/development.yml up
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This command gives us the following output&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Creating network &amp;quot;docker_default&amp;quot; with the default driver
Creating docker_web_1 ... done
Attaching to docker_web_1
web_1  |  * Environment: development
web_1  |  * Debug mode: on
web_1  |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
web_1  |  * Restarting with stat
web_1  |  * Debugger is active!
web_1  |  * Debugger PIN: 234-361-737
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You can stop the containers pressing &lt;code&gt;Ctrl-C&lt;/code&gt;, which gracefully tears down the system. If you run the command &lt;code&gt;up -d&lt;/code&gt; docker-compose will run as a daemon, leaving you the control of the current terminal. If docker-compose is running you can &lt;code&gt;docker ps&lt;/code&gt; and you should see an output similar to this&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;CONTAINER ID  IMAGE       COMMAND                 ...   PORTS                   NAMES
c98f35635625  docker_web  &amp;quot;flask run --host 0.…&amp;quot;  ...   0.0.0.0:5000-&amp;gt;5000/tcp  docker_web_1
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;If you need to explore the container you can login directly with &lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; -it docker_web_1 bash
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;or with&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nv"&gt;FLASK_ENV&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; &lt;span class="nv"&gt;FLASK_CONFIG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; docker-compose -f docker/development.yml &lt;span class="nb"&gt;exec&lt;/span&gt; web bash
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In either case, you will end up in the directory &lt;code&gt;/opt/code&lt;/code&gt; (which is the &lt;code&gt;WORKDIR&lt;/code&gt; of the image), where the current directory in the host is mounted.&lt;/p&gt;&lt;p&gt;To tear down the containers, when running as daemon, you can run&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nv"&gt;FLASK_ENV&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; &lt;span class="nv"&gt;FLASK_CONFIG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt; docker-compose -f docker/development.yml down
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Notice that the server now says &lt;code&gt;Running on http://0.0.0.0:5000/&lt;/code&gt;, as the Docker container is using that network interface to communicate with the outside world. Since the ports are mapped, however, you can head to either &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; or &lt;a href="http://0.0.0.0:5000"&gt;http://0.0.0.0:5000&lt;/a&gt; with your browser.&lt;/p&gt;&lt;p&gt;To simplify the usage of docker-compose, I want to wrap it in the script &lt;code&gt;manage.py&lt;/code&gt;, so that it automatically receives environment variables, as their number is going to increase as soon as we add a database.&lt;/p&gt;&lt;div class="code"&gt;&lt;div class="title"&gt;manage.py&lt;/div&gt;&lt;div class="content"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#! /usr/bin/env python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;signal&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;click&lt;/span&gt;

&lt;span class="n"&gt;docker_compose_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;docker/development.yml&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;docker_compose_cmdline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;docker-compose&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-f&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;docker_compose_file&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;


&lt;span class="c1"&gt;# Ensure an environment variable exists and has a value&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;setenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="n"&gt;setenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;APPLICATION_CONFIG&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;development&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Read configuration from the relative JSON file&lt;/span&gt;
&lt;span class="n"&gt;config_json_filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;APPLICATION_CONFIG&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.json&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;config&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config_json_filename&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Convert the config into a usable Python dictionary&lt;/span&gt;
&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;setenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;


&lt;span class="nd"&gt;@cli&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;context_settings&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ignore_unknown_options&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;subcommand&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nargs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subcommand&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;cmdline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;flask&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subcommand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Popen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmdline&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;send_signal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SIGINT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="nd"&gt;@cli&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;context_settings&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ignore_unknown_options&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;subcommand&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nargs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;compose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subcommand&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;cmdline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;docker_compose_cmdline&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subcommand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Popen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmdline&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;send_signal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SIGINT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;p&gt;You might have noticed that the two functions &lt;code&gt;flask&lt;/code&gt; and &lt;code&gt;compose&lt;/code&gt; are basically the same code, but I resisted the temptation to refactor them because I know that the command &lt;code&gt;compose&lt;/code&gt; will need some changes as soon as I add a database.&lt;/p&gt;&lt;p&gt;Now I can run &lt;code&gt;./manage.py compose up -d&lt;/code&gt; and &lt;code&gt;./manage.py compose down&lt;/code&gt; and have the environment variables automatically passed to the system.&lt;/p&gt;&lt;h3 id="git-commit"&gt;Git commit&lt;/h3&gt;&lt;p&gt;You can see the changes made in this step through &lt;a href="https://github.com/lgiordani/flask_project_setup/commit/9e08735af6177760cd750230122a507b15c9c112"&gt;this Git commit&lt;/a&gt; or &lt;a href="https://github.com/lgiordani/flask_project_setup/tree/9e08735af6177760cd750230122a507b15c9c112"&gt;browse the files&lt;/a&gt;.&lt;/p&gt;&lt;h3 id="resources"&gt;Resources&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker compose&lt;/a&gt; - A tool for defining and running multi-container Docker applications&lt;/li&gt;&lt;li&gt;&lt;a href="https://docs.docker.com/network/"&gt;Docker networking&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://docs.python.org/3/library/subprocess.html"&gt;Python subprocess module&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="final-words"&gt;Final words&lt;a class="headerlink" href="#final-words" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;That's enough for this first post. We started from scratch and added some boilerplate code for a Flask project, exploring what environment variables are used by the framework, then we added a configuration system, a management script, and finally we run everything in a Docker container. In the next post I will show you how to add a persistent database to the development setup and how to use an ephemeral one for the tests. If you find my posts useful please share them with whoever you thing might be interested. &lt;/p&gt;&lt;p&gt;Happy development!&lt;/p&gt;&lt;h2 id="updates"&gt;Updates&lt;a class="headerlink" href="#updates" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;2020-12-22 I reviewed the whole tutorial and corrected several typos&lt;/p&gt;&lt;h2 id="feedback"&gt;Feedback&lt;a class="headerlink" href="#feedback" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Feel free to reach me on &lt;a href="https://twitter.com/thedigicat"&gt;Twitter&lt;/a&gt; if you have questions. The &lt;a href="https://github.com/TheDigitalCatOnline/thedigitalcatonline.github.com/issues"&gt;GitHub issues&lt;/a&gt; page is the best place to submit corrections.&lt;/p&gt;</content><category term="Programming"></category><category term="AWS"></category><category term="devops"></category><category term="Docker"></category><category term="Flask"></category><category term="HTTP"></category><category term="Postgres"></category><category term="Python"></category><category term="Python3"></category><category term="TDD"></category><category term="testing"></category><category term="WWW"></category></entry><entry><title>Stop using tools as if they were solutions</title><link href="https://www.thedigitalcatonline.com/blog/2021/05/25/stop-using-tools-as-if-they-were-solutions/" rel="alternate"></link><published>2021-05-25T09:00:00+01:00</published><updated>2021-08-22T09:00:00+00:00</updated><author><name>Leonardo Giordani</name></author><id>tag:www.thedigitalcatonline.com,2021-05-25:/blog/2021/05/25/stop-using-tools-as-if-they-were-solutions/</id><summary type="html"></summary><content type="html">&lt;p&gt;&lt;em&gt;"I will write a class"&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;I can't tell you how many times I have heard this sentence from candidates during coding interviews.&lt;/p&gt;&lt;p&gt;What's wrong with this sentence? Nothing, out of context, but let me add this little detail: this is usually the first sentence I hear when the candidate tries to tackle a problem.&lt;/p&gt;&lt;p&gt;I know that coding interviews can be very stressful and I also think that leading such interviews requires a lot of effort to avoid transforming them into nitpicking sessions in which the candidate feels every single keystroke is scrutinised and analysed. As if the destiny of the whole company depended on how fast you can code a function that reverses a string!&lt;/p&gt;&lt;p&gt;But even taking into account interview anxiety, I think such an approach reveals something wrong deeper in the way we approach problems as programmers. This is the result of a culture that mistakes tools for solutions, and if I can detect it in senior programmers it means it already propagated into our teams and our companies.&lt;/p&gt;&lt;h2 id="the-problem-solving-challenge"&gt;The problem-solving challenge&lt;a class="headerlink" href="#the-problem-solving-challenge" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When you face a problem (&lt;em&gt;any&lt;/em&gt; problem) you need to devise a strategy to solve it. You need to have an idea of what to do before doing it, otherwise you are reacting and not acting.&lt;/p&gt;&lt;p&gt;When you practice any type of combat sport you train your body to react to specific inputs (attacks) with automatic reactions (defences, counterattacks), but you usually do it because in a real fight you don't have the time to make a conscious decision. Such "perfect" reactions, though, are the result of a constant and very focused effort to transform consciously selected actions into involuntary ones. Without training, a pure reaction is usually an average response at best.&lt;/p&gt;&lt;p&gt;In problem-solving we face the same challenge. Either we devise a strategy, or our approach will be clumsy and ultimately not efficient.&lt;/p&gt;&lt;p&gt;Imagine you were tasked to build a bridge between two sides of a river. Would your first concern be the specific type of hammers that the workers should use? After all, you can have ball-peen hammers, sledgehammers, brick hammers, and many other types. Choosing the wrong one might severely affect the performances of your workers.&lt;/p&gt;&lt;p&gt;That's hardly the first thing you should ask yourself. I'm pretty sure you agree that knowing the distance that the bridge should cover is much more urgent. Also, the type and the amount of traffic that it has to carry (walkers, cars, trucks, trains) is an important factor, and you should be concerned about the budget that you are allowed.&lt;/p&gt;&lt;p&gt;Why are these questions more important than the one about hammers? Because the answers to these questions can heavily influence the whole project. They are pillars of your architecture and not details&lt;sup&gt;[&lt;a id="fr--8217925" href="#fd--8217925"&gt;1&lt;/a&gt;]&lt;/sup&gt;. My colleague Ken Pemberton always reminds me that most of the time we don't ask ourselves an even more important question: "What problem are you trying to solve?". In the example above, a bridge might not be the best solution in the first place.&lt;/p&gt;&lt;p&gt;I think the process, at least when it comes to software projects, can be divided into three connected phases: decomposition, communication, implementation.&lt;/p&gt;&lt;h3 id="decomposition"&gt;Decomposition&lt;/h3&gt;&lt;p&gt;Macroscopically, a &lt;em&gt;processing system&lt;/em&gt; is made of an initial state, some transformations or intermediate states, and a final state.&lt;/p&gt;&lt;p&gt;Usually, it's simple to identify the initial and final state, while it's harder to describe what happens between the two. So, we need to proceed iteratively, describing the system using black boxes, and then opening each one of them, zooming in to describe what happens inside.&lt;/p&gt;&lt;p&gt;At any zoom level, from the 10,000 feet overview down to the description of a single function, you need to identify 4 things: the &lt;strong&gt;input&lt;/strong&gt;, the &lt;strong&gt;output&lt;/strong&gt;, the &lt;strong&gt;actors&lt;/strong&gt; and the &lt;strong&gt;data flow&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;The input is what enters the black box. It has usually been decided at a higher level of zoom or while discussing a component that provides it as output. So, it is given, and if it turns out to be inadequate we should take a step back in the design and question how we can provide proper input. The same is valid for the output.&lt;/p&gt;&lt;p&gt;The actors must be black boxes that accept data and transform it, and the data flow is how information is exchanged between the actors. This is clearly where it can take a long time to find a good solution, and we might need to go back and forth several times.&lt;/p&gt;&lt;p&gt;Let's look at an example. A search engine is a complicated piece of software, and implementing it is not a matter of 1 hour of work. But we can decompose it pretty easily, starting from the fact that the input of the system is a query, and that the output is an ordered set of results. So, my overview of this component is the following: the user inputs a query, the query is processed and the system returns a list of results, ordered by quality.&lt;/p&gt;&lt;p&gt;I didn't describe what "quality" is, nor discussed the specific implementation of the system that stores all possible results. Those details are buried down somewhere at a certain level of zoom and are utterly useless at this level.&lt;/p&gt;&lt;h3 id="communication"&gt;Communication&lt;/h3&gt;&lt;p&gt;Any level of zoom in the decomposition can be described, and the amount of specific technical knowledge needed to understand the explanation should be directly proportional to the zoom level. You might have heard the quote "You do not really understand something unless you can explain it to your grandmother." I believe this might be very offensive to grandmothers, but paraphrasing it, I would say that "There should be a zoom level at which the project is understandable by anyone who doesn't have a specific knowledge of the field".&lt;/p&gt;&lt;p&gt;Indeed, the problem of technical communication is that tech-savvy gurus are usually not able to decompose what they are working on into black boxes that are sufficiently abstract to be understandable by any human being. Please note this can happen to anyone, not only to programmers. I had to listen enough times to people working in banking, insurances, or project management (just to name a few different fields) to know that they can be unable to describe their job or specific aspects of it without using 4 obscure words every 5 words, the fifth one probably being a conjunction.&lt;/p&gt;&lt;p&gt;Being a blogger and an author I want to add a consideration about communication. Explaining things is the best way to see if everything is clear in your mind, which is another way to read the previous quote (without involving grandmothers). The very same post that you are reading started as an intuition, a small list of ideas, and so far has been rewritten 6 times. In the process, I understood the topics I am discussing much better than I did when I first felt the need to write them down.&lt;/p&gt;&lt;h3 id="implementation"&gt;Implementation&lt;/h3&gt;&lt;p&gt;Professor Sidney Morris, in a &lt;a href="https://www.youtube.com/watch?v=T1snRQEQuEk"&gt;very interesting video&lt;/a&gt; about how to write proofs in mathematics, describes the process with these words:&lt;/p&gt;&lt;div class="excerpt"&gt;&lt;div class="content"&gt;&lt;ul&gt;&lt;li&gt;Step 1: write down what we are given&lt;/li&gt;&lt;li&gt;Step 2: write down the definition of each technical term in what we are given&lt;/li&gt;&lt;li&gt;Step 3: write down what we are required to prove&lt;/li&gt;&lt;li&gt;Step 4: write down the definition of each technical term in what we are required to prove&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;So these 4 steps are quite easy, quite straightforward.&lt;/p&gt;
&lt;p&gt;The next step is not as easy&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Step 5: THINK!&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;While we don't need to aim to the same level of formality required to mathematicians who prove theorems, we can surely keep the spirit of the process: write down and define what you have, write down and define what you want to achieve. Then, think.&lt;/p&gt;&lt;p&gt;We tend to take for granted that we can think, after all we do it all day long. But focusing our attention on a specific topic, giving it time, exploring it, considering questions about it, evaluating possible answers, all these things are increasingly unpopular. This is not the place for a critique of our society full of noise, where ideas, products, and works of art are watched for mere seconds before getting a like and passing into oblivion. But it is worth noting that thinking is &lt;em&gt;not&lt;/em&gt; easy.&lt;/p&gt;&lt;p&gt;The implementation of a black box might require a lot of thinking, and we have to accept this. It might require a lot of rewrites, prove unsuccessful only after a certain amount of time, or even require a separate project to be properly managed. There are no shortcuts here.&lt;/p&gt;&lt;h2 id="the-coding-interview-problem"&gt;The coding interview problem&lt;a class="headerlink" href="#the-coding-interview-problem" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;What do we do during a coding interview? What are we trying to understand with this excruciating exercise that puts people in a pillory for one hour? &lt;/p&gt;&lt;p&gt;What we should do, in my opinion, is to &lt;em&gt;help the candidate to show how they solve problems&lt;/em&gt;. We should facilitate a discussion along the lines of the three points that I mentioned: decomposition, communication, implementation. As you can see implementation is not avoided, it's a coding interview because there should be a part of it in which we write code, but it should be done only after we established a decomposition of the system.&lt;/p&gt;&lt;p&gt;I also believe that the assignment should be purposefully too complex to implement in a single one-hour session, and this should be explicitly communicated. This forces the candidate to design instead of rushing headlong into implementing the first requirement of the exercise without reading the rest. At any point, if the candidate is unable to implement a specific step, we can also move on to other steps and fake the input. This way we get many benefits:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The candidate won't feel stressed by the need of showing how good they are at coding. The design part is a friendly chat, where suggestions can be made and specific technologies/solutions might be discarded if not known to the candidate.&lt;/li&gt;&lt;li&gt;They won't perceive the interview as a failure because they couldn't implement a single step or because they didn't complete the assignment in time.&lt;/li&gt;&lt;li&gt;We can explore the way the candidate communicates, the way they decompose complex processes, how well they understand problems and, eventually, how they write code.&lt;/li&gt;&lt;li&gt;We can adjust the level of difficulty of the interview or explore specific topics in detail just asking the candidate to focus on a specific detail.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;As an interviewer, I value the decomposition phase much more than the part in which you show me how well you remember all the functions of the Python standard library in a stressful situation. The truth is that I look them up very often and I don't look down on people because they don't remember the name of a method. I have one hour to decide if you are a good addition to the company, if you can be a good teammate for my next project, and if (possibly with some training) you can be given the responsibility for part of the system. In that hour I need to capture the main traits of your approach.&lt;/p&gt;&lt;p&gt;Don't get me wrong, I am a terrible nitpicker and probably on the brink of being OCD about some things, such as naming or tidiness of the code. But I try to take my own advice. What is the most important thing about you that I can understand? I think it would be extremely disappointing to discover that I hired someone who knows the standard library by heart but can't pick the right technology to complete a project before the deadline.&lt;/p&gt;&lt;p&gt;I understand that when you are interviewed you feel like you are in a position of weakness and that you are sitting there at the mercy of an evil interviewer whose purpose is only to uncover what you don't know. I'm sorry if you had to face such interviewers. I had to, and I understand the frustration. My advice is: always remember that working for a company is a matter of giving your time and your energy in exchange for personal growth. You might be interviewing for your dream job, but if the interviewer is not interested in you and your growth it's probably not that useful for you to work with them.&lt;/p&gt;&lt;p&gt;So, as a candidate, you have a responsibility to show the interviewer how you can solve problems. If you show how good you are at coding, you will impress only interviewers that are interested in your coding skills, and this is, in my opinion, a very limited part of what you can do as a programmer. You need to show that you can design, and this is independent of the level you are at.&lt;/p&gt;&lt;p&gt;You need to show that you understand problems, that you can compare solutions, that you can take your risks picking one specific strategy and that if needed you can stop at a certain point and say "This is the wrong approach".&lt;/p&gt;&lt;h2 id="patterns"&gt;Patterns&lt;a class="headerlink" href="#patterns" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Design patterns are defined by Erich Gamma and his co-authors in their seminal book&lt;sup&gt;[&lt;a id="fr-67596211" href="#fd-67596211"&gt;2&lt;/a&gt;]&lt;/sup&gt; with these words: "[...] patterns solve specific design problems and make object-oriented designs more flexible, elegant, and ultimately reusable. [...] A designer who is familiar with such patterns can apply them immediately to design problems without having to rediscover them."&lt;/p&gt;&lt;p&gt;I want to focus on the words "solve specific design problems" because what I notice is that many people apply patterns without having understood the problem they are trying to solve. Even worse, they look at the world through the lens of the patterns they know, twisting the nature of problems to fit the solution they know.&lt;/p&gt;&lt;p&gt;Back to the original sentence. "I will write a class" is considered the go-to solution in OOP languages. What we believe is that, in an OOP language, whatever the problem, the solution is to write a class. So, our first move on the chessboard of the interview is to write a class. This is a dangerous misuse of a pattern such as data encapsulation, and an expert interviewer will checkmate us in one move. I saw candidates facing problems that could be solved in 10 minutes with two functions and a dictionary spending more than 50 minutes swamped in a multitude of classes, trying to figure out which object contained the data they needed at a certain point of the process.&lt;/p&gt;&lt;p&gt;Clearly, classes might be the best solution for some problems, but this should come at the end of your analysis. You write a class because you have data and functions that can be put together, and this is valid for any other technology. Always ask yourself: what is the reason why I use this? What is the problem that I'm trying to solve?&lt;/p&gt;&lt;h2 id="a-dangerous-culture"&gt;A dangerous culture&lt;a class="headerlink" href="#a-dangerous-culture" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We all make the same mistake here: we push (or at least accept) a culture in which we teach and learn tools as go-to solutions without teaching to identify and face problems.&lt;/p&gt;&lt;p&gt;Programming languages, architectural patterns, algorithms. Those are all tools to implement solutions, they are not the solutions. You should learn them, down to the most minute details if you can, but never put them on the table before you understood the problem.&lt;/p&gt;&lt;p&gt;Alexis Carrel said, "A few observation and much reasoning lead to error; many observations and a little reasoning to truth."&lt;sup&gt;[&lt;a id="fr--1534585" href="#fd--1534585"&gt;3&lt;/a&gt;]&lt;/sup&gt; The advice that I take from the French Nobel Prize winner is: what is in front of you has to be observed deeply to find out its real nature. What things are is much more important than what we think they are and how we think we should treat them ("reasoning"). And what things are, if observed properly, will also reveal ways to interact with them, to manipulate them, to solve them.&lt;/p&gt;&lt;p&gt;If you want a clear example of the opposite, observe a programmer (maybe you yourself) looking for help on an error the web framework or the compiler threw at them. Copy and paste the error message into Google, pick the first result (Stack Overflow), scroll down until you find some code, apply. I dare you to call this "engineering". Many times we don't even read the Stack Overflow question, we directly read the answer, not to mention the fact that many times we don't even read the error message!&lt;/p&gt;&lt;p&gt;I recommend reading a very interesting article by Joseph Gefroh, &lt;a href="https://medium.com/swlh/why-your-technical-interview-is-broken-and-how-to-fix-it-7004da002aa8"&gt;Why Your Technical Interview Is Broken, and How to Fix It&lt;/a&gt;, where he discusses the various types of skills that you can explore during an interview, and which ones you should be interested in. In particular, I couldn't agree more with his point about algorithmic interviews, as I believe they are deeply flawed.&lt;/p&gt;&lt;p&gt;I also recommend having a look at the &lt;a href="https://github.com/guardian/coding-exercises"&gt;Guardian Coding Exercises&lt;/a&gt; and to read the description of the repository. I think they are a good example of tests that allow the candidate and the interviewer to work together, to actually meet and to discuss a solution. There is no "right" way to solve them, and many of them cannot be solved in 45 minutes, which is usually the time given to a candidate after an initial introductory chat.&lt;/p&gt;&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I hope these short considerations helped you to see my point. We should all shift our gaze from the tools we have to the nature of problems and to their solutions. We are missing an important step here, which is ultimately what defines a good engineer and which is the most important thing that you can learn in your career. Observe problems, stop and think, devise a strategy, zoom out and zoom in. Learn to use tools, don't be used by them.&lt;/p&gt;&lt;p&gt;We need to push for this approach in our interviews, but also try to promote this culture in our teams and companies.&lt;/p&gt;&lt;hr&gt;&lt;div id="_footnotes"&gt;&lt;div id="fd--8217925"&gt;&lt;a href="#fr--8217925"&gt;1&lt;/a&gt; see "What is a software architecture?" in Clean Architectures in Python &lt;a href="https://www.thedigitalcatbooks.com"&gt;https://www.thedigitalcatbooks.com&lt;/a&gt;&lt;/div&gt;&lt;div id="fd-67596211"&gt;&lt;a href="#fr-67596211"&gt;2&lt;/a&gt; &lt;em&gt;Design Patterns: Elements of Reusable Object-Oriented Software&lt;/em&gt; by Gamma, Vlissides, Johnson, and Helm&lt;/div&gt;&lt;div id="fd--1534585"&gt;&lt;a href="#fr--1534585"&gt;3&lt;/a&gt; &lt;em&gt;Réflexions sur la vie&lt;/em&gt;, Paris, 1952&lt;/div&gt;&lt;/div&gt;</content><category term="Programming"></category><category term="architectures"></category><category term="design"></category><category term="tools"></category></entry></feed>